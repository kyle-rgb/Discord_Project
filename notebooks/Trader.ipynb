{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, sqlite3 as sql, datetime as dt, re, time, yfinance as yf, psutil\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import nltk\n",
    "import os, gc\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from api_key import cryptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current tables \n",
    "with sql.connect('../data/interim/companies.db') as con:\n",
    "        port = pd.read_sql(f\"SELECT Date date, Open, High, Low, Close, Volume, Volatility, Turnover, symbol FROM daily ORDER BY date\", con=con, parse_dates={'date': '%Y-%m-%d %H:%M:%S'})\\\n",
    "                .drop_duplicates(subset=['date', 'symbol'])\n",
    "        recommends = pd.read_sql(f\"SELECT Date date, symbol, Firm, new_grade, prev_grade, Action from recommendations ORDER BY Date\", con=con, parse_dates={'date': '%Y-%m-%d %H:%M:%S'})\n",
    "        arts =pd.read_sql(\"SELECT date, symbol, publisher, pos_sent, neu_sent, neg_sent, comp_sent FROM articles ORDER BY date\", con=con, parse_dates={'date': '%Y-%m-%d %H:%M:%S'})\n",
    "        crypt_arts = pd.read_sql(\"SELECT date, symbol, publisher,pos_sent, neu_sent, neg_sent, comp_sent  FROM news_sentiment ORDER BY date\", con=con, parse_dates={'date': '%Y-%m-%d %H:%M:%S'})\n",
    "        articles = pd.concat([arts, crypt_arts], axis=0, ignore_index=True)\n",
    "        comments = pd.read_sql(f\"SELECT DATE(timestamp) date, channel, symbols, pos_sent, neu_sent, neg_sent, comp_sent from symbol_comments ORDER BY timestamp\", parse_dates={'date': '%Y-%m-%d'}, con=con)\n",
    "        comments.loc[:, \"symbols\"] = comments.symbols.apply(lambda x: x.replace('BTC', 'BTC-USD'))\n",
    "        companies = tuple(port.symbol.unique())\n",
    "        c_data = pd.read_sql(f\"SELECT * from mentions WHERE symbol IN {companies}\", con=con, index_col='pk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments \n",
    "symbols_re = re.compile(r\"\\[|\\]|\\'|\\'\")\n",
    "last_index = comments.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "# decompose for single symbol / use explode\n",
    "for i, row in comments.iterrows():\n",
    "    symbols = re.sub(symbols_re, \"\", row.symbols)\n",
    "    symbols = symbols.split(',')\n",
    "    for sym in symbols:\n",
    "        last_index+=1\n",
    "        comments.loc[last_index, [\"symbols\"]] = sym\n",
    "        comments.loc[last_index, [\"comment_index\"]] = i\n",
    "        comments.loc[last_index, [\"date\", \"channel\", \"pos_sent\", \"neu_sent\", \"neg_sent\", \"comp_sent\"]] = row.date, row.channel, row.pos_sent, row.neu_sent,  row.neg_sent, row.comp_sent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "comments.assign(sym = lambda x: x.symbols.apply(lambda x: re.sub(symbols_re, '', x)).apply(str.split, sep=',')).explode('sym').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "comments = comments[lambda x:~( x.comment_index.isnull())]\n",
    "comments = comments[lambda x: x.symbols.isin(companies)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyst Recommendations\n",
    "recommendsDict = {\"Very Bearish\": 1, \"Bearish\": 2, \"Neutral\": 3, \"Bullish\": 4, \"Very Bullish\": 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyst Recommendations\n",
    "recommends=recommends.assign(new_sent = lambda x: x.new_grade.apply(lambda g: recommendsDict[g]))\\\n",
    "    .assign(prev_sent = lambda x: x.prev_grade.apply(lambda g: recommendsDict[g]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Volatility',\n",
       "       'Turnover', 'symbol'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Financial Data\n",
    "port.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Financial Data\n",
    "# Add Recent Month's Financial Data \n",
    "def create_daily_data(ticker):\n",
    "    tick = yf.ticker.Ticker(ticker)\n",
    "    historical_data = tick.history(\"1mo\")\n",
    "    outstanding = tick.info.get(\"sharesOutstanding\")\n",
    "    if outstanding == None:\n",
    "        outstanding = 1\n",
    "    daily_close = historical_data[\"Close\"]\n",
    "    pct_change = daily_close.pct_change().fillna(0)\n",
    "    periods = 2\n",
    "    # calc volatility\n",
    "    vola = (pct_change.rolling(periods).std() * np.sqrt(periods)).fillna(0)\n",
    "    historical_data = historical_data.assign(Volatility = vola)\n",
    "    historical_data = historical_data.assign(Turnover = lambda x: x.Volume / outstanding)\n",
    "    historical_data = historical_data.assign(symbol = ticker)\n",
    "    return historical_data.reset_index().round({\"Volatility\": 6, \"Turnover\": 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Class: Originally labeled to be Evaluate Aggregate Trade, but ended up as Agg and Trade; Web App and its visualizations will be the evaluation tools  \n",
    "# take aggregations over a frequency time period; make buying decisions based off the frequency of data points and sentiments\n",
    "# return port with new information: shares and cost * shares\n",
    "class EAT():\n",
    "    def __init__(self, portfolio, articles, comments, recs, start, end):\n",
    "        self.portfolio = portfolio.copy(deep=True)\n",
    "        self.postions = []\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.articles = articles[lambda x: (x.date >= start) & (x.date <= end)]\n",
    "        self.comments =  comments[lambda x: (x.date >= start) & (x.date <= end)]\n",
    "        self.recs = recs[lambda x: (x.date >= start) & (x.date <= end)]\n",
    "\n",
    "        self.aggs = {}\n",
    "\n",
    "    def aggregate(self):\n",
    "        articles_agg = self.articles.groupby([pd.Grouper(key=\"date\", freq=\"1Y\"), 'symbol'])\\\n",
    "            .agg({'pos_sent': ['mean'], 'neg_sent': ['mean'], 'neu_sent': ['mean'], 'comp_sent': ['mean', 'count']}).assign(type=lambda x: 'News')\n",
    "        comments_agg = self.comments.groupby([pd.Grouper(key=\"date\", freq=\"1Y\"), 'symbols'])\\\n",
    "            .agg({'pos_sent': ['mean'], 'neg_sent': ['mean'], 'neu_sent': ['mean'], 'comp_sent': ['mean', 'count']}).assign(type=lambda x: 'Chats')\n",
    "        recommends_agg = self.recs.groupby([pd.Grouper(key=\"date\", freq=\"1Y\"), 'symbol'])\\\n",
    "            .agg({'new_sent': ['mean'], 'prev_sent': ['mean', 'count']}).assign(type=lambda x: 'Analysts')\n",
    "        recommends_agg = recommends_agg.reset_index()\n",
    "        comments_agg = comments_agg.reset_index()\n",
    "        articles_agg = articles_agg.reset_index()\n",
    "        recommends_agg.columns = recommends_agg.columns.droplevel(1)\n",
    "        comments_agg.columns = comments_agg.columns.droplevel(1)\n",
    "        articles_agg.columns = articles_agg.columns.droplevel(1)\n",
    "        \n",
    "        articles_agg.columns = ['date', 'symbol', 'pos_sent', 'neg_sent', 'neu_sent', 'comp_sent',\n",
    "       'counts', 'type']\n",
    "        comments_agg.columns = ['date', 'symbol', 'pos_sent', 'neg_sent', 'neu_sent', 'comp_sent',\n",
    "       'counts', 'type']\n",
    "        recommends_agg.columns = ['date', 'symbol', 'new_sent', 'prev_sent', 'counts', 'type']\n",
    "        # comments_agg=comments_agg.assign(date = lambda x: x.date.apply(lambda x: x.date))\n",
    "        self.aggs['recommendations'] = recommends_agg\n",
    "        self.aggs['articles'] = articles_agg\n",
    "        self.aggs['comments'] = comments_agg\n",
    "        return None \n",
    "\n",
    "\n",
    "    def tradeSents(self, agg, label, min_samples, min_comp_sent, shares):\n",
    "        # add action, shares, cost\n",
    "        returns = self.aggs[agg][lambda x: (x.date >= self.start) & (x[label] >= min_comp_sent) & (x.counts >= min_samples)]\n",
    "        # query portfolio for first cost add columns\n",
    "        indexes = pd.Int64Index([])\n",
    "        for date, sym in returns.loc[:, ['date', 'symbol']].values:\n",
    "            # ns = returns[lambda x: x.date == date].shape[0]\n",
    "            if sym not in self.postions:\n",
    "                self.postions.append(sym)\n",
    "                f1_date = (date + relativedelta(years=1)).to_pydatetime()\n",
    "                indexes = self.portfolio[lambda x: ((x.date > date) & (x.symbol == sym) & (x.date <= f1_date))].index\n",
    "                self.portfolio.loc[indexes, \"shares\"] = shares\n",
    "            else:\n",
    "                self.postions.append(sym)\n",
    "                f1_date = (date + relativedelta(years=1)).to_pydatetime()\n",
    "                indexes = self.portfolio[lambda x: ((x.date > date) & (x.symbol == sym) & (x.date <= f1_date))].index\n",
    "                self.portfolio.loc[indexes, \"shares\"] = shares * self.postions.count(sym)\n",
    "            \n",
    "            i = returns[lambda x: (x.date == date) & (x.symbol == sym)].index\n",
    "            if not indexes.empty:\n",
    "                returns.loc[i, 'cost'] = shares * self.portfolio.loc[indexes[0], \"Close\"]\n",
    "                returns.loc[i, 'returns'] = shares * self.portfolio.loc[indexes[-1], \"Close\"]\n",
    "            else:\n",
    "                indexes = self.portfolio[lambda x: (x.symbol == sym)].index\n",
    "                returns.loc[i, 'cost'] = shares * self.portfolio.loc[indexes[-1], \"Open\"]\n",
    "                returns.loc[i, 'returns'] = shares * self.portfolio.loc[indexes[-1], \"Close\"]\n",
    "\n",
    "        return self.portfolio#returns\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Class\n",
    "eat = EAT(port, articles, comments, recommends, dt.datetime(2018, 1, 1), dt.datetime(2022, 1, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Class; Must be called first\n",
    "eat.aggregate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kyle\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\Kyle\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1765: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>Turnover</th>\n",
       "      <th>symbol</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>42.972000</td>\n",
       "      <td>44.066002</td>\n",
       "      <td>42.192001</td>\n",
       "      <td>43.397999</td>\n",
       "      <td>29616500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.950000e-02</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>11.420000</td>\n",
       "      <td>11.650000</td>\n",
       "      <td>11.020000</td>\n",
       "      <td>11.430000</td>\n",
       "      <td>55182000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.570000e-02</td>\n",
       "      <td>AMD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>27.250112</td>\n",
       "      <td>27.374832</td>\n",
       "      <td>27.005378</td>\n",
       "      <td>27.332474</td>\n",
       "      <td>115127600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000e-03</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>20.639999</td>\n",
       "      <td>21.840000</td>\n",
       "      <td>20.532000</td>\n",
       "      <td>21.360001</td>\n",
       "      <td>73033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000e-04</td>\n",
       "      <td>ACB</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>88.080002</td>\n",
       "      <td>88.599998</td>\n",
       "      <td>8789400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.200000e-03</td>\n",
       "      <td>BABA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98728</th>\n",
       "      <td>2022-01-28</td>\n",
       "      <td>24.003000</td>\n",
       "      <td>25.709999</td>\n",
       "      <td>22.809999</td>\n",
       "      <td>25.639999</td>\n",
       "      <td>21496600</td>\n",
       "      <td>0.101186</td>\n",
       "      <td>7.133600e-02</td>\n",
       "      <td>PTON</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98729</th>\n",
       "      <td>2022-01-28</td>\n",
       "      <td>20.660000</td>\n",
       "      <td>21.320000</td>\n",
       "      <td>19.309999</td>\n",
       "      <td>20.900000</td>\n",
       "      <td>96497500</td>\n",
       "      <td>0.058454</td>\n",
       "      <td>6.066900e-02</td>\n",
       "      <td>NIO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98730</th>\n",
       "      <td>2022-01-28</td>\n",
       "      <td>1.850000</td>\n",
       "      <td>1.870000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1.780000</td>\n",
       "      <td>2441000</td>\n",
       "      <td>0.035781</td>\n",
       "      <td>2.085600e-02</td>\n",
       "      <td>SOLO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98731</th>\n",
       "      <td>2022-01-29</td>\n",
       "      <td>37780.714844</td>\n",
       "      <td>38576.261719</td>\n",
       "      <td>37406.472656</td>\n",
       "      <td>38138.179688</td>\n",
       "      <td>17194183075</td>\n",
       "      <td>0.008032</td>\n",
       "      <td>1.719418e+10</td>\n",
       "      <td>BTC-USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98732</th>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>37922.519531</td>\n",
       "      <td>37922.519531</td>\n",
       "      <td>36865.222656</td>\n",
       "      <td>36916.058594</td>\n",
       "      <td>15363525632</td>\n",
       "      <td>0.041409</td>\n",
       "      <td>1.536353e+10</td>\n",
       "      <td>BTC-USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98731 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date          Open          High           Low         Close  \\\n",
       "0     2017-01-03     42.972000     44.066002     42.192001     43.397999   \n",
       "1     2017-01-03     11.420000     11.650000     11.020000     11.430000   \n",
       "2     2017-01-03     27.250112     27.374832     27.005378     27.332474   \n",
       "3     2017-01-03     20.639999     21.840000     20.532000     21.360001   \n",
       "4     2017-01-03     89.000000     89.000000     88.080002     88.599998   \n",
       "...          ...           ...           ...           ...           ...   \n",
       "98728 2022-01-28     24.003000     25.709999     22.809999     25.639999   \n",
       "98729 2022-01-28     20.660000     21.320000     19.309999     20.900000   \n",
       "98730 2022-01-28      1.850000      1.870000      1.750000      1.780000   \n",
       "98731 2022-01-29  37780.714844  38576.261719  37406.472656  38138.179688   \n",
       "98732 2022-01-31  37922.519531  37922.519531  36865.222656  36916.058594   \n",
       "\n",
       "            Volume  Volatility      Turnover   symbol  shares  \n",
       "0         29616500    0.000000  2.950000e-02     TSLA     NaN  \n",
       "1         55182000    0.000000  4.570000e-02      AMD     NaN  \n",
       "2        115127600    0.000000  7.000000e-03     AAPL     NaN  \n",
       "3            73033    0.000000  4.000000e-04      ACB     NaN  \n",
       "4          8789400    0.000000  3.200000e-03     BABA     NaN  \n",
       "...            ...         ...           ...      ...     ...  \n",
       "98728     21496600    0.101186  7.133600e-02     PTON     NaN  \n",
       "98729     96497500    0.058454  6.066900e-02      NIO     NaN  \n",
       "98730      2441000    0.035781  2.085600e-02     SOLO     NaN  \n",
       "98731  17194183075    0.008032  1.719418e+10  BTC-USD     NaN  \n",
       "98732  15363525632    0.041409  1.536353e+10  BTC-USD     NaN  \n",
       "\n",
       "[98731 rows x 10 columns]"
      ]
     },
     "execution_count": 1173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Custom Class\n",
    "# Trade Based on Text Data Sources\n",
    "eat.tradeSents(\"comments\", \"comp_sent\", min_samples=1, min_comp_sent=0.15, shares=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kyle\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\Kyle\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1765: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    }
   ],
   "source": [
    "# Custom Class\n",
    "ret = eat.tradeSents(\"articles\", \"comp_sent\", 100, 0.5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Class\n",
    "ret = eat.tradeSents(\"recommendations\", \"new_sent\", 25, 4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eat.tradeSents(\"articles\", \"comp_sent\", 100, 0.5, 10)\n",
    "# eat.tradeSents(\"recommendations\", \"new_sent\", 25, 4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos_sent</th>\n",
       "      <th>neg_sent</th>\n",
       "      <th>neu_sent</th>\n",
       "      <th>comp_sent</th>\n",
       "      <th>counts</th>\n",
       "      <th>cost</th>\n",
       "      <th>returns</th>\n",
       "      <th>r_pct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>5.265895</td>\n",
       "      <td>0.623934</td>\n",
       "      <td>15.110028</td>\n",
       "      <td>8.133532</td>\n",
       "      <td>93</td>\n",
       "      <td>42329.746435</td>\n",
       "      <td>67754.449959</td>\n",
       "      <td>0.600634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>4.164832</td>\n",
       "      <td>0.921737</td>\n",
       "      <td>24.733701</td>\n",
       "      <td>5.878339</td>\n",
       "      <td>1405</td>\n",
       "      <td>330494.633604</td>\n",
       "      <td>502545.053391</td>\n",
       "      <td>0.520585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pos_sent  neg_sent   neu_sent  comp_sent  counts           cost  \\\n",
       "date                                                                          \n",
       "2019-12-31  5.265895  0.623934  15.110028   8.133532      93   42329.746435   \n",
       "2020-12-31  4.164832  0.921737  24.733701   5.878339    1405  330494.633604   \n",
       "\n",
       "                  returns     r_pct  \n",
       "date                                 \n",
       "2019-12-31   67754.449959  0.600634  \n",
       "2020-12-31  502545.053391  0.520585  "
      ]
     },
     "execution_count": 1152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Custom Class\n",
    "# Analyst Only Strategy Returns\n",
    "ret.groupby('date').sum().assign(r_pct = lambda x: (x.returns - x.cost) / x.cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kyle\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\Kyle\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1765: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos_sent</th>\n",
       "      <th>neg_sent</th>\n",
       "      <th>neu_sent</th>\n",
       "      <th>comp_sent</th>\n",
       "      <th>counts</th>\n",
       "      <th>cost</th>\n",
       "      <th>returns</th>\n",
       "      <th>r_pct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>1.886672</td>\n",
       "      <td>0.725528</td>\n",
       "      <td>19.387871</td>\n",
       "      <td>12.806051</td>\n",
       "      <td>6245</td>\n",
       "      <td>363631.928234</td>\n",
       "      <td>537816.954250</td>\n",
       "      <td>0.479015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31</th>\n",
       "      <td>2.635620</td>\n",
       "      <td>0.961372</td>\n",
       "      <td>26.403193</td>\n",
       "      <td>18.722140</td>\n",
       "      <td>9305</td>\n",
       "      <td>90168.539557</td>\n",
       "      <td>73207.400317</td>\n",
       "      <td>-0.188105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pos_sent  neg_sent   neu_sent  comp_sent  counts           cost  \\\n",
       "date                                                                          \n",
       "2020-12-31  1.886672  0.725528  19.387871  12.806051    6245  363631.928234   \n",
       "2021-12-31  2.635620  0.961372  26.403193  18.722140    9305   90168.539557   \n",
       "\n",
       "                  returns     r_pct  \n",
       "date                                 \n",
       "2020-12-31  537816.954250  0.479015  \n",
       "2021-12-31   73207.400317 -0.188105  "
      ]
     },
     "execution_count": 1153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Custom Class\n",
    "# News Only Strategy Returns\n",
    "ret = eat.tradeSents(\"articles\", \"comp_sent\", 100, 0.5, 10)\n",
    "ret.groupby('date').sum().assign(r_pct = lambda x: (x.returns - x.cost) / x.cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kyle\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\Kyle\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1765: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_sent</th>\n",
       "      <th>prev_sent</th>\n",
       "      <th>counts</th>\n",
       "      <th>cost</th>\n",
       "      <th>returns</th>\n",
       "      <th>r_pct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-12-31</th>\n",
       "      <td>29.418501</td>\n",
       "      <td>29.140315</td>\n",
       "      <td>280</td>\n",
       "      <td>21844.340649</td>\n",
       "      <td>27577.331295</td>\n",
       "      <td>0.262447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>33.888142</td>\n",
       "      <td>33.519803</td>\n",
       "      <td>355</td>\n",
       "      <td>30153.087006</td>\n",
       "      <td>47727.473297</td>\n",
       "      <td>0.582839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>67.845811</td>\n",
       "      <td>67.276012</td>\n",
       "      <td>993</td>\n",
       "      <td>57397.397575</td>\n",
       "      <td>62125.701008</td>\n",
       "      <td>0.082378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31</th>\n",
       "      <td>58.988827</td>\n",
       "      <td>58.416372</td>\n",
       "      <td>694</td>\n",
       "      <td>67120.639572</td>\n",
       "      <td>56591.000690</td>\n",
       "      <td>-0.156876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             new_sent  prev_sent  counts          cost       returns     r_pct\n",
       "date                                                                          \n",
       "2018-12-31  29.418501  29.140315     280  21844.340649  27577.331295  0.262447\n",
       "2019-12-31  33.888142  33.519803     355  30153.087006  47727.473297  0.582839\n",
       "2020-12-31  67.845811  67.276012     993  57397.397575  62125.701008  0.082378\n",
       "2021-12-31  58.988827  58.416372     694  67120.639572  56591.000690 -0.156876"
      ]
     },
     "execution_count": 1157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Custom Class\n",
    "ret = eat.tradeSents(\"recommendations\", \"new_sent\", 25, 4, 10)\n",
    "ret.groupby('date').sum().assign(r_pct = lambda x: (x.returns - x.cost) / x.cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sql.connect('../data/interim/companies.db') as con:\n",
    "        port =pd.read_sql(\"SELECT * FROM daily ORDER BY date\", con=con, parse_dates={'date': '%Y-%m-%d %H:%M:%S'})\n",
    "        arts =pd.read_sql(\"SELECT * FROM articles ORDER BY date\", con=con, parse_dates={'date': '%Y-%m-%d %H:%M:%S'})\n",
    "        crypt_arts = pd.read_sql(\"SELECT * FROM crypt_articles ORDER BY date\", con=sql.connect('../data/raw/crypt.db'))\n",
    "        #articles = pd.concat([arts, crypt_arts], axis=0, ignore_index=True)\n",
    "        comments = pd.read_sql(f\"SELECT DATE(timestamp) date, channel, symbols, pos_sent, neu_sent, neg_sent, comp_sent from symbol_comments ORDER BY timestamp\", parse_dates={'date': '%Y-%m-%d'}, con=con)\n",
    "        comments.loc[:, \"symbols\"] = comments.symbols.apply(lambda x: x.replace('BTC', 'BTC-USD'))\n",
    "        companies = tuple(port.symbol.unique())\n",
    "        c_data = pd.read_sql(f\"SELECT * from mentions WHERE symbol IN {companies}\", con=con, index_col='pk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# News Articles \n",
    "# Decrypt Byte-Encoded Data\n",
    "decrypt_cols = [x for x in crypt_arts.columns if x not in ['pk', 'pos_sent', \"neu_sent\", \"neg_sent\", \"comp_sent\"]]\n",
    "for col in decrypt_cols:\n",
    "    crypt_arts.loc[:, col] = crypt_arts.loc[:, col].apply(bytes).apply(cryptor.decrypt).apply(str, encoding='utf-8')\n",
    "    if col == 'date':\n",
    "        crypt_arts.loc[:, col] = crypt_arts.loc[:, col].apply(str.split, sep=\" \").apply(lambda x: x[0]).apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pk</th>\n",
       "      <th>article</th>\n",
       "      <th>headline</th>\n",
       "      <th>comments</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>symbol</th>\n",
       "      <th>publisher</th>\n",
       "      <th>pos_sent</th>\n",
       "      <th>neg_sent</th>\n",
       "      <th>neu_sent</th>\n",
       "      <th>comp_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>The Transportation Security Administration say...</td>\n",
       "      <td>TSA extends COVID mask rule for U.S. transport...</td>\n",
       "      <td>49</td>\n",
       "      <td>2021-08-17</td>\n",
       "      <td>https://seekingalpha.com/news/3731674-tsa-exte...</td>\n",
       "      <td>AAL</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.2544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5705</td>\n",
       "      <td>Parler, the social network popular with conser...</td>\n",
       "      <td>Parler comes back online after a month off the...</td>\n",
       "      <td>249</td>\n",
       "      <td>2021-02-16</td>\n",
       "      <td>https://seekingalpha.com/news/3662032-parler-c...</td>\n",
       "      <td>FB</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.9363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1709</td>\n",
       "      <td>Amazon (NASDAQ:AMZN): Q1 GAAP EPS of $15.79 be...</td>\n",
       "      <td>Amazon EPS beats by $6.18, beats on revenue</td>\n",
       "      <td>115</td>\n",
       "      <td>2021-04-29</td>\n",
       "      <td>https://seekingalpha.com/news/3688132-amazon-e...</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.7184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3240</td>\n",
       "      <td>Blink Charging (BLNK +7.4%), EVgo (EVGO +8.4%)...</td>\n",
       "      <td>Electric vehicle battery stocks break higher a...</td>\n",
       "      <td>28</td>\n",
       "      <td>2021-07-28</td>\n",
       "      <td>https://seekingalpha.com/news/3720809-electric...</td>\n",
       "      <td>BLNK</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5968</td>\n",
       "      <td>Teenagers across the U.S. are looking to Redmo...</td>\n",
       "      <td>TikTok rescue by Microsoft could make sense - ...</td>\n",
       "      <td>93</td>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>https://seekingalpha.com/news/3598676-tiktok-r...</td>\n",
       "      <td>FB</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.8934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15321</th>\n",
       "      <td>11885</td>\n",
       "      <td>The Associated Press, NBC, Edison Research, Fo...</td>\n",
       "      <td>Joe Biden wins U.S. presidential election</td>\n",
       "      <td>23654</td>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>https://seekingalpha.com/news/3633355-joe-bide...</td>\n",
       "      <td>QQQ</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.0258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15322</th>\n",
       "      <td>9323</td>\n",
       "      <td>Animal spirits are firing up again on red-hot ...</td>\n",
       "      <td>Electric vehicle names head higher led by Kand...</td>\n",
       "      <td>126</td>\n",
       "      <td>2020-11-23</td>\n",
       "      <td>https://seekingalpha.com/news/3638678-electric...</td>\n",
       "      <td>NIO</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.921</td>\n",
       "      <td>-0.2263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15323</th>\n",
       "      <td>2573</td>\n",
       "      <td>Boeing (BA +3.1%) bounces sharply higher after...</td>\n",
       "      <td>Boeing sales outpaced cancellations last month...</td>\n",
       "      <td>10</td>\n",
       "      <td>2021-03-09</td>\n",
       "      <td>https://seekingalpha.com/news/3670770-boeing-s...</td>\n",
       "      <td>BA</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.913</td>\n",
       "      <td>-0.7005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15324</th>\n",
       "      <td>7455</td>\n",
       "      <td>Workers in Arizona, Oregon, and New Mexico hav...</td>\n",
       "      <td>Intel workers file coronavirus safety complaints</td>\n",
       "      <td>15</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>https://seekingalpha.com/news/3572138-intel-wo...</td>\n",
       "      <td>INTC</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.9112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15325</th>\n",
       "      <td>14010</td>\n",
       "      <td>Commercial vehicle registrations in the Europe...</td>\n",
       "      <td>EU commercial vehicle new registrations expand...</td>\n",
       "      <td>14</td>\n",
       "      <td>2021-05-26</td>\n",
       "      <td>https://seekingalpha.com/news/3700479-eu-comme...</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.8271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15326 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pk                                            article  \\\n",
       "0          9  The Transportation Security Administration say...   \n",
       "1       5705  Parler, the social network popular with conser...   \n",
       "2       1709  Amazon (NASDAQ:AMZN): Q1 GAAP EPS of $15.79 be...   \n",
       "3       3240  Blink Charging (BLNK +7.4%), EVgo (EVGO +8.4%)...   \n",
       "4       5968  Teenagers across the U.S. are looking to Redmo...   \n",
       "...      ...                                                ...   \n",
       "15321  11885  The Associated Press, NBC, Edison Research, Fo...   \n",
       "15322   9323  Animal spirits are firing up again on red-hot ...   \n",
       "15323   2573  Boeing (BA +3.1%) bounces sharply higher after...   \n",
       "15324   7455  Workers in Arizona, Oregon, and New Mexico hav...   \n",
       "15325  14010  Commercial vehicle registrations in the Europe...   \n",
       "\n",
       "                                                headline comments       date  \\\n",
       "0      TSA extends COVID mask rule for U.S. transport...      49  2021-08-17   \n",
       "1      Parler comes back online after a month off the...     249  2021-02-16   \n",
       "2            Amazon EPS beats by $6.18, beats on revenue     115  2021-04-29   \n",
       "3      Electric vehicle battery stocks break higher a...      28  2021-07-28   \n",
       "4      TikTok rescue by Microsoft could make sense - ...      93  2020-08-01   \n",
       "...                                                  ...      ...        ...   \n",
       "15321          Joe Biden wins U.S. presidential election   23654  2020-11-07   \n",
       "15322  Electric vehicle names head higher led by Kand...     126  2020-11-23   \n",
       "15323  Boeing sales outpaced cancellations last month...      10  2021-03-09   \n",
       "15324   Intel workers file coronavirus safety complaints      15  2020-05-08   \n",
       "15325  EU commercial vehicle new registrations expand...      14  2021-05-26   \n",
       "\n",
       "                                                    link symbol  \\\n",
       "0      https://seekingalpha.com/news/3731674-tsa-exte...    AAL   \n",
       "1      https://seekingalpha.com/news/3662032-parler-c...     FB   \n",
       "2      https://seekingalpha.com/news/3688132-amazon-e...   AMZN   \n",
       "3      https://seekingalpha.com/news/3720809-electric...   BLNK   \n",
       "4      https://seekingalpha.com/news/3598676-tiktok-r...     FB   \n",
       "...                                                  ...    ...   \n",
       "15321  https://seekingalpha.com/news/3633355-joe-bide...    QQQ   \n",
       "15322  https://seekingalpha.com/news/3638678-electric...    NIO   \n",
       "15323  https://seekingalpha.com/news/3670770-boeing-s...     BA   \n",
       "15324  https://seekingalpha.com/news/3572138-intel-wo...   INTC   \n",
       "15325  https://seekingalpha.com/news/3700479-eu-comme...   TSLA   \n",
       "\n",
       "           publisher  pos_sent  neg_sent  neu_sent  comp_sent  \n",
       "0      Seeking Alpha     0.042     0.042     0.916     0.2544  \n",
       "1      Seeking Alpha     0.082     0.039     0.879     0.9363  \n",
       "2      Seeking Alpha     0.065     0.000     0.935     0.7184  \n",
       "3      Seeking Alpha     0.047     0.038     0.916     0.1280  \n",
       "4      Seeking Alpha     0.114     0.033     0.853     0.8934  \n",
       "...              ...       ...       ...       ...        ...  \n",
       "15321  Seeking Alpha     0.059     0.048     0.893     0.0258  \n",
       "15322  Seeking Alpha     0.033     0.046     0.921    -0.2263  \n",
       "15323  Seeking Alpha     0.021     0.066     0.913    -0.7005  \n",
       "15324  Seeking Alpha     0.133     0.087     0.779     0.9112  \n",
       "15325  Seeking Alpha     0.069     0.020     0.911     0.8271  \n",
       "\n",
       "[15326 rows x 12 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# News Articles\n",
    "crypt_arts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# News Articles\n",
    "arts = arts.assign(comments = lambda x: 0)\n",
    "arts = arts.loc[:, ['pk', 'article', 'title', 'comments','date', 'link', 'symbol', 'publisher','pos_sent', 'neg_sent', 'neu_sent', 'comp_sent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# News Articles\n",
    "# nongreedy\n",
    "regex = re.compile(r\"© Reuters.+?(-|—)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# News Articles\n",
    "arts = arts.assign(article = lambda x: x.article.apply(lambda w: re.sub(regex, \"\", w)).apply(str.strip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# News Articles\n",
    "# Conform Columns\n",
    "arts = arts.rename(columns={'title': 'headline'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# News Articles\n",
    "# Dummy Site Variable (seeking alpha's site or not)\n",
    "arted = pd.concat([crypt_arts.assign(sa=lambda x: 1), arts.assign(sa=lambda x: 0)], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP\n",
    "stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "stop_words = stop_words.union({'said', 'us', 'also', 'inc', 'could', 'word', 'b', 'q', })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP\n",
    "def wordCounts(df, comment_array):\n",
    "    comment_list = []\n",
    "    for comment in comment_array:\n",
    "        comment_dictionary = {} \n",
    "        punc_regex = r\"[\\，\\’\\'\\'\\\"\\\"\\“\\”!\\?@#$%&\\(\\)\\*,-.\\\\\\{\\}+~\\/:;<>\\[\\]^`|=_]\"\n",
    "        reg_bad_quotes = re.compile(u\"[\\x94\\x93\\x92\\x91]\")\n",
    "        comment = comment.lower()\n",
    "        comment = re.sub(punc_regex, \" \", comment)\n",
    "        comment = re.sub(reg_bad_quotes, \" \", comment)\n",
    "        words = nltk.tokenize.word_tokenize(comment)\n",
    "        for w in words:\n",
    "            if (w in comment_dictionary.keys()) & (w not in stop_words):\n",
    "                comment_dictionary[w] += 1\n",
    "            elif (w not in stop_words):\n",
    "                comment_dictionary[w] = 1\n",
    "        comments_words = dict(sorted(comment_dictionary.items(), key=lambda x: x[1], reverse=True))\n",
    "        comment_list.append(comments_words)\n",
    "    \n",
    "    df = df.assign(word_obj = pd.Series(comment_list))\n",
    "    return df\n",
    "\n",
    "# word counts sans stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP\n",
    "wordy_df = wordCounts(arted, arted.article.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP\n",
    "wordy_df2 = wordy_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP\n",
    "wordy_df2 = wordy_df2.assign(article = lambda x: x.article.apply(lambda line: re.sub(r'(?<=[.,])(?=[^\\s])', r' ', line)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP\n",
    "wordy_df3 = wordy_df2.assign(word_obj = lambda x: x.word_obj.apply(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wordy_df3.to_sql('temp_table', con=sql.connect('temp.db'), if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pk</th>\n",
       "      <th>article</th>\n",
       "      <th>headline</th>\n",
       "      <th>comments</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>symbol</th>\n",
       "      <th>publisher</th>\n",
       "      <th>pos_sent</th>\n",
       "      <th>neg_sent</th>\n",
       "      <th>neu_sent</th>\n",
       "      <th>comp_sent</th>\n",
       "      <th>sa</th>\n",
       "      <th>word_obj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>The Transportation Security Administration say...</td>\n",
       "      <td>TSA extends COVID mask rule for U.S. transport...</td>\n",
       "      <td>49</td>\n",
       "      <td>2021-08-17</td>\n",
       "      <td>https://seekingalpha.com/news/3731674-tsa-exte...</td>\n",
       "      <td>AAL</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.2544</td>\n",
       "      <td>1</td>\n",
       "      <td>{'transportation': 2, 'administration': 2, 'sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5705</td>\n",
       "      <td>Parler, the social network popular with conser...</td>\n",
       "      <td>Parler comes back online after a month off the...</td>\n",
       "      <td>249</td>\n",
       "      <td>2021-02-16</td>\n",
       "      <td>https://seekingalpha.com/news/3662032-parler-c...</td>\n",
       "      <td>FB</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.9363</td>\n",
       "      <td>1</td>\n",
       "      <td>{'parler': 7, 'users': 4, 'platform': 3, 'skys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1709</td>\n",
       "      <td>Amazon (NASDAQ:AMZN): Q1 GAAP EPS of $15. 79 b...</td>\n",
       "      <td>Amazon EPS beats by $6.18, beats on revenue</td>\n",
       "      <td>115</td>\n",
       "      <td>2021-04-29</td>\n",
       "      <td>https://seekingalpha.com/news/3688132-amazon-e...</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.7184</td>\n",
       "      <td>1</td>\n",
       "      <td>{'billion': 6, '5': 4, 'revenue': 3, '108': 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3240</td>\n",
       "      <td>Blink Charging (BLNK +7. 4%), EVgo (EVGO +8. 4...</td>\n",
       "      <td>Electric vehicle battery stocks break higher a...</td>\n",
       "      <td>28</td>\n",
       "      <td>2021-07-28</td>\n",
       "      <td>https://seekingalpha.com/news/3720809-electric...</td>\n",
       "      <td>BLNK</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>1</td>\n",
       "      <td>{'infrastructure': 5, 'bill': 5, '7': 4, 'ev':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5968</td>\n",
       "      <td>Teenagers across the U. S. are looking to Redm...</td>\n",
       "      <td>TikTok rescue by Microsoft could make sense - ...</td>\n",
       "      <td>93</td>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>https://seekingalpha.com/news/3598676-tiktok-r...</td>\n",
       "      <td>FB</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.8934</td>\n",
       "      <td>1</td>\n",
       "      <td>{'would': 5, 'tiktok': 4, 'microsoft': 4, 'mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26805</th>\n",
       "      <td>7584</td>\n",
       "      <td>Stock in gaming and e-commerce firm Sea (NYSE:...</td>\n",
       "      <td>Sea Slumps as Tencent Moves to Cut Voting Stak...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>https://www.investing.com/news/stock-market-ne...</td>\n",
       "      <td>SE</td>\n",
       "      <td>Investing.com</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.7867</td>\n",
       "      <td>0</td>\n",
       "      <td>{'tencent': 5, 'sea': 4, 'voting': 4, 'stake':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26806</th>\n",
       "      <td>1625</td>\n",
       "      <td>On Wednesday, Palantir Technologies Inc (NYSE:...</td>\n",
       "      <td>Palantir Technologies Announces Collaboration ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>https://www.investing.com/news/stock-market-ne...</td>\n",
       "      <td>PLTR</td>\n",
       "      <td>Investing.com</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.9630</td>\n",
       "      <td>0</td>\n",
       "      <td>{'palantir': 6, 'platform': 5, 'hhi': 4, 'big'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26807</th>\n",
       "      <td>7583</td>\n",
       "      <td>Asia Pacific stocks were down on Thursday morn...</td>\n",
       "      <td>Asian Stocks Down, Positive Chinese Data Fails...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>https://www.investing.com/news/stock-market-ne...</td>\n",
       "      <td>SE</td>\n",
       "      <td>Investing.com</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.9201</td>\n",
       "      <td>0</td>\n",
       "      <td>{'services': 4, '1': 4, 'day': 4, 'u': 3, '0':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26808</th>\n",
       "      <td>9547</td>\n",
       "      <td>The S&amp;P 500 closed down Friday, marking its wo...</td>\n",
       "      <td>S&amp;P 500 in Big Weekly Loss as Tech Bulls Scatt...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-07</td>\n",
       "      <td>https://www.investing.com/news/stock-market-ne...</td>\n",
       "      <td>ON</td>\n",
       "      <td>Investing.com</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.9733</td>\n",
       "      <td>0</td>\n",
       "      <td>{'stocks': 5, 'nasdaq': 5, 'tech': 4, 'rate': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26809</th>\n",
       "      <td>9548</td>\n",
       "      <td>The S&amp;P 500 struggled for direction Friday, pa...</td>\n",
       "      <td>S&amp;P 500 Struggles for Direction as Jobs Miss F...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-07</td>\n",
       "      <td>https://www.investing.com/news/stock-market-ne...</td>\n",
       "      <td>ON</td>\n",
       "      <td>Investing.com</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.9807</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': 6, 'nasdaq': 5, 'tech': 4, 'rate': 4, 'm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26810 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pk                                            article  \\\n",
       "0         9  The Transportation Security Administration say...   \n",
       "1      5705  Parler, the social network popular with conser...   \n",
       "2      1709  Amazon (NASDAQ:AMZN): Q1 GAAP EPS of $15. 79 b...   \n",
       "3      3240  Blink Charging (BLNK +7. 4%), EVgo (EVGO +8. 4...   \n",
       "4      5968  Teenagers across the U. S. are looking to Redm...   \n",
       "...     ...                                                ...   \n",
       "26805  7584  Stock in gaming and e-commerce firm Sea (NYSE:...   \n",
       "26806  1625  On Wednesday, Palantir Technologies Inc (NYSE:...   \n",
       "26807  7583  Asia Pacific stocks were down on Thursday morn...   \n",
       "26808  9547  The S&P 500 closed down Friday, marking its wo...   \n",
       "26809  9548  The S&P 500 struggled for direction Friday, pa...   \n",
       "\n",
       "                                                headline comments       date  \\\n",
       "0      TSA extends COVID mask rule for U.S. transport...      49  2021-08-17   \n",
       "1      Parler comes back online after a month off the...     249  2021-02-16   \n",
       "2            Amazon EPS beats by $6.18, beats on revenue     115  2021-04-29   \n",
       "3      Electric vehicle battery stocks break higher a...      28  2021-07-28   \n",
       "4      TikTok rescue by Microsoft could make sense - ...      93  2020-08-01   \n",
       "...                                                  ...      ...        ...   \n",
       "26805  Sea Slumps as Tencent Moves to Cut Voting Stak...        0 2022-01-04   \n",
       "26806  Palantir Technologies Announces Collaboration ...        0 2022-01-05   \n",
       "26807  Asian Stocks Down, Positive Chinese Data Fails...        0 2022-01-05   \n",
       "26808  S&P 500 in Big Weekly Loss as Tech Bulls Scatt...        0 2022-01-07   \n",
       "26809  S&P 500 Struggles for Direction as Jobs Miss F...        0 2022-01-07   \n",
       "\n",
       "                                                    link symbol  \\\n",
       "0      https://seekingalpha.com/news/3731674-tsa-exte...    AAL   \n",
       "1      https://seekingalpha.com/news/3662032-parler-c...     FB   \n",
       "2      https://seekingalpha.com/news/3688132-amazon-e...   AMZN   \n",
       "3      https://seekingalpha.com/news/3720809-electric...   BLNK   \n",
       "4      https://seekingalpha.com/news/3598676-tiktok-r...     FB   \n",
       "...                                                  ...    ...   \n",
       "26805  https://www.investing.com/news/stock-market-ne...     SE   \n",
       "26806  https://www.investing.com/news/stock-market-ne...   PLTR   \n",
       "26807  https://www.investing.com/news/stock-market-ne...     SE   \n",
       "26808  https://www.investing.com/news/stock-market-ne...     ON   \n",
       "26809  https://www.investing.com/news/stock-market-ne...     ON   \n",
       "\n",
       "           publisher  pos_sent  neg_sent  neu_sent  comp_sent  sa  \\\n",
       "0      Seeking Alpha     0.042     0.042     0.916     0.2544   1   \n",
       "1      Seeking Alpha     0.082     0.039     0.879     0.9363   1   \n",
       "2      Seeking Alpha     0.065     0.000     0.935     0.7184   1   \n",
       "3      Seeking Alpha     0.047     0.038     0.916     0.1280   1   \n",
       "4      Seeking Alpha     0.114     0.033     0.853     0.8934   1   \n",
       "...              ...       ...       ...       ...        ...  ..   \n",
       "26805  Investing.com     0.084     0.046     0.870     0.7867   0   \n",
       "26806  Investing.com     0.143     0.015     0.842     0.9630   0   \n",
       "26807  Investing.com     0.068     0.034     0.898     0.9201   0   \n",
       "26808  Investing.com     0.096     0.049     0.856     0.9733   0   \n",
       "26809  Investing.com     0.098     0.038     0.864     0.9807   0   \n",
       "\n",
       "                                                word_obj  \n",
       "0      {'transportation': 2, 'administration': 2, 'sa...  \n",
       "1      {'parler': 7, 'users': 4, 'platform': 3, 'skys...  \n",
       "2      {'billion': 6, '5': 4, 'revenue': 3, '108': 3,...  \n",
       "3      {'infrastructure': 5, 'bill': 5, '7': 4, 'ev':...  \n",
       "4      {'would': 5, 'tiktok': 4, 'microsoft': 4, 'mak...  \n",
       "...                                                  ...  \n",
       "26805  {'tencent': 5, 'sea': 4, 'voting': 4, 'stake':...  \n",
       "26806  {'palantir': 6, 'platform': 5, 'hhi': 4, 'big'...  \n",
       "26807  {'services': 4, '1': 4, 'day': 4, 'u': 3, '0':...  \n",
       "26808  {'stocks': 5, 'nasdaq': 5, 'tech': 4, 'rate': ...  \n",
       "26809  {'0': 6, 'nasdaq': 5, 'tech': 4, 'rate': 4, 'm...  \n",
       "\n",
       "[26810 rows x 14 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLP\n",
    "wordy_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP\n",
    "# encrypted encoding was utf8 and the .htm file encodings were latin-1 \n",
    "bad_encode_regex = re.compile(u\"[\\x94\\x93\\x92\\x91]\")\n",
    "wordy_df2 = wordy_df2.assign(article = lambda x: x.article.apply(lambda line: re.sub(r'(?<=[.,])(?=[^\\s])', r' ', line)))\n",
    "wordy_df2 = wordy_df2.assign(article = lambda x: x.article.apply(lambda line: re.sub(bad_encode_regex, r' ', line)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP\n",
    "def wordCounts(comment_array):\n",
    "    comment_dictionary = {} \n",
    "    for comment in comment_array:\n",
    "        punc_regex = r\"[\\，\\’\\'\\'\\\"\\\"\\“\\”!\\?@#$%&\\(\\)\\*,-.\\\\\\{\\}+~\\/:;<>\\[\\]^`|=_]\"\n",
    "        reg_bad_quotes = re.compile(u\"[\\x94\\x93\\x92\\x91]\")\n",
    "        comment = comment.lower()\n",
    "        comment = re.sub(punc_regex, \" \", comment)\n",
    "        comment = re.sub(reg_bad_quotes, \" \", comment)\n",
    "        comment = re.sub(r\"[0-9]\", \"\", comment)\n",
    "        words = nltk.tokenize.word_tokenize(comment)\n",
    "        for w in words:\n",
    "            if (w in comment_dictionary.keys()) & (w not in stop_words):\n",
    "                comment_dictionary[w] += 1\n",
    "            elif (w not in stop_words):\n",
    "                comment_dictionary[w] = 1\n",
    "    \n",
    "    comments_words = dict(sorted(comment_dictionary.items(), key=lambda x: x[1], reverse=True))\n",
    "    # comment_list.append(comments_words)\n",
    "\n",
    "    # df = df.assign(word_obj = pd.Series(comment_list))\n",
    "    return pd.Series(comments_words)\n",
    "\n",
    "# word counts sans stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# News Articles\n",
    "# NLP\n",
    "positive_article_words = wordCounts(wordy_df2[lambda x: x.comp_sent >= 0].article.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# News Articles\n",
    "# NLP\n",
    "negative_article_words = wordCounts(wordy_df2[lambda x: x.comp_sent < 0].article.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# News Articles\n",
    "# NLP\n",
    "negative_article_words = negative_article_words.reset_index().rename(columns={'index': 'word', 0: 'neg_counts'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# News Articles\n",
    "# NLP\n",
    "positive_article_words = positive_article_words.reset_index().rename(columns={'index': 'word', 0: 'pos_counts'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>draftkings</td>\n",
       "      <td>1114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  pos_counts\n",
       "739  draftkings        1114"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# News Articles\n",
    "# NLP\n",
    "positive_article_words[lambda x: x.word=='draftkings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>neg_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2779</th>\n",
       "      <td>draftkings</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  neg_counts\n",
       "2779  draftkings          56"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# News Articles\n",
    "# NLP\n",
    "# the media loves draftkings (DKNG)\n",
    "negative_article_words[lambda x: x.word == 'draftkings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# News Articles\n",
    "# NLP\n",
    "positive_example = wordCounts(wordy_df2[lambda x: (x.symbol == 'DKNG') & (x.comp_sent >= 0)].article).reset_index().rename(columns={'index': 'word', 0: 'neg_counts'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pk           115\n",
       "article      115\n",
       "headline     115\n",
       "comments     115\n",
       "date         115\n",
       "link         115\n",
       "publisher    115\n",
       "pos_sent     115\n",
       "neg_sent     115\n",
       "neu_sent     115\n",
       "comp_sent    115\n",
       "sa           115\n",
       "word_obj     115\n",
       "Name: TSLA, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# News Articles\n",
    "# NLP\n",
    "wordy_df2[lambda x: (x.date <= dt.datetime(2021, 2, 1)) & (x.date >= dt.datetime(2021, 1, 1))].groupby('symbol').count().sort_values('date').loc['TSLA', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos_counts</th>\n",
       "      <th>neg_counts</th>\n",
       "      <th>pos_pct</th>\n",
       "      <th>neg_pct</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nasdaq</td>\n",
       "      <td>57260.0</td>\n",
       "      <td>12043.0</td>\n",
       "      <td>0.826227</td>\n",
       "      <td>0.173773</td>\n",
       "      <td>69303.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nyse</td>\n",
       "      <td>41399.0</td>\n",
       "      <td>8421.0</td>\n",
       "      <td>0.830971</td>\n",
       "      <td>0.169029</td>\n",
       "      <td>49820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u</td>\n",
       "      <td>20841.0</td>\n",
       "      <td>6841.0</td>\n",
       "      <td>0.752872</td>\n",
       "      <td>0.247128</td>\n",
       "      <td>27682.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>company</td>\n",
       "      <td>21977.0</td>\n",
       "      <td>3720.0</td>\n",
       "      <td>0.855236</td>\n",
       "      <td>0.144764</td>\n",
       "      <td>25697.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>year</td>\n",
       "      <td>21347.0</td>\n",
       "      <td>3856.0</td>\n",
       "      <td>0.847002</td>\n",
       "      <td>0.152998</td>\n",
       "      <td>25203.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51564</th>\n",
       "      <td>synbiotic</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51563</th>\n",
       "      <td>minnett</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51562</th>\n",
       "      <td>ord</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51561</th>\n",
       "      <td>wfm</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61388</th>\n",
       "      <td>reconnecting</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61389 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               word  pos_counts  neg_counts   pos_pct   neg_pct   counts\n",
       "0            nasdaq     57260.0     12043.0  0.826227  0.173773  69303.0\n",
       "1              nyse     41399.0      8421.0  0.830971  0.169029  49820.0\n",
       "4                 u     20841.0      6841.0  0.752872  0.247128  27682.0\n",
       "2           company     21977.0      3720.0  0.855236  0.144764  25697.0\n",
       "3              year     21347.0      3856.0  0.847002  0.152998  25203.0\n",
       "...             ...         ...         ...       ...       ...      ...\n",
       "51564     synbiotic         1.0         0.0  1.000000  0.000000      1.0\n",
       "51563       minnett         1.0         0.0  1.000000  0.000000      1.0\n",
       "51562           ord         1.0         0.0  1.000000  0.000000      1.0\n",
       "51561           wfm         1.0         0.0  1.000000  0.000000      1.0\n",
       "61388  reconnecting         0.0         1.0  0.000000  1.000000      1.0\n",
       "\n",
       "[61389 rows x 6 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# News Articles\n",
    "# NLP\n",
    "positive_article_words.merge(how='outer', right=negative_article_words).fillna(0).\\\n",
    "    assign(pos_pct = lambda x: x.pos_counts / (x.pos_counts + x.neg_counts)).\\\n",
    "        assign(neg_pct = lambda x: x.neg_counts / (x.pos_counts + x.neg_counts)).sort_values('neg_pct').\\\n",
    "            assign(counts = lambda x: (x.pos_counts + x.neg_counts)).sort_values('counts', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP\n",
    "# Sentiment Scores\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP\n",
    "# Sentiment Scores\n",
    "def sentiment_art(art):\n",
    "    return sia.polarity_scores(art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# News Articles\n",
    "# NLP\n",
    "wordy_df_news = wordy_df2.assign(sentiment_dict = lambda x : x.article.apply(sentiment_art))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# News Articles\n",
    "# NLP\n",
    "wordy_df_news= wordy_df_news.assign(pos_sent = lambda x: x.sentiment_dict.apply(lambda y: y['pos']))\\\n",
    "    .assign(neg_sent = lambda x: x.sentiment_dict.apply(lambda y: y['neg']))\\\n",
    "        .assign(neu_sent = lambda x: x.sentiment_dict.apply(lambda y: y['neu']))\\\n",
    "            .assign(comp_sent = lambda x: x.sentiment_dict.apply(lambda y: y['compound']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# News Articles\n",
    "# NLP\n",
    "wordy_df_news.drop('sentiment_dict', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pk</th>\n",
       "      <th>article</th>\n",
       "      <th>headline</th>\n",
       "      <th>comments</th>\n",
       "      <th>link</th>\n",
       "      <th>symbol</th>\n",
       "      <th>publisher</th>\n",
       "      <th>pos_sent</th>\n",
       "      <th>neg_sent</th>\n",
       "      <th>neu_sent</th>\n",
       "      <th>comp_sent</th>\n",
       "      <th>sa</th>\n",
       "      <th>word_obj</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-30</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-31</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-30</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-31</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-28</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-31</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-30</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-31</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-30</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-31</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-31</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-30</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-31</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-30</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-29</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-30</th>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-31</th>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-30</th>\n",
       "      <td>1160</td>\n",
       "      <td>1160</td>\n",
       "      <td>1160</td>\n",
       "      <td>1160</td>\n",
       "      <td>1160</td>\n",
       "      <td>1160</td>\n",
       "      <td>1160</td>\n",
       "      <td>1160</td>\n",
       "      <td>1160</td>\n",
       "      <td>1160</td>\n",
       "      <td>1160</td>\n",
       "      <td>1160</td>\n",
       "      <td>1160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-31</th>\n",
       "      <td>1678</td>\n",
       "      <td>1678</td>\n",
       "      <td>1678</td>\n",
       "      <td>1678</td>\n",
       "      <td>1678</td>\n",
       "      <td>1678</td>\n",
       "      <td>1678</td>\n",
       "      <td>1678</td>\n",
       "      <td>1678</td>\n",
       "      <td>1678</td>\n",
       "      <td>1678</td>\n",
       "      <td>1678</td>\n",
       "      <td>1678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-31</th>\n",
       "      <td>1664</td>\n",
       "      <td>1664</td>\n",
       "      <td>1664</td>\n",
       "      <td>1664</td>\n",
       "      <td>1664</td>\n",
       "      <td>1664</td>\n",
       "      <td>1664</td>\n",
       "      <td>1664</td>\n",
       "      <td>1664</td>\n",
       "      <td>1664</td>\n",
       "      <td>1664</td>\n",
       "      <td>1664</td>\n",
       "      <td>1664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-30</th>\n",
       "      <td>1671</td>\n",
       "      <td>1671</td>\n",
       "      <td>1671</td>\n",
       "      <td>1671</td>\n",
       "      <td>1671</td>\n",
       "      <td>1671</td>\n",
       "      <td>1671</td>\n",
       "      <td>1671</td>\n",
       "      <td>1671</td>\n",
       "      <td>1671</td>\n",
       "      <td>1671</td>\n",
       "      <td>1671</td>\n",
       "      <td>1671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-31</th>\n",
       "      <td>1841</td>\n",
       "      <td>1841</td>\n",
       "      <td>1841</td>\n",
       "      <td>1841</td>\n",
       "      <td>1841</td>\n",
       "      <td>1841</td>\n",
       "      <td>1841</td>\n",
       "      <td>1841</td>\n",
       "      <td>1841</td>\n",
       "      <td>1841</td>\n",
       "      <td>1841</td>\n",
       "      <td>1841</td>\n",
       "      <td>1841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-30</th>\n",
       "      <td>1787</td>\n",
       "      <td>1787</td>\n",
       "      <td>1787</td>\n",
       "      <td>1787</td>\n",
       "      <td>1787</td>\n",
       "      <td>1787</td>\n",
       "      <td>1787</td>\n",
       "      <td>1787</td>\n",
       "      <td>1787</td>\n",
       "      <td>1787</td>\n",
       "      <td>1787</td>\n",
       "      <td>1787</td>\n",
       "      <td>1787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>1603</td>\n",
       "      <td>1603</td>\n",
       "      <td>1603</td>\n",
       "      <td>1603</td>\n",
       "      <td>1603</td>\n",
       "      <td>1603</td>\n",
       "      <td>1603</td>\n",
       "      <td>1603</td>\n",
       "      <td>1603</td>\n",
       "      <td>1603</td>\n",
       "      <td>1603</td>\n",
       "      <td>1603</td>\n",
       "      <td>1603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-31</th>\n",
       "      <td>1995</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-28</th>\n",
       "      <td>2031</td>\n",
       "      <td>2031</td>\n",
       "      <td>2031</td>\n",
       "      <td>2031</td>\n",
       "      <td>2031</td>\n",
       "      <td>2031</td>\n",
       "      <td>2031</td>\n",
       "      <td>2031</td>\n",
       "      <td>2031</td>\n",
       "      <td>2031</td>\n",
       "      <td>2031</td>\n",
       "      <td>2031</td>\n",
       "      <td>2031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-31</th>\n",
       "      <td>2099</td>\n",
       "      <td>2099</td>\n",
       "      <td>2099</td>\n",
       "      <td>2099</td>\n",
       "      <td>2099</td>\n",
       "      <td>2099</td>\n",
       "      <td>2099</td>\n",
       "      <td>2099</td>\n",
       "      <td>2099</td>\n",
       "      <td>2099</td>\n",
       "      <td>2099</td>\n",
       "      <td>2099</td>\n",
       "      <td>2099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-30</th>\n",
       "      <td>1978</td>\n",
       "      <td>1978</td>\n",
       "      <td>1978</td>\n",
       "      <td>1978</td>\n",
       "      <td>1978</td>\n",
       "      <td>1978</td>\n",
       "      <td>1978</td>\n",
       "      <td>1978</td>\n",
       "      <td>1978</td>\n",
       "      <td>1978</td>\n",
       "      <td>1978</td>\n",
       "      <td>1978</td>\n",
       "      <td>1978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-31</th>\n",
       "      <td>1874</td>\n",
       "      <td>1874</td>\n",
       "      <td>1874</td>\n",
       "      <td>1874</td>\n",
       "      <td>1874</td>\n",
       "      <td>1874</td>\n",
       "      <td>1874</td>\n",
       "      <td>1874</td>\n",
       "      <td>1874</td>\n",
       "      <td>1874</td>\n",
       "      <td>1874</td>\n",
       "      <td>1874</td>\n",
       "      <td>1874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-30</th>\n",
       "      <td>1663</td>\n",
       "      <td>1663</td>\n",
       "      <td>1663</td>\n",
       "      <td>1663</td>\n",
       "      <td>1663</td>\n",
       "      <td>1663</td>\n",
       "      <td>1663</td>\n",
       "      <td>1663</td>\n",
       "      <td>1663</td>\n",
       "      <td>1663</td>\n",
       "      <td>1663</td>\n",
       "      <td>1663</td>\n",
       "      <td>1663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-31</th>\n",
       "      <td>1392</td>\n",
       "      <td>1392</td>\n",
       "      <td>1392</td>\n",
       "      <td>1392</td>\n",
       "      <td>1392</td>\n",
       "      <td>1392</td>\n",
       "      <td>1392</td>\n",
       "      <td>1392</td>\n",
       "      <td>1392</td>\n",
       "      <td>1392</td>\n",
       "      <td>1392</td>\n",
       "      <td>1392</td>\n",
       "      <td>1392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-31</th>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-30</th>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-31</th>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-30</th>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31</th>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-31</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pk  article  headline  comments  link  symbol  publisher  \\\n",
       "date                                                                     \n",
       "2018-01-31     1        1         1         1     1       1          1   \n",
       "2018-02-28     0        0         0         0     0       0          0   \n",
       "2018-03-31     0        0         0         0     0       0          0   \n",
       "2018-04-30     0        0         0         0     0       0          0   \n",
       "2018-05-31     0        0         0         0     0       0          0   \n",
       "2018-06-30     1        1         1         1     1       1          1   \n",
       "2018-07-31     0        0         0         0     0       0          0   \n",
       "2018-08-31     1        1         1         1     1       1          1   \n",
       "2018-09-30     0        0         0         0     0       0          0   \n",
       "2018-10-31     2        2         2         2     2       2          2   \n",
       "2018-11-30     3        3         3         3     3       3          3   \n",
       "2018-12-31     0        0         0         0     0       0          0   \n",
       "2019-01-31     8        8         8         8     8       8          8   \n",
       "2019-02-28     5        5         5         5     5       5          5   \n",
       "2019-03-31     8        8         8         8     8       8          8   \n",
       "2019-04-30     4        4         4         4     4       4          4   \n",
       "2019-05-31     9        9         9         9     9       9          9   \n",
       "2019-06-30     4        4         4         4     4       4          4   \n",
       "2019-07-31     4        4         4         4     4       4          4   \n",
       "2019-08-31     6        6         6         6     6       6          6   \n",
       "2019-09-30     5        5         5         5     5       5          5   \n",
       "2019-10-31     5        5         5         5     5       5          5   \n",
       "2019-11-30     8        8         8         8     8       8          8   \n",
       "2019-12-31     3        3         3         3     3       3          3   \n",
       "2020-01-31     1        1         1         1     1       1          1   \n",
       "2020-02-29     9        9         9         9     9       9          9   \n",
       "2020-03-31    24       24        24        24    24      24         24   \n",
       "2020-04-30    49       49        49        49    49      49         49   \n",
       "2020-05-31   760      760       760       760   760     760        760   \n",
       "2020-06-30  1160     1160      1160      1160  1160    1160       1160   \n",
       "2020-07-31  1678     1678      1678      1678  1678    1678       1678   \n",
       "2020-08-31  1664     1664      1664      1664  1664    1664       1664   \n",
       "2020-09-30  1671     1671      1671      1671  1671    1671       1671   \n",
       "2020-10-31  1841     1841      1841      1841  1841    1841       1841   \n",
       "2020-11-30  1787     1787      1787      1787  1787    1787       1787   \n",
       "2020-12-31  1603     1603      1603      1603  1603    1603       1603   \n",
       "2021-01-31  1995     1995      1995      1995  1995    1995       1995   \n",
       "2021-02-28  2031     2031      2031      2031  2031    2031       2031   \n",
       "2021-03-31  2099     2099      2099      2099  2099    2099       2099   \n",
       "2021-04-30  1978     1978      1978      1978  1978    1978       1978   \n",
       "2021-05-31  1874     1874      1874      1874  1874    1874       1874   \n",
       "2021-06-30  1663     1663      1663      1663  1663    1663       1663   \n",
       "2021-07-31  1392     1392      1392      1392  1392    1392       1392   \n",
       "2021-08-31  1195     1195      1195      1195  1195    1195       1195   \n",
       "2021-09-30   102      102       102       102   102     102        102   \n",
       "2021-10-31    48       48        48        48    48      48         48   \n",
       "2021-11-30    64       64        64        64    64      64         64   \n",
       "2021-12-31    40       40        40        40    40      40         40   \n",
       "2022-01-31     5        5         5         5     5       5          5   \n",
       "\n",
       "            pos_sent  neg_sent  neu_sent  comp_sent    sa  word_obj  \n",
       "date                                                                 \n",
       "2018-01-31         1         1         1          1     1         1  \n",
       "2018-02-28         0         0         0          0     0         0  \n",
       "2018-03-31         0         0         0          0     0         0  \n",
       "2018-04-30         0         0         0          0     0         0  \n",
       "2018-05-31         0         0         0          0     0         0  \n",
       "2018-06-30         1         1         1          1     1         1  \n",
       "2018-07-31         0         0         0          0     0         0  \n",
       "2018-08-31         1         1         1          1     1         1  \n",
       "2018-09-30         0         0         0          0     0         0  \n",
       "2018-10-31         2         2         2          2     2         2  \n",
       "2018-11-30         3         3         3          3     3         3  \n",
       "2018-12-31         0         0         0          0     0         0  \n",
       "2019-01-31         8         8         8          8     8         8  \n",
       "2019-02-28         5         5         5          5     5         5  \n",
       "2019-03-31         8         8         8          8     8         8  \n",
       "2019-04-30         4         4         4          4     4         4  \n",
       "2019-05-31         9         9         9          9     9         9  \n",
       "2019-06-30         4         4         4          4     4         4  \n",
       "2019-07-31         4         4         4          4     4         4  \n",
       "2019-08-31         6         6         6          6     6         6  \n",
       "2019-09-30         5         5         5          5     5         5  \n",
       "2019-10-31         5         5         5          5     5         5  \n",
       "2019-11-30         8         8         8          8     8         8  \n",
       "2019-12-31         3         3         3          3     3         3  \n",
       "2020-01-31         1         1         1          1     1         1  \n",
       "2020-02-29         9         9         9          9     9         9  \n",
       "2020-03-31        24        24        24         24    24        24  \n",
       "2020-04-30        49        49        49         49    49        49  \n",
       "2020-05-31       760       760       760        760   760       760  \n",
       "2020-06-30      1160      1160      1160       1160  1160      1160  \n",
       "2020-07-31      1678      1678      1678       1678  1678      1678  \n",
       "2020-08-31      1664      1664      1664       1664  1664      1664  \n",
       "2020-09-30      1671      1671      1671       1671  1671      1671  \n",
       "2020-10-31      1841      1841      1841       1841  1841      1841  \n",
       "2020-11-30      1787      1787      1787       1787  1787      1787  \n",
       "2020-12-31      1603      1603      1603       1603  1603      1603  \n",
       "2021-01-31      1995      1995      1995       1995  1995      1995  \n",
       "2021-02-28      2031      2031      2031       2031  2031      2031  \n",
       "2021-03-31      2099      2099      2099       2099  2099      2099  \n",
       "2021-04-30      1978      1978      1978       1978  1978      1978  \n",
       "2021-05-31      1874      1874      1874       1874  1874      1874  \n",
       "2021-06-30      1663      1663      1663       1663  1663      1663  \n",
       "2021-07-31      1392      1392      1392       1392  1392      1392  \n",
       "2021-08-31      1195      1195      1195       1195  1195      1195  \n",
       "2021-09-30       102       102       102        102   102       102  \n",
       "2021-10-31        48        48        48         48    48        48  \n",
       "2021-11-30        64        64        64         64    64        64  \n",
       "2021-12-31        40        40        40         40    40        40  \n",
       "2022-01-31         5         5         5          5     5         5  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# News Articles\n",
    "# NLP\n",
    "wordy_df_news.groupby(pd.Grouper(key='date', freq=\"1M\")).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>channel</th>\n",
       "      <th>symbols</th>\n",
       "      <th>pos_sent</th>\n",
       "      <th>neu_sent</th>\n",
       "      <th>neg_sent</th>\n",
       "      <th>comp_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-08</td>\n",
       "      <td>wetlqd-ideas</td>\n",
       "      <td>['AMD']</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.4404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-13</td>\n",
       "      <td>wetlqd-ideas</td>\n",
       "      <td>['MSFT']</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.4404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-13</td>\n",
       "      <td>wetlqd-ideas</td>\n",
       "      <td>['MSFT']</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.3612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-14</td>\n",
       "      <td>wetlqd-ideas</td>\n",
       "      <td>['ON', 'MA', 'ING']</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.403</td>\n",
       "      <td>-0.4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-14</td>\n",
       "      <td>wetlqd-ideas</td>\n",
       "      <td>['CRM']</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3389</th>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>option-trading</td>\n",
       "      <td>['OOOO']</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3390</th>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>option-trading</td>\n",
       "      <td>['ING']</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.8402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3391</th>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>trading</td>\n",
       "      <td>['FSLY']</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3392</th>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>trading</td>\n",
       "      <td>['IT']</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3393</th>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>options</td>\n",
       "      <td>['CRM']</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3394 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date         channel              symbols  pos_sent  neu_sent  \\\n",
       "0    2019-08-08    wetlqd-ideas              ['AMD']     0.293     0.707   \n",
       "1    2019-08-13    wetlqd-ideas             ['MSFT']     0.182     0.818   \n",
       "2    2019-08-13    wetlqd-ideas             ['MSFT']     0.294     0.706   \n",
       "3    2019-08-14    wetlqd-ideas  ['ON', 'MA', 'ING']     0.000     0.597   \n",
       "4    2019-08-14    wetlqd-ideas              ['CRM']     0.000     1.000   \n",
       "...         ...             ...                  ...       ...       ...   \n",
       "3389 2020-12-08  option-trading             ['OOOO']     0.000     1.000   \n",
       "3390 2020-12-08  option-trading              ['ING']     0.900     0.100   \n",
       "3391 2020-12-08         trading             ['FSLY']     0.000     1.000   \n",
       "3392 2020-12-08         trading               ['IT']     0.000     1.000   \n",
       "3393 2020-12-08         options              ['CRM']     0.000     1.000   \n",
       "\n",
       "      neg_sent  comp_sent  \n",
       "0        0.000     0.4404  \n",
       "1        0.000     0.4404  \n",
       "2        0.000     0.3612  \n",
       "3        0.403    -0.4019  \n",
       "4        0.000     0.0000  \n",
       "...        ...        ...  \n",
       "3389     0.000     0.0000  \n",
       "3390     0.000     0.8402  \n",
       "3391     0.000     0.0000  \n",
       "3392     0.000     0.0000  \n",
       "3393     0.000     0.0000  \n",
       "\n",
       "[3394 rows x 7 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comments\n",
    "# Stock Comments\n",
    "comments#.groupby(pd.Grouper(key='date', freq='1M')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sql.connect('../data/interim/discord/discord.db') as con:\n",
    "    full_comments =pd.read_sql(f\"SELECT DATE(timestamp) date, timestamp,channel, id, server, pk, content, isBot, mentions, emojis, links, chat_emotes from comments ORDER BY timestamp\", parse_dates={'date': '%Y-%m-%d'}, con=con)\n",
    "with sql.connect('../data/interim/companies.db') as con:\n",
    "    wanted_companies = pd.read_sql(\"SELECT DISTINCT symbol FROM daily WHERE symbol NOT IN ('PT', 'IT', 'ON', 'ING')\", con=con).symbol.values\n",
    "    wanted_companies = tuple(wanted_companies)\n",
    "    mentions = pd.read_sql(f\"SELECT * from mentions WHERE symbol IN {wanted_companies}\", con=con, index_col='pk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "full_comments = full_comments.assign(timestamp=lambda x: x.timestamp.apply(pd.to_datetime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "userIdCatcher = r\"(<@(!)?\\d+>|@everyone)\"\n",
    "discord_emote_regex = r\"<:.+:\\d+>\"\n",
    "url_regex = r\"https*\\:.+|www\\..+\"\n",
    "punc_regex = r\"[\\’\\'\\'\\\"\\\"\\“\\”!\\?@#$%&\\(\\)\\*,-.\\\\\\{\\}+~\\/:;<>\\[\\]^`|=_’]\"\n",
    "contract_regex = r\"[\\'\\’\\’]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse Comments\n",
    "# Comments\n",
    "def clean_comment(comment):\n",
    "    userIdCatcher = r\"(<@(!)?\\d+>|@everyone)\"\n",
    "    discord_emote_regex = r\"<:.+:\\d+>\"\n",
    "    url_regex = r\"https*\\:.+|www\\..+\"\n",
    "    punc_regex = r\"[\\’\\'\\'\\\"\\\"\\“\\”!\\?@#$%&\\(\\)\\*,-.\\\\\\{\\}+~\\/:;<>\\[\\]^`|=_’]\"\n",
    "    contract_regex = r\"[\\'\\’\\’]\"\n",
    "    comment = re.sub(\"|\".join([x for x in [userIdCatcher, discord_emote_regex, url_regex]]), \"\", comment)\n",
    "    comment = re.sub(contract_regex, \"\", comment)\n",
    "    comment = re.sub(punc_regex, \" \", comment)\n",
    "    comment = comment.replace(\"\\n\", \" \").replace(\"'s\", \"\")\n",
    "    return \" \" + comment + \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "full_comments = full_comments.assign(cc_comment = lambda x: x.content.apply(clean_comment).apply(str.lower))\n",
    "full_comments = full_comments.assign(st_comment = lambda x: x.cc_comment.apply(sentiment_art))\n",
    "full_comments = full_comments.assign(pos_sent = lambda x: x.st_comment.apply(lambda y: y['pos']))\\\n",
    "    .assign(neg_sent = lambda x: x.st_comment.apply(lambda y: y['neg']))\\\n",
    "        .assign(neu_sent = lambda x: x.st_comment.apply(lambda y: y['neu']))\\\n",
    "            .assign(comp_sent = lambda x: x.st_comment.apply(lambda y: y['compound'])).drop(['st_comment'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "company_set = set(x.lower() for x in mentions.symbol.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "def list_to_symbols(list_obj, set=company_set):\n",
    "    symbols = []\n",
    "    for l in list_obj:\n",
    "        if l in set:\n",
    "            symbols.append(l)\n",
    "    return symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "full_comments = full_comments.assign(symbols = lambda x: x.cc_comment.apply(nltk.tokenize.word_tokenize).apply(lambda z: list_to_symbols(z)).apply(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "emote_agg = {}\n",
    "def agg_(comma_companies, agg_dict):\n",
    "    comma_companies = re.sub(r'[\\[\\]\\'\\']', \"\", comma_companies)\n",
    "    for e in comma_companies.split(\",\"):\n",
    "        e = e.strip()\n",
    "        if e in agg_dict.keys():\n",
    "            emote_agg[e] += 1\n",
    "        else:\n",
    "            emote_agg[e] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        None\n",
       "1        None\n",
       "2        None\n",
       "3        None\n",
       "4        None\n",
       "         ... \n",
       "31929    None\n",
       "31930    None\n",
       "31931    None\n",
       "31932    None\n",
       "31933    None\n",
       "Name: symbols, Length: 31934, dtype: object"
      ]
     },
     "execution_count": 857,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comments\n",
    "full_comments.symbols.apply(lambda x: agg_(x, emote_agg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "new_mentions = pd.Series(emote_agg).reset_index().iloc[1:, :].sort_values(0, ascending=False).reset_index(drop=True).rename(columns={'index': 'symbol', 0:'counts'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>counts_x</th>\n",
       "      <th>counts_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPY</td>\n",
       "      <td>167</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>166</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NIO</td>\n",
       "      <td>151</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMD</td>\n",
       "      <td>133</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>114</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DKNG</td>\n",
       "      <td>75</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PLTR</td>\n",
       "      <td>74</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACB</td>\n",
       "      <td>60</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ZM</td>\n",
       "      <td>59</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BABA</td>\n",
       "      <td>55</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FB</td>\n",
       "      <td>54</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BA</td>\n",
       "      <td>50</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>WKHS</td>\n",
       "      <td>48</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SQ</td>\n",
       "      <td>48</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BYND</td>\n",
       "      <td>47</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>45</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>IDEX</td>\n",
       "      <td>44</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>40</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PFE</td>\n",
       "      <td>39</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>38</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NKLA</td>\n",
       "      <td>36</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GNUS</td>\n",
       "      <td>34</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>FSLY</td>\n",
       "      <td>34</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PTON</td>\n",
       "      <td>33</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RSI</td>\n",
       "      <td>31</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ROKU</td>\n",
       "      <td>31</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PINS</td>\n",
       "      <td>31</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>CRSR</td>\n",
       "      <td>31</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>PLUG</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   symbol  counts_x  counts_y\n",
       "0     SPY       167       313\n",
       "1    TSLA       166       253\n",
       "2     NIO       151       232\n",
       "3     AMD       133       174\n",
       "4    AAPL       114       174\n",
       "5    DKNG        75        86\n",
       "6    PLTR        74        99\n",
       "7     ACB        60        74\n",
       "8      ZM        59        69\n",
       "9    BABA        55       105\n",
       "10     FB        54        62\n",
       "11     BA        50        56\n",
       "12   WKHS        48        62\n",
       "13     SQ        48        64\n",
       "14   BYND        47        64\n",
       "15   NVDA        45        56\n",
       "16   IDEX        44        56\n",
       "17   AMZN        40        60\n",
       "18    PFE        39        58\n",
       "19   MSFT        38        52\n",
       "20   NKLA        36        46\n",
       "21   GNUS        34        43\n",
       "22   FSLY        34        44\n",
       "23   PTON        33        36\n",
       "24    RSI        31        46\n",
       "25   ROKU        31        64\n",
       "26   PINS        31        47\n",
       "27   CRSR        31        34\n",
       "28   PLUG        30        43"
      ]
     },
     "execution_count": 859,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comments\n",
    "# Initial Counts and Additional Data Garnered\n",
    "mentions.merge(new_mentions.assign(symbol=lambda x: x.symbol.apply(str.upper)), 'left', on='symbol').iloc[:29, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "# NLP\n",
    "comment_token_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "# NLP\n",
    "tokenSeries = wordCounts(full_comments.cc_comment.values).reset_index().rename(columns={'index': 'word', 0:'counts'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "# NLP\n",
    "commentsPositiveSeries = wordCounts(full_comments[lambda x: x.comp_sent >= 0.0].cc_comment.values).reset_index().rename(columns={'index': 'word', 0:'counts'})\n",
    "commentsNegativeSeries = wordCounts(full_comments[lambda x: x.comp_sent <= 0.0].cc_comment.values).reset_index().rename(columns={'index': 'word', 0:'counts'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>spy</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word  counts\n",
       "52  spy     176"
      ]
     },
     "execution_count": 863,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comments\n",
    "# NLP\n",
    "commentsNegativeSeries[lambda x: x.word == 'spy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>spy</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word  counts\n",
       "62  spy     269"
      ]
     },
     "execution_count": 864,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comments\n",
    "# NLP\n",
    "commentsPositiveSeries[lambda x: x.word == 'spy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SPY', 'TSLA', 'NIO', 'AMD', 'AAPL', 'DKNG', 'PLTR', 'ACB', 'ZM',\n",
       "       'BABA', 'FB', 'BA', 'WKHS', 'SQ', 'BYND', 'NVDA', 'IDEX', 'AMZN',\n",
       "       'PFE', 'MSFT', 'NKLA', 'GNUS', 'FSLY', 'PTON', 'RSI', 'ROKU',\n",
       "       'PINS', 'CRSR', 'PLUG', 'WWR', 'HYLN', 'SNDL', 'JD', 'SNAP', 'RKT',\n",
       "       'ES', 'JKS', 'NNDM', 'GME', 'SE', 'MA', 'SQQQ', 'KO', 'MARA',\n",
       "       'HEAR', 'CRM', 'CGC', 'IZEA', 'CBAT', 'VXX', 'INTC', 'SPCE', 'AAL',\n",
       "       'SPI', 'AREC', 'NFLX', 'QQQ', 'UONE', 'BLNK', 'HD', 'DIS', 'MO',\n",
       "       'TLRY', 'ADTX', 'LMNL', 'JMIA', 'EXAS', 'SOLO', 'XERS', 'DPW',\n",
       "       'GILD', 'VLDR'], dtype=object)"
      ]
     },
     "execution_count": 865,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comments\n",
    "# NLP\n",
    "mentions.symbol.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "# NLP\n",
    "# Adding the single tokens that represent the security\n",
    "more_terms = {'SPY': ['SPDR', 'SP', 'SP500', 'SPY'],\n",
    "'TSLA': ['Tesla', 'TSLA'],\n",
    "'NIO': ['Nio', 'NIO'], 'AMD': ['AMD'], 'AAPL': ['Apple', 'AAPL'],\n",
    "'DKNG': ['DraftKings', 'DKNG'],\n",
    "'PLTR': ['Palantir', 'PLTR'], 'ACB':['Aurora', 'Aurora', 'PLTR'], 'ZM':['ZM', 'Zoom'],\n",
    "'BABA':['Alibaba', 'BABA'], 'FB':['Facebook'], 'BA':['Boeing', 'BA'],\n",
    "'WKHS':['Workhorse', 'WKHS'],\n",
    "'SQ':['Square', 'SQ'], 'BYND':['Beyond Meat', 'bynd'],\n",
    "'NVDA':['NVDA', 'Nvidia'], 'IDEX':['IDEX', 'Ideanomics'], 'AMZN':['amazon', 'AMZN'],\n",
    "'PFE':['PFE', 'Pfzier'], 'MSFT':['Microsoft', 'MSFT'], 'NKLA':['Nikola', 'NKLA'], 'GNUS':['GNUS', 'Genius'],\n",
    "'FSLY':['Flastly', 'FSLY'], 'PTON':['PTON', 'Peleton'], 'RSI':['RSI'], 'ROKU':['Roku', 'ROKU'],\n",
    "'PINS':['PINS', 'Pinterest'], 'CRSR':['Corsair', 'CRSR'], 'PLUG':['Plug', 'PLUG'], 'WWR':['Westwater', 'WWR'],\n",
    "'HYLN':['HYLN', 'Hyliion'], 'SNDL':['Sundial', 'SNDL'], 'JD':['JD'], 'SNAP':['snap', 'snapchat'],\n",
    "'RKT':['Rocket', 'RKT'],\n",
    "'ES':['Eversource', 'ES'], 'JKS':['JinkoSolar', 'JKS'],\n",
    "'NNDM':['NNDM'], 'GME':['Gamestop', 'GME'], 'SE':['SE'], 'MA':['Mastercard', 'MA'], 'SQQQ':['Invesco', 'sqqq'],\n",
    "'KO':['KO', 'Coke'], 'MARA':['MARA'],\n",
    "'HEAR':['HEAR'], 'CRM':['Salesforce', 'CRM'], 'CGC':['Canopy', 'CGC'], 'IZEA':['IZEA'],\n",
    "'CBAT':['CBAK', 'CBAT'], 'VXX':['vxx'], 'INTC':['Intel', 'intc'],\n",
    "'SPCE':['virgin galactic', 'SPCE'], 'AAL':['American Airlines', 'AAL'],\n",
    "'SPI':['SPI'], 'AREC':['AREC'], 'NFLX':['Netflix', 'NFLX'], 'QQQ':['Invesco', 'QQQ'],\n",
    "'UONE':['UONE'], 'BLNK':['Blink', 'BLNK'],\n",
    "'HD':['Home Depot', 'HD'], 'DIS':['disney', 'DIS'], 'MO':['Altria', 'MO'],\n",
    "'TLRY':['Tilray', 'TLRY'], 'ADTX':['Aditxt', 'ADTX'],\n",
    "'LMNL':['Liminal', 'LMNL'], 'JMIA':['Jumia', 'JMIA'], 'EXAS':['Exact Sciences', 'EXAS'],\n",
    "'SOLO':['Electrameccanica', 'SOLO'], 'XERS':['Xeris', 'XERS'], 'DPW':['Deutsche Post', 'DPW'],\n",
    "'GILD':['GILD', 'Gilead'], 'VLDR':['Velodyne', 'VLDR'], 'BTC': ['Bitcoin', 'BTC', 'BTC-USD']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "more_terms = {k: tuple(v) for k, v in more_terms.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "additional_terms = {}\n",
    "for k, vals in more_terms.items():\n",
    "    for v in vals:\n",
    "        additional_terms[v.lower()] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "def list_to_symbols(list_obj, set=additional_terms):\n",
    "    symbols = []\n",
    "    for l in list_obj:\n",
    "        if l in set.keys():\n",
    "            symbols.append(additional_terms[l])\n",
    "    return symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "full_comments = full_comments.assign(more_symbols = lambda x: x.cc_comment.apply(nltk.tokenize.word_tokenize).apply(lambda z: list_to_symbols(z)).apply(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "full_comments = full_comments.assign(symbols = lambda x: x.symbols.apply(lambda s: re.sub(r'[\\[\\]\\'\\']', \"\", s)).apply(str.upper).apply(str.strip))\\\n",
    "    .assign(more_symbols = lambda x: x.more_symbols.apply(lambda s: re.sub(r'[\\[\\]\\'\\']', \"\", s)))\\\n",
    "        .assign(last_symbols = lambda x: x.symbols.apply(str.upper) + ',' + x.more_symbols)\\\n",
    "            .assign(last_symbols = lambda x: x.last_symbols.apply(lambda sym: set(sym.strip().split(',')) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "# Additional symbols. Full list\n",
    "full_comments = full_comments.assign(symbols = lambda x: x.last_symbols.apply(lambda s: \",\".join([c.strip() for c in s if c != ''])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "full_comments_final = full_comments.drop(['more_symbols', 'last_symbols', 'cc_comment'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_comments_final[lambda x: x.symbols.str.contains(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "with sql.connect('../data/interim/companies.db') as con:\n",
    "    cs = pd.read_sql(f\"SELECT DATE(timestamp) date, channel, symbols, pos_sent, neu_sent, neg_sent, comp_sent from symbol_comments ORDER BY timestamp\", parse_dates={'date': '%Y-%m-%d'}, con=con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>channel</th>\n",
       "      <th>symbols</th>\n",
       "      <th>pos_sent</th>\n",
       "      <th>neu_sent</th>\n",
       "      <th>neg_sent</th>\n",
       "      <th>comp_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-08</td>\n",
       "      <td>wetlqd-ideas</td>\n",
       "      <td>['AMD']</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.4404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-13</td>\n",
       "      <td>wetlqd-ideas</td>\n",
       "      <td>['MSFT']</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.4404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-13</td>\n",
       "      <td>wetlqd-ideas</td>\n",
       "      <td>['MSFT']</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.3612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-14</td>\n",
       "      <td>wetlqd-ideas</td>\n",
       "      <td>['ON', 'MA', 'ING']</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.403</td>\n",
       "      <td>-0.4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-14</td>\n",
       "      <td>wetlqd-ideas</td>\n",
       "      <td>['CRM']</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3389</th>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>option-trading</td>\n",
       "      <td>['OOOO']</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3390</th>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>option-trading</td>\n",
       "      <td>['ING']</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.8402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3391</th>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>trading</td>\n",
       "      <td>['FSLY']</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3392</th>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>trading</td>\n",
       "      <td>['IT']</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3393</th>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>options</td>\n",
       "      <td>['CRM']</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3394 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date         channel              symbols  pos_sent  neu_sent  \\\n",
       "0    2019-08-08    wetlqd-ideas              ['AMD']     0.293     0.707   \n",
       "1    2019-08-13    wetlqd-ideas             ['MSFT']     0.182     0.818   \n",
       "2    2019-08-13    wetlqd-ideas             ['MSFT']     0.294     0.706   \n",
       "3    2019-08-14    wetlqd-ideas  ['ON', 'MA', 'ING']     0.000     0.597   \n",
       "4    2019-08-14    wetlqd-ideas              ['CRM']     0.000     1.000   \n",
       "...         ...             ...                  ...       ...       ...   \n",
       "3389 2020-12-08  option-trading             ['OOOO']     0.000     1.000   \n",
       "3390 2020-12-08  option-trading              ['ING']     0.900     0.100   \n",
       "3391 2020-12-08         trading             ['FSLY']     0.000     1.000   \n",
       "3392 2020-12-08         trading               ['IT']     0.000     1.000   \n",
       "3393 2020-12-08         options              ['CRM']     0.000     1.000   \n",
       "\n",
       "      neg_sent  comp_sent  \n",
       "0        0.000     0.4404  \n",
       "1        0.000     0.4404  \n",
       "2        0.000     0.3612  \n",
       "3        0.403    -0.4019  \n",
       "4        0.000     0.0000  \n",
       "...        ...        ...  \n",
       "3389     0.000     0.0000  \n",
       "3390     0.000     0.8402  \n",
       "3391     0.000     0.0000  \n",
       "3392     0.000     0.0000  \n",
       "3393     0.000     0.0000  \n",
       "\n",
       "[3394 rows x 7 columns]"
      ]
     },
     "execution_count": 876,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comments\n",
    "# sentiment and symbols\n",
    "cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "# Hash Users IDs to anon them \n",
    "id_codes = {k: hash(k) for k in full_comments_final.id.unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "# Hash Users IDs to anon them \n",
    "id_regex = r\"|\".join([key for key in id_codes.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "def new_string(string):\n",
    "    regs = re.findall(id_regex, string)\n",
    "    if regs != []:\n",
    "        for r in regs:\n",
    "            string = string.replace(r, str(hash(r)))\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "# Replace Mentions Column and Chat Content to Conform to new Codes\n",
    "full_comments_final = full_comments.assign(content = lambda x: x.content.apply(lambda s: new_string(s))).assign(mentions=lambda x: x.mentions.apply(lambda s: new_string(s)))\\\n",
    "    .assign(id=lambda x: x.id.apply(lambda s: new_string(s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "full_comments_final = full_comments_final.drop(['more_symbols', 'last_symbols'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "full_comments_final = full_comments_final.drop(['cc_comment'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "full_comments_final = full_comments_final.drop(['pk'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>channel</th>\n",
       "      <th>id</th>\n",
       "      <th>server</th>\n",
       "      <th>content</th>\n",
       "      <th>isBot</th>\n",
       "      <th>mentions</th>\n",
       "      <th>emojis</th>\n",
       "      <th>links</th>\n",
       "      <th>chat_emotes</th>\n",
       "      <th>pos_sent</th>\n",
       "      <th>neg_sent</th>\n",
       "      <th>neu_sent</th>\n",
       "      <th>comp_sent</th>\n",
       "      <th>symbols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>2019-08-02 01:10:52.637000+00:00</td>\n",
       "      <td>wetlqd-ideas</td>\n",
       "      <td>1767074690797870795</td>\n",
       "      <td>Misc</td>\n",
       "      <td>Play account today</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.3400</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>2019-08-02 01:13:47.923000+00:00</td>\n",
       "      <td>wetlqd-ideas</td>\n",
       "      <td>1767074690797870795</td>\n",
       "      <td>Misc</td>\n",
       "      <td>@everyone today’s total. This doesn’t calculat...</td>\n",
       "      <td>0</td>\n",
       "      <td>everyone</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.4404</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>2019-08-02 01:14:35.798000+00:00</td>\n",
       "      <td>wetlqd-ideas</td>\n",
       "      <td>9165658630182813742</td>\n",
       "      <td>Misc</td>\n",
       "      <td>Crack</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>2019-08-02 01:14:39.682000+00:00</td>\n",
       "      <td>wetlqd-ideas</td>\n",
       "      <td>9165658630182813742</td>\n",
       "      <td>Misc</td>\n",
       "      <td>Big crack</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>2019-08-02 01:14:44.367000+00:00</td>\n",
       "      <td>wetlqd-ideas</td>\n",
       "      <td>9165658630182813742</td>\n",
       "      <td>Misc</td>\n",
       "      <td>Heroin</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.4939</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31929</th>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>2020-12-08 20:38:45.351000+00:00</td>\n",
       "      <td>trading</td>\n",
       "      <td>-4958649595996145486</td>\n",
       "      <td>LSV</td>\n",
       "      <td>&lt;@!7285578842926376802&gt; all of my shorter vide...</td>\n",
       "      <td>0</td>\n",
       "      <td>7285578842926376802</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.3400</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31930</th>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>2020-12-08 20:39:17.246000+00:00</td>\n",
       "      <td>trading</td>\n",
       "      <td>-3368183788766211362</td>\n",
       "      <td>LSV</td>\n",
       "      <td>&lt;@-4958649595996145486&gt; have you done a video ...</td>\n",
       "      <td>0</td>\n",
       "      <td>-4958649595996145486</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.2500</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31931</th>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>2020-12-08 20:39:32.831000+00:00</td>\n",
       "      <td>trading</td>\n",
       "      <td>-4958649595996145486</td>\n",
       "      <td>LSV</td>\n",
       "      <td>&lt;@!-3368183788766211362&gt; nope, not yet</td>\n",
       "      <td>0</td>\n",
       "      <td>-3368183788766211362</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31932</th>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>2020-12-08 20:39:38.597000+00:00</td>\n",
       "      <td>trading</td>\n",
       "      <td>-4958649595996145486</td>\n",
       "      <td>LSV</td>\n",
       "      <td>they're the airline wifi company right?</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31933</th>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>2020-12-08 20:41:38.298000+00:00</td>\n",
       "      <td>options</td>\n",
       "      <td>3578456118343029471</td>\n",
       "      <td>LSV</td>\n",
       "      <td>CRM ??</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>CRM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31934 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                        timestamp       channel  \\\n",
       "0     2019-08-02 2019-08-02 01:10:52.637000+00:00  wetlqd-ideas   \n",
       "1     2019-08-02 2019-08-02 01:13:47.923000+00:00  wetlqd-ideas   \n",
       "2     2019-08-02 2019-08-02 01:14:35.798000+00:00  wetlqd-ideas   \n",
       "3     2019-08-02 2019-08-02 01:14:39.682000+00:00  wetlqd-ideas   \n",
       "4     2019-08-02 2019-08-02 01:14:44.367000+00:00  wetlqd-ideas   \n",
       "...          ...                              ...           ...   \n",
       "31929 2020-12-08 2020-12-08 20:38:45.351000+00:00       trading   \n",
       "31930 2020-12-08 2020-12-08 20:39:17.246000+00:00       trading   \n",
       "31931 2020-12-08 2020-12-08 20:39:32.831000+00:00       trading   \n",
       "31932 2020-12-08 2020-12-08 20:39:38.597000+00:00       trading   \n",
       "31933 2020-12-08 2020-12-08 20:41:38.298000+00:00       options   \n",
       "\n",
       "                         id server  \\\n",
       "0       1767074690797870795   Misc   \n",
       "1       1767074690797870795   Misc   \n",
       "2       9165658630182813742   Misc   \n",
       "3       9165658630182813742   Misc   \n",
       "4       9165658630182813742   Misc   \n",
       "...                     ...    ...   \n",
       "31929  -4958649595996145486    LSV   \n",
       "31930  -3368183788766211362    LSV   \n",
       "31931  -4958649595996145486    LSV   \n",
       "31932  -4958649595996145486    LSV   \n",
       "31933   3578456118343029471    LSV   \n",
       "\n",
       "                                                 content  isBot  \\\n",
       "0                                     Play account today      0   \n",
       "1      @everyone today’s total. This doesn’t calculat...      0   \n",
       "2                                                  Crack      0   \n",
       "3                                              Big crack      0   \n",
       "4                                                 Heroin      0   \n",
       "...                                                  ...    ...   \n",
       "31929  <@!7285578842926376802> all of my shorter vide...      0   \n",
       "31930  <@-4958649595996145486> have you done a video ...      0   \n",
       "31931             <@!-3368183788766211362> nope, not yet      0   \n",
       "31932            they're the airline wifi company right?      0   \n",
       "31933                                             CRM ??      0   \n",
       "\n",
       "                   mentions emojis links chat_emotes  pos_sent  neg_sent  \\\n",
       "0                                                        0.545       0.0   \n",
       "1                  everyone                              0.153       0.0   \n",
       "2                                                        0.000       0.0   \n",
       "3                                                        0.000       0.0   \n",
       "4                                                        0.000       1.0   \n",
       "...                     ...    ...   ...         ...       ...       ...   \n",
       "31929   7285578842926376802                              0.082       0.0   \n",
       "31930  -4958649595996145486                              0.182       0.0   \n",
       "31931  -3368183788766211362                              0.000       0.0   \n",
       "31932                                                    0.000       0.0   \n",
       "31933                                                    0.000       0.0   \n",
       "\n",
       "       neu_sent  comp_sent symbols  \n",
       "0         0.455     0.3400          \n",
       "1         0.847     0.4404          \n",
       "2         1.000     0.0000          \n",
       "3         1.000     0.0000          \n",
       "4         0.000    -0.4939          \n",
       "...         ...        ...     ...  \n",
       "31929     0.918     0.3400          \n",
       "31930     0.818     0.2500          \n",
       "31931     1.000     0.0000          \n",
       "31932     1.000     0.0000          \n",
       "31933     1.000     0.0000     CRM  \n",
       "\n",
       "[31934 rows x 16 columns]"
      ]
     },
     "execution_count": 926,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comments\n",
    "full_comments_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>channel</th>\n",
       "      <th>symbols</th>\n",
       "      <th>pos_sent</th>\n",
       "      <th>neg_sent</th>\n",
       "      <th>neu_sent</th>\n",
       "      <th>comp_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>wetlqd-ideas</td>\n",
       "      <td></td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>wetlqd-ideas</td>\n",
       "      <td></td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.4404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>wetlqd-ideas</td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>wetlqd-ideas</td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>wetlqd-ideas</td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.4939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31929</th>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>trading</td>\n",
       "      <td></td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31930</th>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>trading</td>\n",
       "      <td></td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31931</th>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>trading</td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31932</th>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>trading</td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31933</th>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>options</td>\n",
       "      <td>CRM</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31934 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date       channel symbols  pos_sent  neg_sent  neu_sent  \\\n",
       "0     2019-08-02  wetlqd-ideas             0.545       0.0     0.455   \n",
       "1     2019-08-02  wetlqd-ideas             0.153       0.0     0.847   \n",
       "2     2019-08-02  wetlqd-ideas             0.000       0.0     1.000   \n",
       "3     2019-08-02  wetlqd-ideas             0.000       0.0     1.000   \n",
       "4     2019-08-02  wetlqd-ideas             0.000       1.0     0.000   \n",
       "...          ...           ...     ...       ...       ...       ...   \n",
       "31929 2020-12-08       trading             0.082       0.0     0.918   \n",
       "31930 2020-12-08       trading             0.182       0.0     0.818   \n",
       "31931 2020-12-08       trading             0.000       0.0     1.000   \n",
       "31932 2020-12-08       trading             0.000       0.0     1.000   \n",
       "31933 2020-12-08       options     CRM     0.000       0.0     1.000   \n",
       "\n",
       "       comp_sent  \n",
       "0         0.3400  \n",
       "1         0.4404  \n",
       "2         0.0000  \n",
       "3         0.0000  \n",
       "4        -0.4939  \n",
       "...          ...  \n",
       "31929     0.3400  \n",
       "31930     0.2500  \n",
       "31931     0.0000  \n",
       "31932     0.0000  \n",
       "31933     0.0000  \n",
       "\n",
       "[31934 rows x 7 columns]"
      ]
     },
     "execution_count": 927,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comments\n",
    "full_comments_final.loc[:, ['date', 'channel', 'symbols', 'pos_sent', 'neg_sent', 'neu_sent', 'comp_sent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "with sql.connect('../data/interim/companies.db') as con:\n",
    "    full_comments_final.loc[:, ['date', 'channel', 'symbols', 'pos_sent', 'neg_sent', 'neu_sent', 'comp_sent']][lambda x: x.symbols != '']\\\n",
    "        .to_sql('symbol_comments', con=con, index_label='pk', if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "with sql.connect('../data/interim/discord/discord.db') as con:\n",
    "    full_comments_final.to_sql('comments', con=con, index_label='pk', if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5231923759791198"
      ]
     },
     "execution_count": 934,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# News Articles\n",
    "# NLP\n",
    "# Average Combined Sentiment\n",
    "wordy_df_news.comp_sent.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crpyt.db = [\"pk\", \"article\", 'headline', \"comments\", \"date\", 'link', 'symbol', 'publisher', 'pos_sent', 'neg_sent', 'neu_sent', 'comp_sent']\n",
    "# in bytes\n",
    "# articles table = ['pk', 'id', 'title', 'link', 'date', 'publisher', 'symbol', 'article', 'pos_sent', neg_sent', 'neu_sent', 'comp_sent']\n",
    "# news_sentiment of encrypted articles = ['index', 'symbol', 'publisher', 'pos_sent', 'neu_sent', 'neg_sent', 'comp_sent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {},
   "outputs": [],
   "source": [
    "# News Articles\n",
    "# NLP\n",
    "wordy_df_news = wordy_df_news.drop('pk', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [],
   "source": [
    "# News Articles\n",
    "wordy_df_news = wordy_df_news.assign(word_obj = lambda x: x.word_obj.apply(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "metadata": {},
   "outputs": [],
   "source": [
    "# News Articles\n",
    "with sql.connect('../data/raw/temp2.db') as con:\n",
    "    wordy_df_news.to_sql('full_articles', con=con, index=True, index_label='pk', if_exists='fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the Data\n",
    "# Revised Tables\n",
    "with sql.connect('../data/interim/companies.db') as con:\n",
    "    a_articles = pd.read_sql('SELECT * FROM articles', con=con) # \n",
    "    a_info  = pd.read_sql('SELECT * FROM info', con=con) ##\n",
    "    a_news_sentiment = pd.read_sql('SELECT * FROM news_sentiment', con=con) #\n",
    "    a_symbol_comments = pd.read_sql('SELECT * FROM symbol_comments', con=con) ##\n",
    "    a_daily = pd.read_sql('SELECT * FROM daily', con=con) ##\n",
    "    a_mentions = pd.read_sql('SELECT * FROM mentions', con=con)\n",
    "    a_recommendations = pd.read_sql('SELECT * FROM recommendations', con=con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Financial Data\n",
    "a_daily = a_daily.assign(Date = lambda x: x.Date.apply(pd.to_datetime)).drop('pk', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyst Recommendations\n",
    "a_recommendations = a_recommendations.assign(Date = lambda x: x.Date.apply(pd.to_datetime)).drop('pk', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pk</th>\n",
       "      <th>symbol</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SPY</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NIO</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AMD</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329</th>\n",
       "      <td>2329</td>\n",
       "      <td>NDS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330</th>\n",
       "      <td>2330</td>\n",
       "      <td>FRIE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2331</th>\n",
       "      <td>2331</td>\n",
       "      <td>SAID</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332</th>\n",
       "      <td>2332</td>\n",
       "      <td>BEIN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2333</th>\n",
       "      <td>2333</td>\n",
       "      <td>EDIT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2334 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        pk symbol  counts\n",
       "0        0    SPY     167\n",
       "1        1   TSLA     166\n",
       "2        2    NIO     151\n",
       "3        3    AMD     133\n",
       "4        4   AAPL     114\n",
       "...    ...    ...     ...\n",
       "2329  2329    NDS       1\n",
       "2330  2330   FRIE       1\n",
       "2331  2331   SAID       1\n",
       "2332  2332   BEIN       1\n",
       "2333  2333   EDIT       1\n",
       "\n",
       "[2334 rows x 3 columns]"
      ]
     },
     "execution_count": 993,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comments\n",
    "a_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 72 entries, 0 to 71\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   symbol    72 non-null     object\n",
      " 1   counts_x  72 non-null     int64 \n",
      " 2   counts_y  72 non-null     int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 2.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Comments\n",
    "# Company Counts\n",
    "mentions.merge(new_mentions.assign(symbol=lambda x: x.symbol.apply(str.upper)), 'left', on='symbol').info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "# Company Counts\n",
    "new_mentions = new_mentions.assign(symbol=lambda x: x.symbol.apply(str.upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>headline</th>\n",
       "      <th>comments</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>symbol</th>\n",
       "      <th>publisher</th>\n",
       "      <th>pos_sent</th>\n",
       "      <th>neg_sent</th>\n",
       "      <th>neu_sent</th>\n",
       "      <th>comp_sent</th>\n",
       "      <th>sa</th>\n",
       "      <th>word_obj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4084</th>\n",
       "      <td>b'A University of Florida economist known as  ...</td>\n",
       "      <td>Mr. IPO says biopharma IPOs prices arent r...</td>\n",
       "      <td>14</td>\n",
       "      <td>2021-01-27</td>\n",
       "      <td>https://seekingalpha.com/news/3655139-mr-ipo-s...</td>\n",
       "      <td>FB</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.9906</td>\n",
       "      <td>1</td>\n",
       "      <td>{'tech': 7, 'ritter': 7, 'ipo': 6, 'nasdaq': 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7070</th>\n",
       "      <td>b'A University of Florida economist known as \\...</td>\n",
       "      <td>âMr. IPOâ says biopharma IPOs prices arenâ...</td>\n",
       "      <td>14</td>\n",
       "      <td>2021-01-27</td>\n",
       "      <td>https://seekingalpha.com/news/3655139-mr-ipo-s...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.9874</td>\n",
       "      <td>1</td>\n",
       "      <td>{'tech': 7, 'â\\x80\\x9d': 6, 'nasdaq': 6, 'ipos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10672</th>\n",
       "      <td>b'A University of Florida economist known as  ...</td>\n",
       "      <td>Mr. IPO says biopharma IPOs prices arent r...</td>\n",
       "      <td>14</td>\n",
       "      <td>2021-01-27</td>\n",
       "      <td>https://seekingalpha.com/news/3655139-mr-ipo-s...</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.9906</td>\n",
       "      <td>1</td>\n",
       "      <td>{'tech': 7, 'ritter': 7, 'ipo': 6, 'nasdaq': 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13186</th>\n",
       "      <td>b'A University of Florida economist known as  ...</td>\n",
       "      <td>Mr. IPO says biopharma IPOs prices arent r...</td>\n",
       "      <td>14</td>\n",
       "      <td>2021-01-27</td>\n",
       "      <td>https://seekingalpha.com/news/3655139-mr-ipo-s...</td>\n",
       "      <td>ZM</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.9906</td>\n",
       "      <td>1</td>\n",
       "      <td>{'tech': 7, 'ritter': 7, 'ipo': 6, 'nasdaq': 6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 article  \\\n",
       "4084   b'A University of Florida economist known as  ...   \n",
       "7070   b'A University of Florida economist known as \\...   \n",
       "10672  b'A University of Florida economist known as  ...   \n",
       "13186  b'A University of Florida economist known as  ...   \n",
       "\n",
       "                                                headline comments       date  \\\n",
       "4084   Mr. IPO says biopharma IPOs prices arent r...      14  2021-01-27   \n",
       "7070   âMr. IPOâ says biopharma IPOs prices arenâ...      14  2021-01-27   \n",
       "10672  Mr. IPO says biopharma IPOs prices arent r...      14  2021-01-27   \n",
       "13186  Mr. IPO says biopharma IPOs prices arent r...      14  2021-01-27   \n",
       "\n",
       "                                                    link symbol  \\\n",
       "4084   https://seekingalpha.com/news/3655139-mr-ipo-s...     FB   \n",
       "7070   https://seekingalpha.com/news/3655139-mr-ipo-s...   AAPL   \n",
       "10672  https://seekingalpha.com/news/3655139-mr-ipo-s...   MSFT   \n",
       "13186  https://seekingalpha.com/news/3655139-mr-ipo-s...     ZM   \n",
       "\n",
       "           publisher  pos_sent  neg_sent  neu_sent  comp_sent  sa  \\\n",
       "4084   Seeking Alpha     0.102     0.011     0.887     0.9906   1   \n",
       "7070   Seeking Alpha     0.088     0.011     0.901     0.9874   1   \n",
       "10672  Seeking Alpha     0.102     0.011     0.887     0.9906   1   \n",
       "13186  Seeking Alpha     0.102     0.011     0.887     0.9906   1   \n",
       "\n",
       "                                                word_obj  \n",
       "4084   {'tech': 7, 'ritter': 7, 'ipo': 6, 'nasdaq': 6...  \n",
       "7070   {'tech': 7, 'â\\x80\\x9d': 6, 'nasdaq': 6, 'ipos...  \n",
       "10672  {'tech': 7, 'ritter': 7, 'ipo': 6, 'nasdaq': 6...  \n",
       "13186  {'tech': 7, 'ritter': 7, 'ipo': 6, 'nasdaq': 6...  "
      ]
     },
     "execution_count": 1025,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# News Articles\n",
    "wordy_df_news.assign(article=lambda x: x.article.apply(bytes, encoding='utf-8').apply(cryptor.encrypt).apply(cryptor.decrypt).apply(str))[lambda x: x.article.str.contains('Mr. IPO')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kyle\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2612: UserWarning: The spaces in these column names will not be changed. In pandas versions < 0.14, spaces were converted to underscores.\n",
      "  method=method,\n"
     ]
    }
   ],
   "source": [
    "# Save New Tables\n",
    "with sql.connect('../data/interim/temp_c.db') as con:\n",
    "    a_info.drop(['pk', 'holdings'], axis=1).to_sql('info', index=True, index_label='pk', con=con)\n",
    "    wordy_df_news.loc[:, ['pos_sent', 'neu_sent', 'neg_sent', 'comp_sent']].to_sql('news_sentiment', con=con, index=True, index_label='pk')\n",
    "    wordy_df_news.drop(['pos_sent', 'neg_sent', 'neu_sent', 'comp_sent', 'article'], axis=1).to_sql('articles', con=con, index=True, index_label='pk')\n",
    "    full_comments_final.loc[:, ['date', 'channel', 'server','symbols', 'pos_sent', 'neg_sent', 'neu_sent', 'comp_sent']][lambda x: x.symbols != ''].\\\n",
    "        reset_index().rename(columns={'index': 'comment_pk'}).to_sql('symbol_comments', con=con, index=True, index_label='pk')\n",
    "    a_daily.to_sql('daily', con=con, index=True, index_label='pk')\n",
    "    a_recommendations.to_sql('recommendations', con=con, index=True, index_label='pk')\n",
    "    new_mentions.to_sql('mentions', con=con, index=True, index_label='pk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# News Articles\n",
    "with sql.connect('../data/processed/temp_c.db') as con:\n",
    "    wordy_df_news = pd.read_sql('SELECT * FROM articles', con=con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# News Articles\n",
    "wordy_df_news = wordy_df_news.assign(comments = lambda x: x.comments.apply(float)).fillna(0).assign(comments=lambda x: x.comments.apply(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# News Articles\n",
    "with sql.connect('../data/processed/temp_c.db') as con:\n",
    "    wordy_df_news.to_sql('articles', con=con, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# News Articles\n",
    "wordy_df_news = wordy_df_news.assign(date = lambda x: x.date.apply(pd.to_datetime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">comments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-06-30</th>\n",
       "      <th>AAL</th>\n",
       "      <td>63</td>\n",
       "      <td>1821</td>\n",
       "      <td>28.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-31</th>\n",
       "      <th>AAL</th>\n",
       "      <td>79</td>\n",
       "      <td>1263</td>\n",
       "      <td>15.987342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-31</th>\n",
       "      <th>AAL</th>\n",
       "      <td>64</td>\n",
       "      <td>1494</td>\n",
       "      <td>23.343750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-30</th>\n",
       "      <th>AAL</th>\n",
       "      <td>59</td>\n",
       "      <td>726</td>\n",
       "      <td>12.305085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-31</th>\n",
       "      <th>AAL</th>\n",
       "      <td>78</td>\n",
       "      <td>2067</td>\n",
       "      <td>26.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-28</th>\n",
       "      <th>ZM</th>\n",
       "      <td>12</td>\n",
       "      <td>121</td>\n",
       "      <td>10.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-31</th>\n",
       "      <th>ZM</th>\n",
       "      <td>35</td>\n",
       "      <td>803</td>\n",
       "      <td>22.942857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-30</th>\n",
       "      <th>ZM</th>\n",
       "      <td>12</td>\n",
       "      <td>77</td>\n",
       "      <td>6.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-31</th>\n",
       "      <th>ZM</th>\n",
       "      <td>11</td>\n",
       "      <td>707</td>\n",
       "      <td>64.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-30</th>\n",
       "      <th>ZM</th>\n",
       "      <td>31</td>\n",
       "      <td>104</td>\n",
       "      <td>3.354839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>920 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  comments                 \n",
       "                     count   sum       mean\n",
       "date       symbol                          \n",
       "2020-06-30 AAL          63  1821  28.904762\n",
       "2020-07-31 AAL          79  1263  15.987342\n",
       "2020-08-31 AAL          64  1494  23.343750\n",
       "2020-09-30 AAL          59   726  12.305085\n",
       "2020-10-31 AAL          78  2067  26.500000\n",
       "...                    ...   ...        ...\n",
       "2021-02-28 ZM           12   121  10.083333\n",
       "2021-03-31 ZM           35   803  22.942857\n",
       "2021-04-30 ZM           12    77   6.416667\n",
       "2021-05-31 ZM           11   707  64.272727\n",
       "2021-06-30 ZM           31   104   3.354839\n",
       "\n",
       "[920 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# News Articles\n",
    "wordy_df_news[lambda x: ((x.date > dt.datetime(2020, 5, 31))&(x.date <= dt.datetime(2021, 6, 30)))].groupby([pd.Grouper(key='date', freq='1M'), 'symbol']).agg({'comments': ['count', 'sum', 'mean']}).sort_index(level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "def clean_comment(comment):\n",
    "    userIdCatcher = r\"(<@(!)?\\d+>|@everyone)\"\n",
    "    discord_emote_regex = r\"<.+>\"\n",
    "    url_regex = r\"https*\\:.+|www\\..+\"\n",
    "    punc_regex = r\"[\\’\\'\\'\\\"\\\"\\“\\”!\\?@#$%&\\(\\)\\*,-.\\\\\\{\\}+~\\/:;<>\\[\\]^`|=_’]\"\n",
    "    contract_regex = r\"[\\'\\’\\’]\"\n",
    "    comment = re.sub(\"|\".join([x for x in [userIdCatcher, discord_emote_regex, url_regex]]), \"\", comment)\n",
    "    comment = re.sub(contract_regex, \"\", comment)\n",
    "    comment = re.sub(punc_regex, \" \", comment)\n",
    "    comment = comment.replace(\"\\n\", \" \").replace(\"'s\", \"\")\n",
    "    return \" \" + comment + \" \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "# NLP\n",
    "def wordCount(comment_array, pos):\n",
    "    comment_dictionary = {}\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words = stop_words.union({'said', 'us', 'also', 'inc', 'could', 'word', 'b', 'q', 'https', 'com', 'lol', 'k', 'ta', 'thanks'})\n",
    "    for comment in comment_array:\n",
    "        punc_regex = r\"[\\，\\’\\'\\'\\\"\\\"\\“\\”!\\?@#$%&\\(\\)\\*,-.\\\\\\{\\}+~\\/:;<>\\[\\]^`|=_]\"\n",
    "        reg_bad_quotes = re.compile(u\"[\\x94\\x93\\x92\\x91]\")\n",
    "        comment = comment.lower()\n",
    "        comment = re.sub(punc_regex, \" \", comment)\n",
    "        comment = re.sub(reg_bad_quotes, \" \", comment)\n",
    "        comment = re.sub(r\"[0-9]\", \"\", comment)\n",
    "        words = word_tokenize(comment)\n",
    "        tags = pos_tag(words)\n",
    "        for w, po in tags:\n",
    "            if (w in comment_dictionary.keys()) & (w not in stop_words) & (po.startswith(pos)):\n",
    "                comment_dictionary[w] += 1\n",
    "            elif (w not in stop_words) & (pos.startswith(pos)):\n",
    "                comment_dictionary[w] = 1\n",
    "    \n",
    "    comments_words = dict(sorted(comment_dictionary.items(), key=lambda x: x[1], reverse=True))\n",
    "    # comment_list.append(comments_words)\n",
    "\n",
    "    # df = df.assign(word_obj = pd.Series(comment_list))\n",
    "    return pd.Series(comments_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "con = sql.connect('../data/processed/discord.db')\n",
    "comments = pd.read_sql('select content, DATE(timestamp) date, comp_sent from comments', con=con, parse_dates={'timestamp': '%Y-%m-%d'})\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "# Gathering the Nouns and Verbs \n",
    "comment_nouns = wordCount(comments.content, 'N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "comment_verbs = wordCount(comments.content, 'V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "day          1024\n",
       "today         782\n",
       "week          712\n",
       "time          652\n",
       "market        639\n",
       "stock         582\n",
       "tomorrow      550\n",
       "money         525\n",
       "stocks        445\n",
       "shares        374\n",
       "news          373\n",
       "earnings      351\n",
       "people        335\n",
       "everyone      332\n",
       "options       324\n",
       "anyone        311\n",
       "term          303\n",
       "gains         301\n",
       "price         299\n",
       "lot           298\n",
       "days          282\n",
       "way           261\n",
       "profits       255\n",
       "man           251\n",
       "futures       208\n",
       "morning       207\n",
       "cash          195\n",
       "year          191\n",
       "something     181\n",
       "company       178\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comments\n",
    "comment_nouns.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "going      618\n",
       "sold       403\n",
       "looking    400\n",
       "made       282\n",
       "getting    219\n",
       "took       194\n",
       "went       165\n",
       "goes       164\n",
       "trimmed    155\n",
       "trying     151\n",
       "done       147\n",
       "reached    135\n",
       "know       126\n",
       "seems      121\n",
       "using      108\n",
       "called      92\n",
       "makes       86\n",
       "seen        83\n",
       "saying      79\n",
       "posted      78\n",
       "keeping     75\n",
       "gets        74\n",
       "talking     72\n",
       "seeing      67\n",
       "based       65\n",
       "wanted      58\n",
       "make        57\n",
       "came        57\n",
       "wants       54\n",
       "says        53\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comments\n",
    "comment_verbs.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "# Breakdown of Tokens by Comment Overall Sentiment \n",
    "comment_nouns_pos = wordCount(comments[lambda x: x.comp_sent > 0].content, 'N')\n",
    "comment_verbs_pos = wordCount(comments[lambda x: x.comp_sent > 0].content, 'V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "# Breakdown of Tokens by Negative Comments\n",
    "comment_nouns_neg = wordCount(comments[lambda x: x.comp_sent < 0].content, 'N')\n",
    "comment_verbs_neg = wordCount(comments[lambda x: x.comp_sent < 0].content, 'V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "going       252\n",
       "looking     230\n",
       "know        197\n",
       "sold        166\n",
       "made        153\n",
       "reached     132\n",
       "took        122\n",
       "holding     109\n",
       "getting      85\n",
       "got          83\n",
       "seems        77\n",
       "trying       73\n",
       "goes         72\n",
       "went         71\n",
       "done         66\n",
       "using        55\n",
       "make         50\n",
       "trimmed      50\n",
       "come         47\n",
       "started      44\n",
       "held         42\n",
       "seeing       41\n",
       "waiting      40\n",
       "remember     39\n",
       "called       38\n",
       "makes        38\n",
       "used         37\n",
       "based        37\n",
       "talking      35\n",
       "want         33\n",
       "saying       33\n",
       "posted       32\n",
       "playing      32\n",
       "gets         31\n",
       "played       31\n",
       "learned      30\n",
       "wanted       29\n",
       "moving       29\n",
       "found        28\n",
       "came         27\n",
       "says         26\n",
       "looked       26\n",
       "running      25\n",
       "watching     24\n",
       "gave         24\n",
       "keeping      24\n",
       "seen         24\n",
       "alerted      23\n",
       "take         23\n",
       "wants        23\n",
       "dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comments\n",
    "comment_verbs_pos.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "day           148\n",
       "market        136\n",
       "today         135\n",
       "time          122\n",
       "money         111\n",
       "people        111\n",
       "week          101\n",
       "stock          91\n",
       "tomorrow       83\n",
       "loss           78\n",
       "stocks         72\n",
       "news           69\n",
       "lot            60\n",
       "way            58\n",
       "term           58\n",
       "price          54\n",
       "earnings       52\n",
       "losses         45\n",
       "options        41\n",
       "man            39\n",
       "days           38\n",
       "morning        36\n",
       "something      36\n",
       "idea           35\n",
       "cap            35\n",
       "shares         34\n",
       "everyone       33\n",
       "bit            32\n",
       "risk           32\n",
       "year           31\n",
       "cash           31\n",
       "vix            31\n",
       "thing          30\n",
       "index          30\n",
       "company        29\n",
       "weeks          27\n",
       "position       27\n",
       "change         27\n",
       "futures        27\n",
       "election       27\n",
       "gains          26\n",
       "anything       26\n",
       "entry          25\n",
       "anyone         25\n",
       "apple          24\n",
       "reason         23\n",
       "investment     23\n",
       "someone        23\n",
       "volume         22\n",
       "strike         22\n",
       "dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comments\n",
    "comment_nouns_neg.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyst Recommendations \n",
    "con = sql.connect('../data/processed/temp_c.db')\n",
    "recommendations_sent = pd.read_sql(f\"SELECT DATE(Date) date, symbol, Firm, Action, new_grade, prev_grade FROM recommendations\", con=con, parse_dates={'month': '%Y-%m-%d'})\n",
    "port = pd.read_sql(\"SELECT DATE(Date) date, Open, Close, Volatility, symbol FROM daily WHERE symbol NOT IN ('IT', 'PT', 'ON', 'ING', 'VPU', 'VNQ', 'VAW', 'VGT', 'VIS', 'VHT', 'VFH', 'VDE', 'VDC', 'VCR', 'VOX')\", con=con, parse_dates={'date': '%Y-%m-%d'})\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyst Ratings\n",
    "ratings_parse = {'Very Bearish': 1, 'Bearish': 2, 'Neutral': 3, 'Bullish': 4, 'Very Bullish': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Financial Data\n",
    "# Calcualte Returns with Baseline Options (for S&P)\n",
    "def calc_r(series, data, base=False):\n",
    "    if base:\n",
    "        symb = 'SPY'\n",
    "    else:\n",
    "        symb = series['symbol']\n",
    "    d = data[lambda x: ((x.date >= series['date']) & (x.date <= dt.datetime(2022, 1, 31))&(x.symbol==symb))]\n",
    "    if d.empty:\n",
    "        return 0\n",
    "    else:\n",
    "        ret = (d.iloc[-1, 2] - d.iloc[0, 2]) / d.iloc[0, 2]\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyst Ratings\n",
    "analyst_returns_Series = recommendations_sent.loc[:, ['date', 'symbol']].apply(calc_r, data=port, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyst Ratings\n",
    "analyst_returns_Series.name = \"Returns_Post_Ratings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyst Ratings\n",
    "recommendations_sent = recommendations_sent.merge(analyst_returns_Series, left_index=True, right_index=True).assign(new_grade=lambda x: x.new_grade.apply(lambda d: ratings_parse[d])).assign(prev_grade=lambda x: x.prev_grade.apply(lambda d: ratings_parse[d]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyst Ratings\n",
    "# Financial Data\n",
    "spy_returns_Series = recommendations_sent.loc[:, ['date', 'symbol']].apply(calc_r, data=port, base=True,axis=1)\n",
    "spy_returns_Series.name = 'Market_Returns'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyst Ratings\n",
    "\n",
    "recommendations_sent = recommendations_sent.merge(spy_returns_Series, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyst Ratings\n",
    "\n",
    "recommendations_sent = recommendations_sent.assign(date=lambda x: x.date.apply(pd.to_datetime))\n",
    "recommendations_sent.merge(analyst_returns_Series, left_index=True, right_index=True)\n",
    "recs = recommendations_sent[lambda x: x.date >= dt.datetime(2017, 1, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyst Ratings\n",
    "# Creating a Valuation Mechanism to Evaluate Ratings vs. investing in the index fund on the same day of the ratings\n",
    "# gives credit for high ratings matching higher returns since a given rating date\n",
    "recs = recs.assign(g = lambda x: x.new_grade * x.Returns_Post_Ratings).assign(alpha = lambda x: x.Returns_Post_Ratings-x.Market_Returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th>Firm</th>\n",
       "      <th>Action</th>\n",
       "      <th>new_grade</th>\n",
       "      <th>prev_grade</th>\n",
       "      <th>Returns_Post_Ratings</th>\n",
       "      <th>Market_Returns</th>\n",
       "      <th>g</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2017-01-19</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>Morgan Stanley</td>\n",
       "      <td>up</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>13.474688</td>\n",
       "      <td>0.784487</td>\n",
       "      <td>53.898753</td>\n",
       "      <td>12.690201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2017-02-23</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>RBC Capital</td>\n",
       "      <td>main</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>12.783155</td>\n",
       "      <td>0.705014</td>\n",
       "      <td>38.349464</td>\n",
       "      <td>12.078141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2017-02-27</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>Goldman Sachs</td>\n",
       "      <td>down</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13.329489</td>\n",
       "      <td>0.700196</td>\n",
       "      <td>13.329489</td>\n",
       "      <td>12.629293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2017-03-08</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>Bernstein</td>\n",
       "      <td>init</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>13.292340</td>\n",
       "      <td>0.704149</td>\n",
       "      <td>39.877019</td>\n",
       "      <td>12.588191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>2017-03-20</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>main</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>12.471098</td>\n",
       "      <td>0.695262</td>\n",
       "      <td>37.413294</td>\n",
       "      <td>11.775836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9363</th>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>VLDR</td>\n",
       "      <td>Needham</td>\n",
       "      <td>main</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9364</th>\n",
       "      <td>2021-07-20</td>\n",
       "      <td>VLDR</td>\n",
       "      <td>Baird</td>\n",
       "      <td>down</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9365</th>\n",
       "      <td>2021-08-06</td>\n",
       "      <td>VLDR</td>\n",
       "      <td>Needham</td>\n",
       "      <td>main</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9366</th>\n",
       "      <td>2021-11-05</td>\n",
       "      <td>VLDR</td>\n",
       "      <td>Needham</td>\n",
       "      <td>main</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9367</th>\n",
       "      <td>2021-11-09</td>\n",
       "      <td>VLDR</td>\n",
       "      <td>Citigroup</td>\n",
       "      <td>down</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5924 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date symbol            Firm Action  new_grade  prev_grade  \\\n",
       "127  2017-01-19   TSLA  Morgan Stanley     up          4           3   \n",
       "128  2017-02-23   TSLA     RBC Capital   main          3           3   \n",
       "129  2017-02-27   TSLA   Goldman Sachs   down          1           3   \n",
       "130  2017-03-08   TSLA       Bernstein   init          3           3   \n",
       "131  2017-03-20   TSLA   Deutsche Bank   main          3           3   \n",
       "...         ...    ...             ...    ...        ...         ...   \n",
       "9363 2021-05-11   VLDR         Needham   main          5           5   \n",
       "9364 2021-07-20   VLDR           Baird   down          3           4   \n",
       "9365 2021-08-06   VLDR         Needham   main          5           5   \n",
       "9366 2021-11-05   VLDR         Needham   main          5           5   \n",
       "9367 2021-11-09   VLDR       Citigroup   down          3           5   \n",
       "\n",
       "      Returns_Post_Ratings  Market_Returns          g      alpha  \n",
       "127              13.474688        0.784487  53.898753  12.690201  \n",
       "128              12.783155        0.705014  38.349464  12.078141  \n",
       "129              13.329489        0.700196  13.329489  12.629293  \n",
       "130              13.292340        0.704149  39.877019  12.588191  \n",
       "131              12.471098        0.695262  37.413294  11.775836  \n",
       "...                    ...             ...        ...        ...  \n",
       "9363              0.000000        0.000000   0.000000   0.000000  \n",
       "9364              0.000000        0.000000   0.000000   0.000000  \n",
       "9365              0.000000        0.000000   0.000000   0.000000  \n",
       "9366              0.000000        0.000000   0.000000   0.000000  \n",
       "9367              0.000000        0.000000   0.000000   0.000000  \n",
       "\n",
       "[5924 rows x 10 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyst Ratings\n",
    "recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyst Ratings\n",
    "analyst_returns_Series_21 = recommendations_sent.loc[:, ['date', 'symbol']].apply(calc_r, data=port, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyst Ratings\n",
    "analyst_returns_Series_21.name = 'Returns_Jan_2022'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyst Ratings\n",
    "# Financial Data\n",
    "spy_returns_Series_22 = recommendations_sent.loc[:, ['date', 'symbol']].apply(calc_r, data=port, base=True, axis=1)\n",
    "spy_returns_Series_22.name = 'Market_Returns_22'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyst Ratings\n",
    "# Merge it All Together\n",
    "recs = recs.merge(analyst_returns_Series_21, left_index=True, right_index=True)\\\n",
    "    .merge(spy_returns_Series_22, left_index=True, right_index=True).assign(g2 = lambda x: x.new_grade * x.Returns_Jan_2022).assign(alpha2 = lambda x: x.Returns_Jan_2022-x.Market_Returns_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "# NLP\n",
    "nouns = comment_nouns_pos.reset_index().rename(columns={0: 'positive_count', 'index': 'word'}).merge(comment_nouns_neg.reset_index().rename(columns={0: 'negative_count', 'index': 'word'}), on='word', how='outer').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "# NLP\n",
    "verbs = comment_verbs_pos.reset_index().rename(columns={0: 'positive_count', 'index': 'word'}).merge(comment_verbs_neg.reset_index().rename(columns={0: 'negative_count', 'index': 'word'}), on='word', how='outer').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "# NLP\n",
    "tokens = pd.concat([nouns.assign(total=lambda x: x.sum(axis=1)).assign(type=lambda x: 'noun'), verbs.assign(total=lambda x: x.sum(axis=1)).assign(type=lambda x: 'verb')], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "# NLP\n",
    "con=sql.connect('../data/processed/discord.db')\n",
    "tokens.to_sql('tokens', index=True, index_label='pk', con=con, if_exists='replace')\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyst Ratings\n",
    "con=sql.connect('../data/processed/temp_c.db')\n",
    "recs.to_sql('recsEvaluation', index=True, index_label='pk', con=con)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>positive_count</th>\n",
       "      <th>negative_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>day</td>\n",
       "      <td>1.0</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>market</td>\n",
       "      <td>1.0</td>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>today</td>\n",
       "      <td>1.0</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>time</td>\n",
       "      <td>1.0</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>people</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>money</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>week</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>stock</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>tomorrow</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1415</th>\n",
       "      <td>loss</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>stocks</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>news</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>lot</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>term</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>way</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>price</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>earnings</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>losses</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>options</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>man</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  positive_count  negative_count\n",
       "1102       day             1.0           148.0\n",
       "1113    market             1.0           136.0\n",
       "1086     today             1.0           135.0\n",
       "1172      time             1.0           122.0\n",
       "1297    people             1.0           111.0\n",
       "1131     money             1.0           111.0\n",
       "1099      week             1.0           101.0\n",
       "1262     stock             1.0            91.0\n",
       "1092  tomorrow             1.0            83.0\n",
       "1415      loss             1.0            78.0\n",
       "1769    stocks             1.0            72.0\n",
       "1283      news             1.0            69.0\n",
       "1201       lot             1.0            60.0\n",
       "1247      term             1.0            58.0\n",
       "1624       way             1.0            58.0\n",
       "1141     price             1.0            54.0\n",
       "1090  earnings             1.0            52.0\n",
       "1315    losses             1.0            45.0\n",
       "1330   options             1.0            41.0\n",
       "1095       man             1.0            39.0"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comments\n",
    "# NLP\n",
    "verbs.sort_values('negative_count', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>positive_count</th>\n",
       "      <th>negative_count</th>\n",
       "      <th>total</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>day</td>\n",
       "      <td>511.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>659.0</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>today</td>\n",
       "      <td>387.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>522.0</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>week</td>\n",
       "      <td>363.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shares</td>\n",
       "      <td>333.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>time</td>\n",
       "      <td>326.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21155</th>\n",
       "      <td>martha</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>verb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21156</th>\n",
       "      <td>chest</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>verb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21157</th>\n",
       "      <td>hoe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>verb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21158</th>\n",
       "      <td>wfh</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>verb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21159</th>\n",
       "      <td>starters</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>verb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21160 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  positive_count  negative_count  total  type\n",
       "0           day           511.0           148.0  659.0  noun\n",
       "1         today           387.0           135.0  522.0  noun\n",
       "2          week           363.0           101.0  464.0  noun\n",
       "3        shares           333.0            34.0  367.0  noun\n",
       "4          time           326.0           122.0  448.0  noun\n",
       "...         ...             ...             ...    ...   ...\n",
       "21155    martha             0.0             1.0    1.0  verb\n",
       "21156     chest             0.0             1.0    1.0  verb\n",
       "21157       hoe             0.0             1.0    1.0  verb\n",
       "21158       wfh             0.0             1.0    1.0  verb\n",
       "21159  starters             0.0             1.0    1.0  verb\n",
       "\n",
       "[21160 rows x 5 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comments\n",
    "# NLP\n",
    "# Tokens Table\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "# NLP\n",
    "verbs = comment_verbs_pos.reset_index().rename(columns={0: 'positive_count', 'index': 'word'})\\\n",
    "    .merge(comment_verbs_neg.reset_index().rename(columns={0: 'negative_count', 'index': 'word'}), on='word', how='outer').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "with sql.connect('../data/processed/discord.db') as con:\n",
    "    mentions = pd.read_sql('SELECT * FROM comments', con=con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "mentions = mentions.assign(cc_comment=lambda x: x.content.apply(clean_comment).apply(str.lower))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "full_comments = mentions.assign(more_symbols = lambda x: x.cc_comment.apply(nltk.tokenize.word_tokenize).apply(lambda z: list_to_symbols(z)).apply(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "# Add on BTC Comment Mentions for Previously Created Tables\n",
    "full_comments = full_comments[lambda x: x.more_symbols.str.contains('BTC')].loc[:, ['pk', 'date', 'channel', 'server', 'more_symbols', 'pos_sent', 'neg_sent', 'neu_sent', 'comp_sent']]\\\n",
    "    .assign(symbols= lambda x: x.more_symbols.apply(lambda s: re.sub(r'[\\[\\]\\'\\']', \"\", s)).apply(str.upper).apply(str.strip)).drop(['more_symbols'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "full_comments = full_comments.assign(symbols=lambda x: x.symbols.apply(str.split, sep=',').apply(lambda v: [a.strip() for a in v]).apply(set).apply(lambda j: ','.join(j)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "full_comments = full_comments.assign(date=lambda x: x.date.apply(pd.to_datetime)).rename(columns={'pk': 'comment_pk'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "fcc = full_comments.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "fcc.index = pd.RangeIndex(start=3852, stop=3852+134, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "full_comments = fcc.loc[:, ['comment_pk', 'date', 'channel', 'server', 'symbols', 'pos_sent', 'neg_sent', 'neu_sent','comp_sent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "btc_counts = {}\n",
    "for string in full_comments.symbols:\n",
    "    cs = string.split(',')\n",
    "    for c in cs:\n",
    "        if c in btc_counts.keys():\n",
    "            btc_counts[c]+= 1\n",
    "        else:\n",
    "            btc_counts[c] =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BTC-USD': 134, 'MARA': 8, 'SQ': 3, 'AMD': 1, 'SPY': 2, 'AAPL': 1, 'HEAR': 1}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comments\n",
    "btc_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "# Need to Add to Mention Count Tables and Symbol Comments Tables; Do not need to re-add other tickers b/c they would be counted twice\n",
    "con=sql.connect('../data/processed/temp_c.db')\n",
    "m = pd.read_sql('SELECT * FROM mentions', con=con)\n",
    "symc = pd.read_sql('SELECT * FROM symbol_comments', con=con)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "m = pd.concat([m.drop('pk', axis=1), pd.DataFrame({'symbol': ['BTC-USD'], 'counts': [134]})], axis=0, ignore_index=True).sort_values('counts', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "symc = pd.concat([symc.drop('pk', axis=1), full_comments], axis=0, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "symc=symc.assign(date=lambda x: x.date.apply(pd.to_datetime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to DB\n",
    "con=sql.connect('../data/processed/temp_c.db')\n",
    "m.to_sql('mentions', index_label='pk', index=True, if_exists='replace', con=con)\n",
    "symc.to_sql('symbol_comments', index_label='pk', index=True, if_exists='replace', con=con)\n",
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "533f42cc1718b4e514b78a4bcd7158294e27b7c18264f40c4fe062bcb1773c09"
  },
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

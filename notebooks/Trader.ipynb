{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, sqlite3 as sql, datetime as dt, re, time, yfinance as yf\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import nltk\n",
    "import os, gc\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from api_key import cryptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1174,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sql.connect('../data/interim/companies.db') as con:\n",
    "        port = pd.read_sql(f\"SELECT Date date, Open, High, Low, Close, Volume, Volatility, Turnover, symbol FROM daily ORDER BY date\", con=con, parse_dates={'date': '%Y-%m-%d %H:%M:%S'})\\\n",
    "                .drop_duplicates(subset=['date', 'symbol'])\n",
    "        recommends = pd.read_sql(f\"SELECT Date date, symbol, Firm, new_grade, prev_grade, Action from recommendations ORDER BY Date\", con=con, parse_dates={'date': '%Y-%m-%d %H:%M:%S'})\n",
    "        arts =pd.read_sql(\"SELECT date, symbol, publisher, pos_sent, neu_sent, neg_sent, comp_sent FROM articles ORDER BY date\", con=con, parse_dates={'date': '%Y-%m-%d %H:%M:%S'})\n",
    "        crypt_arts = pd.read_sql(\"SELECT date, symbol, publisher,pos_sent, neu_sent, neg_sent, comp_sent  FROM news_sentiment ORDER BY date\", con=con, parse_dates={'date': '%Y-%m-%d %H:%M:%S'})\n",
    "        articles = pd.concat([arts, crypt_arts], axis=0, ignore_index=True)\n",
    "        comments = pd.read_sql(f\"SELECT DATE(timestamp) date, channel, symbols, pos_sent, neu_sent, neg_sent, comp_sent from symbol_comments ORDER BY timestamp\", parse_dates={'date': '%Y-%m-%d'}, con=con)\n",
    "        comments.loc[:, \"symbols\"] = comments.symbols.apply(lambda x: x.replace('BTC', 'BTC-USD'))\n",
    "        companies = tuple(port.symbol.unique())\n",
    "        c_data = pd.read_sql(f\"SELECT * from mentions WHERE symbol IN {companies}\", con=con, index_col='pk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1175,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols_re = re.compile(r\"\\[|\\]|\\'|\\'\")\n",
    "last_index = comments.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decompose for single symbol\n",
    "for i, row in comments.iterrows():\n",
    "    symbols = re.sub(symbols_re, \"\", row.symbols)\n",
    "    symbols = symbols.split(',')\n",
    "    for sym in symbols:\n",
    "        last_index+=1\n",
    "        comments.loc[last_index, [\"symbols\"]] = sym\n",
    "        comments.loc[last_index, [\"comment_index\"]] = i\n",
    "        comments.loc[last_index, [\"date\", \"channel\", \"pos_sent\", \"neu_sent\", \"neg_sent\", \"comp_sent\"]] = row.date, row.channel, row.pos_sent, row.neu_sent,  row.neg_sent, row.comp_sent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75420.9830585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "75421.0021197"
      ]
     },
     "execution_count": 1195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(time.perf_counter())\n",
    "\n",
    "time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.assign(sym = lambda x: x.symbols.apply(lambda x: re.sub(symbols_re, '', x)).apply(str.split, sep=',')).explode('sym').reset_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1166,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = comments[lambda x:~( x.comment_index.isnull())]\n",
    "comments = comments[lambda x: x.symbols.isin(companies)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1167,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendsDict = {\"Very Bearish\": 1, \"Bearish\": 2, \"Neutral\": 3, \"Bullish\": 4, \"Very Bullish\": 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1168,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommends=recommends.assign(new_sent = lambda x: x.new_grade.apply(lambda g: recommendsDict[g]))\\\n",
    "    .assign(prev_sent = lambda x: x.prev_grade.apply(lambda g: recommendsDict[g]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Volatility',\n",
       "       'Turnover', 'symbol'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_daily_data(ticker):\n",
    "    tick = yf.ticker.Ticker(ticker)\n",
    "    historical_data = tick.history(\"1mo\")\n",
    "    outstanding = tick.info.get(\"sharesOutstanding\")\n",
    "    if outstanding == None:\n",
    "        outstanding = 1\n",
    "    daily_close = historical_data[\"Close\"]\n",
    "    pct_change = daily_close.pct_change().fillna(0)\n",
    "    periods = 2\n",
    "    # calc volatility\n",
    "    vola = (pct_change.rolling(periods).std() * np.sqrt(periods)).fillna(0)\n",
    "    historical_data = historical_data.assign(Volatility = vola)\n",
    "    historical_data = historical_data.assign(Turnover = lambda x: x.Volume / outstanding)\n",
    "    historical_data = historical_data.assign(symbol = ticker)\n",
    "    return historical_data.reset_index().round({\"Volatility\": 6, \"Turnover\": 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take aggregations over wanted frequency; make buy decisions based off of the frequency of data points and sentiments\n",
    "# return port with new information: shares and cost * shares\n",
    "class EAT():\n",
    "    def __init__(self, portfolio, articles, comments, recs, start, end):\n",
    "        self.portfolio = portfolio.copy(deep=True)\n",
    "        self.postions = []\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.articles = articles[lambda x: (x.date >= start) & (x.date <= end)]\n",
    "        self.comments =  comments[lambda x: (x.date >= start) & (x.date <= end)]\n",
    "        self.recs = recs[lambda x: (x.date >= start) & (x.date <= end)]\n",
    "\n",
    "        self.aggs = {}\n",
    "\n",
    "    def aggregate(self):\n",
    "        articles_agg = self.articles.groupby([pd.Grouper(key=\"date\", freq=\"1Y\"), 'symbol'])\\\n",
    "            .agg({'pos_sent': ['mean'], 'neg_sent': ['mean'], 'neu_sent': ['mean'], 'comp_sent': ['mean', 'count']}).assign(type=lambda x: 'News')\n",
    "        comments_agg = self.comments.groupby([pd.Grouper(key=\"date\", freq=\"1Y\"), 'symbols'])\\\n",
    "            .agg({'pos_sent': ['mean'], 'neg_sent': ['mean'], 'neu_sent': ['mean'], 'comp_sent': ['mean', 'count']}).assign(type=lambda x: 'Chats')\n",
    "        recommends_agg = self.recs.groupby([pd.Grouper(key=\"date\", freq=\"1Y\"), 'symbol'])\\\n",
    "            .agg({'new_sent': ['mean'], 'prev_sent': ['mean', 'count']}).assign(type=lambda x: 'Analysts')\n",
    "        recommends_agg = recommends_agg.reset_index()\n",
    "        comments_agg = comments_agg.reset_index()\n",
    "        articles_agg = articles_agg.reset_index()\n",
    "        recommends_agg.columns = recommends_agg.columns.droplevel(1)\n",
    "        comments_agg.columns = comments_agg.columns.droplevel(1)\n",
    "        articles_agg.columns = articles_agg.columns.droplevel(1)\n",
    "        \n",
    "        articles_agg.columns = ['date', 'symbol', 'pos_sent', 'neg_sent', 'neu_sent', 'comp_sent',\n",
    "       'counts', 'type']\n",
    "        comments_agg.columns = ['date', 'symbol', 'pos_sent', 'neg_sent', 'neu_sent', 'comp_sent',\n",
    "       'counts', 'type']\n",
    "        recommends_agg.columns = ['date', 'symbol', 'new_sent', 'prev_sent', 'counts', 'type']\n",
    "        # comments_agg=comments_agg.assign(date = lambda x: x.date.apply(lambda x: x.date))\n",
    "        self.aggs['recommendations'] = recommends_agg\n",
    "        self.aggs['articles'] = articles_agg\n",
    "        self.aggs['comments'] = comments_agg\n",
    "        return None \n",
    "\n",
    "\n",
    "    def tradeSents(self, agg, label, min_samples, min_comp_sent, shares):\n",
    "        # add action, shares, cost\n",
    "        returns = self.aggs[agg][lambda x: (x.date >= self.start) & (x[label] >= min_comp_sent) & (x.counts >= min_samples)]\n",
    "        # query portfolio for first cost add columns\n",
    "        indexes = pd.Int64Index([])\n",
    "        for date, sym in returns.loc[:, ['date', 'symbol']].values:\n",
    "            # ns = returns[lambda x: x.date == date].shape[0]\n",
    "            if sym not in self.postions:\n",
    "                self.postions.append(sym)\n",
    "                f1_date = (date + relativedelta(years=1)).to_pydatetime()\n",
    "                indexes = self.portfolio[lambda x: ((x.date > date) & (x.symbol == sym) & (x.date <= f1_date))].index\n",
    "                self.portfolio.loc[indexes, \"shares\"] = shares\n",
    "            else:\n",
    "                self.postions.append(sym)\n",
    "                f1_date = (date + relativedelta(years=1)).to_pydatetime()\n",
    "                indexes = self.portfolio[lambda x: ((x.date > date) & (x.symbol == sym) & (x.date <= f1_date))].index\n",
    "                self.portfolio.loc[indexes, \"shares\"] = shares * self.postions.count(sym)\n",
    "            \n",
    "            i = returns[lambda x: (x.date == date) & (x.symbol == sym)].index\n",
    "            if not indexes.empty:\n",
    "                returns.loc[i, 'cost'] = shares * self.portfolio.loc[indexes[0], \"Close\"]\n",
    "                returns.loc[i, 'returns'] = shares * self.portfolio.loc[indexes[-1], \"Close\"]\n",
    "            else:\n",
    "                indexes = self.portfolio[lambda x: (x.symbol == sym)].index\n",
    "                returns.loc[i, 'cost'] = shares * self.portfolio.loc[indexes[-1], \"Open\"]\n",
    "                returns.loc[i, 'returns'] = shares * self.portfolio.loc[indexes[-1], \"Close\"]\n",
    "\n",
    "        return self.portfolio#returns\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1171,
   "metadata": {},
   "outputs": [],
   "source": [
    "eat = EAT(port, articles, comments, recommends, dt.datetime(2018, 1, 1), dt.datetime(2022, 1, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1172,
   "metadata": {},
   "outputs": [],
   "source": [
    "eat.aggregate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kyle\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\Kyle\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1765: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>Turnover</th>\n",
       "      <th>symbol</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>42.972000</td>\n",
       "      <td>44.066002</td>\n",
       "      <td>42.192001</td>\n",
       "      <td>43.397999</td>\n",
       "      <td>29616500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.950000e-02</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>11.420000</td>\n",
       "      <td>11.650000</td>\n",
       "      <td>11.020000</td>\n",
       "      <td>11.430000</td>\n",
       "      <td>55182000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.570000e-02</td>\n",
       "      <td>AMD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>27.250112</td>\n",
       "      <td>27.374832</td>\n",
       "      <td>27.005378</td>\n",
       "      <td>27.332474</td>\n",
       "      <td>115127600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000e-03</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>20.639999</td>\n",
       "      <td>21.840000</td>\n",
       "      <td>20.532000</td>\n",
       "      <td>21.360001</td>\n",
       "      <td>73033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000e-04</td>\n",
       "      <td>ACB</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>88.080002</td>\n",
       "      <td>88.599998</td>\n",
       "      <td>8789400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.200000e-03</td>\n",
       "      <td>BABA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98728</th>\n",
       "      <td>2022-01-28</td>\n",
       "      <td>24.003000</td>\n",
       "      <td>25.709999</td>\n",
       "      <td>22.809999</td>\n",
       "      <td>25.639999</td>\n",
       "      <td>21496600</td>\n",
       "      <td>0.101186</td>\n",
       "      <td>7.133600e-02</td>\n",
       "      <td>PTON</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98729</th>\n",
       "      <td>2022-01-28</td>\n",
       "      <td>20.660000</td>\n",
       "      <td>21.320000</td>\n",
       "      <td>19.309999</td>\n",
       "      <td>20.900000</td>\n",
       "      <td>96497500</td>\n",
       "      <td>0.058454</td>\n",
       "      <td>6.066900e-02</td>\n",
       "      <td>NIO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98730</th>\n",
       "      <td>2022-01-28</td>\n",
       "      <td>1.850000</td>\n",
       "      <td>1.870000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1.780000</td>\n",
       "      <td>2441000</td>\n",
       "      <td>0.035781</td>\n",
       "      <td>2.085600e-02</td>\n",
       "      <td>SOLO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98731</th>\n",
       "      <td>2022-01-29</td>\n",
       "      <td>37780.714844</td>\n",
       "      <td>38576.261719</td>\n",
       "      <td>37406.472656</td>\n",
       "      <td>38138.179688</td>\n",
       "      <td>17194183075</td>\n",
       "      <td>0.008032</td>\n",
       "      <td>1.719418e+10</td>\n",
       "      <td>BTC-USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98732</th>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>37922.519531</td>\n",
       "      <td>37922.519531</td>\n",
       "      <td>36865.222656</td>\n",
       "      <td>36916.058594</td>\n",
       "      <td>15363525632</td>\n",
       "      <td>0.041409</td>\n",
       "      <td>1.536353e+10</td>\n",
       "      <td>BTC-USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98731 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date          Open          High           Low         Close  \\\n",
       "0     2017-01-03     42.972000     44.066002     42.192001     43.397999   \n",
       "1     2017-01-03     11.420000     11.650000     11.020000     11.430000   \n",
       "2     2017-01-03     27.250112     27.374832     27.005378     27.332474   \n",
       "3     2017-01-03     20.639999     21.840000     20.532000     21.360001   \n",
       "4     2017-01-03     89.000000     89.000000     88.080002     88.599998   \n",
       "...          ...           ...           ...           ...           ...   \n",
       "98728 2022-01-28     24.003000     25.709999     22.809999     25.639999   \n",
       "98729 2022-01-28     20.660000     21.320000     19.309999     20.900000   \n",
       "98730 2022-01-28      1.850000      1.870000      1.750000      1.780000   \n",
       "98731 2022-01-29  37780.714844  38576.261719  37406.472656  38138.179688   \n",
       "98732 2022-01-31  37922.519531  37922.519531  36865.222656  36916.058594   \n",
       "\n",
       "            Volume  Volatility      Turnover   symbol  shares  \n",
       "0         29616500    0.000000  2.950000e-02     TSLA     NaN  \n",
       "1         55182000    0.000000  4.570000e-02      AMD     NaN  \n",
       "2        115127600    0.000000  7.000000e-03     AAPL     NaN  \n",
       "3            73033    0.000000  4.000000e-04      ACB     NaN  \n",
       "4          8789400    0.000000  3.200000e-03     BABA     NaN  \n",
       "...            ...         ...           ...      ...     ...  \n",
       "98728     21496600    0.101186  7.133600e-02     PTON     NaN  \n",
       "98729     96497500    0.058454  6.066900e-02      NIO     NaN  \n",
       "98730      2441000    0.035781  2.085600e-02     SOLO     NaN  \n",
       "98731  17194183075    0.008032  1.719418e+10  BTC-USD     NaN  \n",
       "98732  15363525632    0.041409  1.536353e+10  BTC-USD     NaN  \n",
       "\n",
       "[98731 rows x 10 columns]"
      ]
     },
     "execution_count": 1173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eat.tradeSents(\"comments\", \"comp_sent\", min_samples=1, min_comp_sent=0.15, shares=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kyle\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\Kyle\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1765: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    }
   ],
   "source": [
    "ret = eat.tradeSents(\"articles\", \"comp_sent\", 100, 0.5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = eat.tradeSents(\"recommendations\", \"new_sent\", 25, 4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eat.tradeSents(\"articles\", \"comp_sent\", 100, 0.5, 10)\n",
    "# eat.tradeSents(\"recommendations\", \"new_sent\", 25, 4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos_sent</th>\n",
       "      <th>neg_sent</th>\n",
       "      <th>neu_sent</th>\n",
       "      <th>comp_sent</th>\n",
       "      <th>counts</th>\n",
       "      <th>cost</th>\n",
       "      <th>returns</th>\n",
       "      <th>r_pct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>5.265895</td>\n",
       "      <td>0.623934</td>\n",
       "      <td>15.110028</td>\n",
       "      <td>8.133532</td>\n",
       "      <td>93</td>\n",
       "      <td>42329.746435</td>\n",
       "      <td>67754.449959</td>\n",
       "      <td>0.600634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>4.164832</td>\n",
       "      <td>0.921737</td>\n",
       "      <td>24.733701</td>\n",
       "      <td>5.878339</td>\n",
       "      <td>1405</td>\n",
       "      <td>330494.633604</td>\n",
       "      <td>502545.053391</td>\n",
       "      <td>0.520585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pos_sent  neg_sent   neu_sent  comp_sent  counts           cost  \\\n",
       "date                                                                          \n",
       "2019-12-31  5.265895  0.623934  15.110028   8.133532      93   42329.746435   \n",
       "2020-12-31  4.164832  0.921737  24.733701   5.878339    1405  330494.633604   \n",
       "\n",
       "                  returns     r_pct  \n",
       "date                                 \n",
       "2019-12-31   67754.449959  0.600634  \n",
       "2020-12-31  502545.053391  0.520585  "
      ]
     },
     "execution_count": 1152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret.groupby('date').sum().assign(r_pct = lambda x: (x.returns - x.cost) / x.cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kyle\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\Kyle\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1765: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos_sent</th>\n",
       "      <th>neg_sent</th>\n",
       "      <th>neu_sent</th>\n",
       "      <th>comp_sent</th>\n",
       "      <th>counts</th>\n",
       "      <th>cost</th>\n",
       "      <th>returns</th>\n",
       "      <th>r_pct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>1.886672</td>\n",
       "      <td>0.725528</td>\n",
       "      <td>19.387871</td>\n",
       "      <td>12.806051</td>\n",
       "      <td>6245</td>\n",
       "      <td>363631.928234</td>\n",
       "      <td>537816.954250</td>\n",
       "      <td>0.479015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31</th>\n",
       "      <td>2.635620</td>\n",
       "      <td>0.961372</td>\n",
       "      <td>26.403193</td>\n",
       "      <td>18.722140</td>\n",
       "      <td>9305</td>\n",
       "      <td>90168.539557</td>\n",
       "      <td>73207.400317</td>\n",
       "      <td>-0.188105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pos_sent  neg_sent   neu_sent  comp_sent  counts           cost  \\\n",
       "date                                                                          \n",
       "2020-12-31  1.886672  0.725528  19.387871  12.806051    6245  363631.928234   \n",
       "2021-12-31  2.635620  0.961372  26.403193  18.722140    9305   90168.539557   \n",
       "\n",
       "                  returns     r_pct  \n",
       "date                                 \n",
       "2020-12-31  537816.954250  0.479015  \n",
       "2021-12-31   73207.400317 -0.188105  "
      ]
     },
     "execution_count": 1153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret = eat.tradeSents(\"articles\", \"comp_sent\", 100, 0.5, 10)\n",
    "ret.groupby('date').sum().assign(r_pct = lambda x: (x.returns - x.cost) / x.cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kyle\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\Kyle\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1765: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_sent</th>\n",
       "      <th>prev_sent</th>\n",
       "      <th>counts</th>\n",
       "      <th>cost</th>\n",
       "      <th>returns</th>\n",
       "      <th>r_pct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-12-31</th>\n",
       "      <td>29.418501</td>\n",
       "      <td>29.140315</td>\n",
       "      <td>280</td>\n",
       "      <td>21844.340649</td>\n",
       "      <td>27577.331295</td>\n",
       "      <td>0.262447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>33.888142</td>\n",
       "      <td>33.519803</td>\n",
       "      <td>355</td>\n",
       "      <td>30153.087006</td>\n",
       "      <td>47727.473297</td>\n",
       "      <td>0.582839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>67.845811</td>\n",
       "      <td>67.276012</td>\n",
       "      <td>993</td>\n",
       "      <td>57397.397575</td>\n",
       "      <td>62125.701008</td>\n",
       "      <td>0.082378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31</th>\n",
       "      <td>58.988827</td>\n",
       "      <td>58.416372</td>\n",
       "      <td>694</td>\n",
       "      <td>67120.639572</td>\n",
       "      <td>56591.000690</td>\n",
       "      <td>-0.156876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             new_sent  prev_sent  counts          cost       returns     r_pct\n",
       "date                                                                          \n",
       "2018-12-31  29.418501  29.140315     280  21844.340649  27577.331295  0.262447\n",
       "2019-12-31  33.888142  33.519803     355  30153.087006  47727.473297  0.582839\n",
       "2020-12-31  67.845811  67.276012     993  57397.397575  62125.701008  0.082378\n",
       "2021-12-31  58.988827  58.416372     694  67120.639572  56591.000690 -0.156876"
      ]
     },
     "execution_count": 1157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret = eat.tradeSents(\"recommendations\", \"new_sent\", 25, 4, 10)\n",
    "ret.groupby('date').sum().assign(r_pct = lambda x: (x.returns - x.cost) / x.cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with sql.connect('../data/interim/companies.db') as con:\n",
    "#     new_port.to_sql('daily', con=con, index=True, index_label=\"pk\", if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sql.connect('../data/interim/companies.db') as con:\n",
    "        port =pd.read_sql(\"SELECT * FROM daily ORDER BY date\", con=con, parse_dates={'date': '%Y-%m-%d %H:%M:%S'})\n",
    "        arts =pd.read_sql(\"SELECT * FROM articles ORDER BY date\", con=con, parse_dates={'date': '%Y-%m-%d %H:%M:%S'})\n",
    "        crypt_arts = pd.read_sql(\"SELECT * FROM crypt_articles ORDER BY date\", con=sql.connect('../data/raw/crypt.db'))\n",
    "        #articles = pd.concat([arts, crypt_arts], axis=0, ignore_index=True)\n",
    "        comments = pd.read_sql(f\"SELECT DATE(timestamp) date, channel, symbols, pos_sent, neu_sent, neg_sent, comp_sent from symbol_comments ORDER BY timestamp\", parse_dates={'date': '%Y-%m-%d'}, con=con)\n",
    "        comments.loc[:, \"symbols\"] = comments.symbols.apply(lambda x: x.replace('BTC', 'BTC-USD'))\n",
    "        companies = tuple(port.symbol.unique())\n",
    "        c_data = pd.read_sql(f\"SELECT * from mentions WHERE symbol IN {companies}\", con=con, index_col='pk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "decrypt_cols = [x for x in crypt_arts.columns if x not in ['pk', 'pos_sent', \"neu_sent\", \"neg_sent\", \"comp_sent\"]]\n",
    "for col in decrypt_cols:\n",
    "    crypt_arts.loc[:, col] = crypt_arts.loc[:, col].apply(bytes).apply(cryptor.decrypt).apply(str, encoding='utf-8')\n",
    "    if col == 'date':\n",
    "        crypt_arts.loc[:, col] = crypt_arts.loc[:, col].apply(str.split, sep=\" \").apply(lambda x: x[0]).apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pk</th>\n",
       "      <th>article</th>\n",
       "      <th>headline</th>\n",
       "      <th>comments</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>symbol</th>\n",
       "      <th>publisher</th>\n",
       "      <th>pos_sent</th>\n",
       "      <th>neg_sent</th>\n",
       "      <th>neu_sent</th>\n",
       "      <th>comp_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>The Transportation Security Administration say...</td>\n",
       "      <td>TSA extends COVID mask rule for U.S. transport...</td>\n",
       "      <td>49</td>\n",
       "      <td>2021-08-17</td>\n",
       "      <td>https://seekingalpha.com/news/3731674-tsa-exte...</td>\n",
       "      <td>AAL</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.2544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5705</td>\n",
       "      <td>Parler, the social network popular with conser...</td>\n",
       "      <td>Parler comes back online after a month off the...</td>\n",
       "      <td>249</td>\n",
       "      <td>2021-02-16</td>\n",
       "      <td>https://seekingalpha.com/news/3662032-parler-c...</td>\n",
       "      <td>FB</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.9363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1709</td>\n",
       "      <td>Amazon (NASDAQ:AMZN): Q1 GAAP EPS of $15.79 be...</td>\n",
       "      <td>Amazon EPS beats by $6.18, beats on revenue</td>\n",
       "      <td>115</td>\n",
       "      <td>2021-04-29</td>\n",
       "      <td>https://seekingalpha.com/news/3688132-amazon-e...</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.7184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3240</td>\n",
       "      <td>Blink Charging (BLNK +7.4%), EVgo (EVGO +8.4%)...</td>\n",
       "      <td>Electric vehicle battery stocks break higher a...</td>\n",
       "      <td>28</td>\n",
       "      <td>2021-07-28</td>\n",
       "      <td>https://seekingalpha.com/news/3720809-electric...</td>\n",
       "      <td>BLNK</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5968</td>\n",
       "      <td>Teenagers across the U.S. are looking to Redmo...</td>\n",
       "      <td>TikTok rescue by Microsoft could make sense - ...</td>\n",
       "      <td>93</td>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>https://seekingalpha.com/news/3598676-tiktok-r...</td>\n",
       "      <td>FB</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.8934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15321</th>\n",
       "      <td>11885</td>\n",
       "      <td>The Associated Press, NBC, Edison Research, Fo...</td>\n",
       "      <td>Joe Biden wins U.S. presidential election</td>\n",
       "      <td>23654</td>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>https://seekingalpha.com/news/3633355-joe-bide...</td>\n",
       "      <td>QQQ</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.0258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15322</th>\n",
       "      <td>9323</td>\n",
       "      <td>Animal spirits are firing up again on red-hot ...</td>\n",
       "      <td>Electric vehicle names head higher led by Kand...</td>\n",
       "      <td>126</td>\n",
       "      <td>2020-11-23</td>\n",
       "      <td>https://seekingalpha.com/news/3638678-electric...</td>\n",
       "      <td>NIO</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.921</td>\n",
       "      <td>-0.2263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15323</th>\n",
       "      <td>2573</td>\n",
       "      <td>Boeing (BA +3.1%) bounces sharply higher after...</td>\n",
       "      <td>Boeing sales outpaced cancellations last month...</td>\n",
       "      <td>10</td>\n",
       "      <td>2021-03-09</td>\n",
       "      <td>https://seekingalpha.com/news/3670770-boeing-s...</td>\n",
       "      <td>BA</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.913</td>\n",
       "      <td>-0.7005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15324</th>\n",
       "      <td>7455</td>\n",
       "      <td>Workers in Arizona, Oregon, and New Mexico hav...</td>\n",
       "      <td>Intel workers file coronavirus safety complaints</td>\n",
       "      <td>15</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>https://seekingalpha.com/news/3572138-intel-wo...</td>\n",
       "      <td>INTC</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.9112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15325</th>\n",
       "      <td>14010</td>\n",
       "      <td>Commercial vehicle registrations in the Europe...</td>\n",
       "      <td>EU commercial vehicle new registrations expand...</td>\n",
       "      <td>14</td>\n",
       "      <td>2021-05-26</td>\n",
       "      <td>https://seekingalpha.com/news/3700479-eu-comme...</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.8271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15326 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pk                                            article  \\\n",
       "0          9  The Transportation Security Administration say...   \n",
       "1       5705  Parler, the social network popular with conser...   \n",
       "2       1709  Amazon (NASDAQ:AMZN): Q1 GAAP EPS of $15.79 be...   \n",
       "3       3240  Blink Charging (BLNK +7.4%), EVgo (EVGO +8.4%)...   \n",
       "4       5968  Teenagers across the U.S. are looking to Redmo...   \n",
       "...      ...                                                ...   \n",
       "15321  11885  The Associated Press, NBC, Edison Research, Fo...   \n",
       "15322   9323  Animal spirits are firing up again on red-hot ...   \n",
       "15323   2573  Boeing (BA +3.1%) bounces sharply higher after...   \n",
       "15324   7455  Workers in Arizona, Oregon, and New Mexico hav...   \n",
       "15325  14010  Commercial vehicle registrations in the Europe...   \n",
       "\n",
       "                                                headline comments       date  \\\n",
       "0      TSA extends COVID mask rule for U.S. transport...      49  2021-08-17   \n",
       "1      Parler comes back online after a month off the...     249  2021-02-16   \n",
       "2            Amazon EPS beats by $6.18, beats on revenue     115  2021-04-29   \n",
       "3      Electric vehicle battery stocks break higher a...      28  2021-07-28   \n",
       "4      TikTok rescue by Microsoft could make sense - ...      93  2020-08-01   \n",
       "...                                                  ...      ...        ...   \n",
       "15321          Joe Biden wins U.S. presidential election   23654  2020-11-07   \n",
       "15322  Electric vehicle names head higher led by Kand...     126  2020-11-23   \n",
       "15323  Boeing sales outpaced cancellations last month...      10  2021-03-09   \n",
       "15324   Intel workers file coronavirus safety complaints      15  2020-05-08   \n",
       "15325  EU commercial vehicle new registrations expand...      14  2021-05-26   \n",
       "\n",
       "                                                    link symbol  \\\n",
       "0      https://seekingalpha.com/news/3731674-tsa-exte...    AAL   \n",
       "1      https://seekingalpha.com/news/3662032-parler-c...     FB   \n",
       "2      https://seekingalpha.com/news/3688132-amazon-e...   AMZN   \n",
       "3      https://seekingalpha.com/news/3720809-electric...   BLNK   \n",
       "4      https://seekingalpha.com/news/3598676-tiktok-r...     FB   \n",
       "...                                                  ...    ...   \n",
       "15321  https://seekingalpha.com/news/3633355-joe-bide...    QQQ   \n",
       "15322  https://seekingalpha.com/news/3638678-electric...    NIO   \n",
       "15323  https://seekingalpha.com/news/3670770-boeing-s...     BA   \n",
       "15324  https://seekingalpha.com/news/3572138-intel-wo...   INTC   \n",
       "15325  https://seekingalpha.com/news/3700479-eu-comme...   TSLA   \n",
       "\n",
       "           publisher  pos_sent  neg_sent  neu_sent  comp_sent  \n",
       "0      Seeking Alpha     0.042     0.042     0.916     0.2544  \n",
       "1      Seeking Alpha     0.082     0.039     0.879     0.9363  \n",
       "2      Seeking Alpha     0.065     0.000     0.935     0.7184  \n",
       "3      Seeking Alpha     0.047     0.038     0.916     0.1280  \n",
       "4      Seeking Alpha     0.114     0.033     0.853     0.8934  \n",
       "...              ...       ...       ...       ...        ...  \n",
       "15321  Seeking Alpha     0.059     0.048     0.893     0.0258  \n",
       "15322  Seeking Alpha     0.033     0.046     0.921    -0.2263  \n",
       "15323  Seeking Alpha     0.021     0.066     0.913    -0.7005  \n",
       "15324  Seeking Alpha     0.133     0.087     0.779     0.9112  \n",
       "15325  Seeking Alpha     0.069     0.020     0.911     0.8271  \n",
       "\n",
       "[15326 rows x 12 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crypt_arts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "arts = arts.assign(comments = lambda x: 0)\n",
    "arts = arts.loc[:, ['pk', 'article', 'title', 'comments','date', 'link', 'symbol', 'publisher','pos_sent', 'neg_sent', 'neu_sent', 'comp_sent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nongreedy\n",
    "regex = re.compile(r\"© Reuters.+?(-|—)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "arts = arts.assign(article = lambda x: x.article.apply(lambda w: re.sub(regex, \"\", w)).apply(str.strip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "arts = arts.rename(columns={'title': 'headline'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "arted = pd.concat([crypt_arts.assign(sa=lambda x: 1), arts.assign(sa=lambda x: 0)], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "stop_words = stop_words.union({'said', 'us', 'also', 'inc', 'could', 'word', 'b', 'q', })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordCounts(df, comment_array):\n",
    "    comment_list = []\n",
    "    for comment in comment_array:\n",
    "        comment_dictionary = {} \n",
    "        punc_regex = r\"[\\，\\’\\'\\'\\\"\\\"\\“\\”!\\?@#$%&\\(\\)\\*,-.\\\\\\{\\}+~\\/:;<>\\[\\]^`|=_]\"\n",
    "        reg_bad_quotes = re.compile(u\"[\\x94\\x93\\x92\\x91]\")\n",
    "        comment = comment.lower()\n",
    "        comment = re.sub(punc_regex, \" \", comment)\n",
    "        comment = re.sub(reg_bad_quotes, \" \", comment)\n",
    "        words = nltk.tokenize.word_tokenize(comment)\n",
    "        for w in words:\n",
    "            if (w in comment_dictionary.keys()) & (w not in stop_words):\n",
    "                comment_dictionary[w] += 1\n",
    "            elif (w not in stop_words):\n",
    "                comment_dictionary[w] = 1\n",
    "        comments_words = dict(sorted(comment_dictionary.items(), key=lambda x: x[1], reverse=True))\n",
    "        comment_list.append(comments_words)\n",
    "    \n",
    "    df = df.assign(word_obj = pd.Series(comment_list))\n",
    "    return df\n",
    "\n",
    "# word counts sans stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordy_df = wordCounts(arted, arted.article.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordy_df2 = wordy_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordy_df2 = wordy_df2.assign(article = lambda x: x.article.apply(lambda line: re.sub(r'(?<=[.,])(?=[^\\s])', r' ', line)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordy_df3 = wordy_df2.assign(word_obj = lambda x: x.word_obj.apply(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wordy_df3.to_sql('temp_table', con=sql.connect('temp.db'), if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pk</th>\n",
       "      <th>article</th>\n",
       "      <th>headline</th>\n",
       "      <th>comments</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>symbol</th>\n",
       "      <th>publisher</th>\n",
       "      <th>pos_sent</th>\n",
       "      <th>neg_sent</th>\n",
       "      <th>neu_sent</th>\n",
       "      <th>comp_sent</th>\n",
       "      <th>sa</th>\n",
       "      <th>word_obj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>The Transportation Security Administration say...</td>\n",
       "      <td>TSA extends COVID mask rule for U.S. transport...</td>\n",
       "      <td>49</td>\n",
       "      <td>2021-08-17</td>\n",
       "      <td>https://seekingalpha.com/news/3731674-tsa-exte...</td>\n",
       "      <td>AAL</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.2544</td>\n",
       "      <td>1</td>\n",
       "      <td>{'transportation': 2, 'administration': 2, 'sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5705</td>\n",
       "      <td>Parler, the social network popular with conser...</td>\n",
       "      <td>Parler comes back online after a month off the...</td>\n",
       "      <td>249</td>\n",
       "      <td>2021-02-16</td>\n",
       "      <td>https://seekingalpha.com/news/3662032-parler-c...</td>\n",
       "      <td>FB</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.9363</td>\n",
       "      <td>1</td>\n",
       "      <td>{'parler': 7, 'users': 4, 'platform': 3, 'skys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1709</td>\n",
       "      <td>Amazon (NASDAQ:AMZN): Q1 GAAP EPS of $15. 79 b...</td>\n",
       "      <td>Amazon EPS beats by $6.18, beats on revenue</td>\n",
       "      <td>115</td>\n",
       "      <td>2021-04-29</td>\n",
       "      <td>https://seekingalpha.com/news/3688132-amazon-e...</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.7184</td>\n",
       "      <td>1</td>\n",
       "      <td>{'billion': 6, '5': 4, 'revenue': 3, '108': 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3240</td>\n",
       "      <td>Blink Charging (BLNK +7. 4%), EVgo (EVGO +8. 4...</td>\n",
       "      <td>Electric vehicle battery stocks break higher a...</td>\n",
       "      <td>28</td>\n",
       "      <td>2021-07-28</td>\n",
       "      <td>https://seekingalpha.com/news/3720809-electric...</td>\n",
       "      <td>BLNK</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>1</td>\n",
       "      <td>{'infrastructure': 5, 'bill': 5, '7': 4, 'ev':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5968</td>\n",
       "      <td>Teenagers across the U. S. are looking to Redm...</td>\n",
       "      <td>TikTok rescue by Microsoft could make sense - ...</td>\n",
       "      <td>93</td>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>https://seekingalpha.com/news/3598676-tiktok-r...</td>\n",
       "      <td>FB</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.8934</td>\n",
       "      <td>1</td>\n",
       "      <td>{'would': 5, 'tiktok': 4, 'microsoft': 4, 'mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26805</th>\n",
       "      <td>7584</td>\n",
       "      <td>Stock in gaming and e-commerce firm Sea (NYSE:...</td>\n",
       "      <td>Sea Slumps as Tencent Moves to Cut Voting Stak...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>https://www.investing.com/news/stock-market-ne...</td>\n",
       "      <td>SE</td>\n",
       "      <td>Investing.com</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.7867</td>\n",
       "      <td>0</td>\n",
       "      <td>{'tencent': 5, 'sea': 4, 'voting': 4, 'stake':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26806</th>\n",
       "      <td>1625</td>\n",
       "      <td>On Wednesday, Palantir Technologies Inc (NYSE:...</td>\n",
       "      <td>Palantir Technologies Announces Collaboration ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>https://www.investing.com/news/stock-market-ne...</td>\n",
       "      <td>PLTR</td>\n",
       "      <td>Investing.com</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.9630</td>\n",
       "      <td>0</td>\n",
       "      <td>{'palantir': 6, 'platform': 5, 'hhi': 4, 'big'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26807</th>\n",
       "      <td>7583</td>\n",
       "      <td>Asia Pacific stocks were down on Thursday morn...</td>\n",
       "      <td>Asian Stocks Down, Positive Chinese Data Fails...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>https://www.investing.com/news/stock-market-ne...</td>\n",
       "      <td>SE</td>\n",
       "      <td>Investing.com</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.9201</td>\n",
       "      <td>0</td>\n",
       "      <td>{'services': 4, '1': 4, 'day': 4, 'u': 3, '0':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26808</th>\n",
       "      <td>9547</td>\n",
       "      <td>The S&amp;P 500 closed down Friday, marking its wo...</td>\n",
       "      <td>S&amp;P 500 in Big Weekly Loss as Tech Bulls Scatt...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-07</td>\n",
       "      <td>https://www.investing.com/news/stock-market-ne...</td>\n",
       "      <td>ON</td>\n",
       "      <td>Investing.com</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.9733</td>\n",
       "      <td>0</td>\n",
       "      <td>{'stocks': 5, 'nasdaq': 5, 'tech': 4, 'rate': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26809</th>\n",
       "      <td>9548</td>\n",
       "      <td>The S&amp;P 500 struggled for direction Friday, pa...</td>\n",
       "      <td>S&amp;P 500 Struggles for Direction as Jobs Miss F...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-07</td>\n",
       "      <td>https://www.investing.com/news/stock-market-ne...</td>\n",
       "      <td>ON</td>\n",
       "      <td>Investing.com</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.9807</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': 6, 'nasdaq': 5, 'tech': 4, 'rate': 4, 'm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26810 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pk                                            article  \\\n",
       "0         9  The Transportation Security Administration say...   \n",
       "1      5705  Parler, the social network popular with conser...   \n",
       "2      1709  Amazon (NASDAQ:AMZN): Q1 GAAP EPS of $15. 79 b...   \n",
       "3      3240  Blink Charging (BLNK +7. 4%), EVgo (EVGO +8. 4...   \n",
       "4      5968  Teenagers across the U. S. are looking to Redm...   \n",
       "...     ...                                                ...   \n",
       "26805  7584  Stock in gaming and e-commerce firm Sea (NYSE:...   \n",
       "26806  1625  On Wednesday, Palantir Technologies Inc (NYSE:...   \n",
       "26807  7583  Asia Pacific stocks were down on Thursday morn...   \n",
       "26808  9547  The S&P 500 closed down Friday, marking its wo...   \n",
       "26809  9548  The S&P 500 struggled for direction Friday, pa...   \n",
       "\n",
       "                                                headline comments       date  \\\n",
       "0      TSA extends COVID mask rule for U.S. transport...      49  2021-08-17   \n",
       "1      Parler comes back online after a month off the...     249  2021-02-16   \n",
       "2            Amazon EPS beats by $6.18, beats on revenue     115  2021-04-29   \n",
       "3      Electric vehicle battery stocks break higher a...      28  2021-07-28   \n",
       "4      TikTok rescue by Microsoft could make sense - ...      93  2020-08-01   \n",
       "...                                                  ...      ...        ...   \n",
       "26805  Sea Slumps as Tencent Moves to Cut Voting Stak...        0 2022-01-04   \n",
       "26806  Palantir Technologies Announces Collaboration ...        0 2022-01-05   \n",
       "26807  Asian Stocks Down, Positive Chinese Data Fails...        0 2022-01-05   \n",
       "26808  S&P 500 in Big Weekly Loss as Tech Bulls Scatt...        0 2022-01-07   \n",
       "26809  S&P 500 Struggles for Direction as Jobs Miss F...        0 2022-01-07   \n",
       "\n",
       "                                                    link symbol  \\\n",
       "0      https://seekingalpha.com/news/3731674-tsa-exte...    AAL   \n",
       "1      https://seekingalpha.com/news/3662032-parler-c...     FB   \n",
       "2      https://seekingalpha.com/news/3688132-amazon-e...   AMZN   \n",
       "3      https://seekingalpha.com/news/3720809-electric...   BLNK   \n",
       "4      https://seekingalpha.com/news/3598676-tiktok-r...     FB   \n",
       "...                                                  ...    ...   \n",
       "26805  https://www.investing.com/news/stock-market-ne...     SE   \n",
       "26806  https://www.investing.com/news/stock-market-ne...   PLTR   \n",
       "26807  https://www.investing.com/news/stock-market-ne...     SE   \n",
       "26808  https://www.investing.com/news/stock-market-ne...     ON   \n",
       "26809  https://www.investing.com/news/stock-market-ne...     ON   \n",
       "\n",
       "           publisher  pos_sent  neg_sent  neu_sent  comp_sent  sa  \\\n",
       "0      Seeking Alpha     0.042     0.042     0.916     0.2544   1   \n",
       "1      Seeking Alpha     0.082     0.039     0.879     0.9363   1   \n",
       "2      Seeking Alpha     0.065     0.000     0.935     0.7184   1   \n",
       "3      Seeking Alpha     0.047     0.038     0.916     0.1280   1   \n",
       "4      Seeking Alpha     0.114     0.033     0.853     0.8934   1   \n",
       "...              ...       ...       ...       ...        ...  ..   \n",
       "26805  Investing.com     0.084     0.046     0.870     0.7867   0   \n",
       "26806  Investing.com     0.143     0.015     0.842     0.9630   0   \n",
       "26807  Investing.com     0.068     0.034     0.898     0.9201   0   \n",
       "26808  Investing.com     0.096     0.049     0.856     0.9733   0   \n",
       "26809  Investing.com     0.098     0.038     0.864     0.9807   0   \n",
       "\n",
       "                                                word_obj  \n",
       "0      {'transportation': 2, 'administration': 2, 'sa...  \n",
       "1      {'parler': 7, 'users': 4, 'platform': 3, 'skys...  \n",
       "2      {'billion': 6, '5': 4, 'revenue': 3, '108': 3,...  \n",
       "3      {'infrastructure': 5, 'bill': 5, '7': 4, 'ev':...  \n",
       "4      {'would': 5, 'tiktok': 4, 'microsoft': 4, 'mak...  \n",
       "...                                                  ...  \n",
       "26805  {'tencent': 5, 'sea': 4, 'voting': 4, 'stake':...  \n",
       "26806  {'palantir': 6, 'platform': 5, 'hhi': 4, 'big'...  \n",
       "26807  {'services': 4, '1': 4, 'day': 4, 'u': 3, '0':...  \n",
       "26808  {'stocks': 5, 'nasdaq': 5, 'tech': 4, 'rate': ...  \n",
       "26809  {'0': 6, 'nasdaq': 5, 'tech': 4, 'rate': 4, 'm...  \n",
       "\n",
       "[26810 rows x 14 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordy_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_encode_regex = re.compile(u\"[\\x94\\x93\\x92\\x91]\")\n",
    "wordy_df2 = wordy_df2.assign(article = lambda x: x.article.apply(lambda line: re.sub(r'(?<=[.,])(?=[^\\s])', r' ', line)))\n",
    "wordy_df2 = wordy_df2.assign(article = lambda x: x.article.apply(lambda line: re.sub(bad_encode_regex, r' ', line)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordCounts(comment_array):\n",
    "    comment_dictionary = {} \n",
    "    for comment in comment_array:\n",
    "        punc_regex = r\"[\\，\\’\\'\\'\\\"\\\"\\“\\”!\\?@#$%&\\(\\)\\*,-.\\\\\\{\\}+~\\/:;<>\\[\\]^`|=_]\"\n",
    "        reg_bad_quotes = re.compile(u\"[\\x94\\x93\\x92\\x91]\")\n",
    "        comment = comment.lower()\n",
    "        comment = re.sub(punc_regex, \" \", comment)\n",
    "        comment = re.sub(reg_bad_quotes, \" \", comment)\n",
    "        comment = re.sub(r\"[0-9]\", \"\", comment)\n",
    "        words = nltk.tokenize.word_tokenize(comment)\n",
    "        for w in words:\n",
    "            if (w in comment_dictionary.keys()) & (w not in stop_words):\n",
    "                comment_dictionary[w] += 1\n",
    "            elif (w not in stop_words):\n",
    "                comment_dictionary[w] = 1\n",
    "    \n",
    "    comments_words = dict(sorted(comment_dictionary.items(), key=lambda x: x[1], reverse=True))\n",
    "    # comment_list.append(comments_words)\n",
    "\n",
    "    # df = df.assign(word_obj = pd.Series(comment_list))\n",
    "    return pd.Series(comments_words)\n",
    "\n",
    "# word counts sans stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_article_words = wordCounts(wordy_df2[lambda x: x.comp_sent >= 0].article.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_article_words = wordCounts(wordy_df2[lambda x: x.comp_sent < 0].article.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_article_words = negative_article_words.reset_index().rename(columns={'index': 'word', 0: 'neg_counts'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_article_words = positive_article_words.reset_index().rename(columns={'index': 'word', 0: 'pos_counts'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>draftkings</td>\n",
       "      <td>1114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  pos_counts\n",
       "739  draftkings        1114"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_article_words[lambda x: x.word=='draftkings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>neg_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2779</th>\n",
       "      <td>draftkings</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  neg_counts\n",
       "2779  draftkings          56"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_article_words[lambda x: x.word == 'draftkings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_example = wordCounts(wordy_df2[lambda x: (x.symbol == 'DKNG') & (x.comp_sent >= 0)].article).reset_index().rename(columns={'index': 'word', 0: 'neg_counts'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pk           115\n",
       "article      115\n",
       "headline     115\n",
       "comments     115\n",
       "date         115\n",
       "link         115\n",
       "publisher    115\n",
       "pos_sent     115\n",
       "neg_sent     115\n",
       "neu_sent     115\n",
       "comp_sent    115\n",
       "sa           115\n",
       "word_obj     115\n",
       "Name: TSLA, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordy_df2[lambda x: (x.date <= dt.datetime(2021, 2, 1)) & (x.date >= dt.datetime(2021, 1, 1))].groupby('symbol').count().sort_values('date').loc['TSLA', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos_counts</th>\n",
       "      <th>neg_counts</th>\n",
       "      <th>pos_pct</th>\n",
       "      <th>neg_pct</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nasdaq</td>\n",
       "      <td>57260.0</td>\n",
       "      <td>12043.0</td>\n",
       "      <td>0.826227</td>\n",
       "      <td>0.173773</td>\n",
       "      <td>69303.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nyse</td>\n",
       "      <td>41399.0</td>\n",
       "      <td>8421.0</td>\n",
       "      <td>0.830971</td>\n",
       "      <td>0.169029</td>\n",
       "      <td>49820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u</td>\n",
       "      <td>20841.0</td>\n",
       "      <td>6841.0</td>\n",
       "      <td>0.752872</td>\n",
       "      <td>0.247128</td>\n",
       "      <td>27682.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>company</td>\n",
       "      <td>21977.0</td>\n",
       "      <td>3720.0</td>\n",
       "      <td>0.855236</td>\n",
       "      <td>0.144764</td>\n",
       "      <td>25697.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>year</td>\n",
       "      <td>21347.0</td>\n",
       "      <td>3856.0</td>\n",
       "      <td>0.847002</td>\n",
       "      <td>0.152998</td>\n",
       "      <td>25203.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51564</th>\n",
       "      <td>synbiotic</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51563</th>\n",
       "      <td>minnett</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51562</th>\n",
       "      <td>ord</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51561</th>\n",
       "      <td>wfm</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61388</th>\n",
       "      <td>reconnecting</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61389 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               word  pos_counts  neg_counts   pos_pct   neg_pct   counts\n",
       "0            nasdaq     57260.0     12043.0  0.826227  0.173773  69303.0\n",
       "1              nyse     41399.0      8421.0  0.830971  0.169029  49820.0\n",
       "4                 u     20841.0      6841.0  0.752872  0.247128  27682.0\n",
       "2           company     21977.0      3720.0  0.855236  0.144764  25697.0\n",
       "3              year     21347.0      3856.0  0.847002  0.152998  25203.0\n",
       "...             ...         ...         ...       ...       ...      ...\n",
       "51564     synbiotic         1.0         0.0  1.000000  0.000000      1.0\n",
       "51563       minnett         1.0         0.0  1.000000  0.000000      1.0\n",
       "51562           ord         1.0         0.0  1.000000  0.000000      1.0\n",
       "51561           wfm         1.0         0.0  1.000000  0.000000      1.0\n",
       "61388  reconnecting         0.0         1.0  0.000000  1.000000      1.0\n",
       "\n",
       "[61389 rows x 6 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_article_words.merge(how='outer', right=negative_article_words).fillna(0).\\\n",
    "    assign(pos_pct = lambda x: x.pos_counts / (x.pos_counts + x.neg_counts)).\\\n",
    "        assign(neg_pct = lambda x: x.neg_counts / (x.pos_counts + x.neg_counts)).sort_values('neg_pct').\\\n",
    "            assign(counts = lambda x: (x.pos_counts + x.neg_counts)).sort_values('counts', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_art(art):\n",
    "    return sia.polarity_scores(art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordy_df_news = wordy_df2.assign(sentiment_dict = lambda x : x.article.apply(sentiment_art))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordy_df_news= wordy_df_news.assign(pos_sent = lambda x: x.sentiment_dict.apply(lambda y: y['pos']))\\\n",
    "    .assign(neg_sent = lambda x: x.sentiment_dict.apply(lambda y: y['neg']))\\\n",
    "        .assign(neu_sent = lambda x: x.sentiment_dict.apply(lambda y: y['neu']))\\\n",
    "            .assign(comp_sent = lambda x: x.sentiment_dict.apply(lambda y: y['compound']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordy_df_news.drop('sentiment_dict', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pk</th>\n",
       "      <th>article</th>\n",
       "      <th>headline</th>\n",
       "      <th>comments</th>\n",
       "      <th>link</th>\n",
       "      <th>symbol</th>\n",
       "      <th>publisher</th>\n",
       "      <th>pos_sent</th>\n",
       "      <th>neg_sent</th>\n",
       "      <th>neu_sent</th>\n",
       "      <th>comp_sent</th>\n",
       "      <th>sa</th>\n",
       "      <th>word_obj</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-30</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-31</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-30</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-31</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-28</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-31</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-30</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-31</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-30</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-31</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-31</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-30</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-31</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-30</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-29</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-30</th>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-31</th>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-30</th>\n",
       "      <td>1160</td>\n",
       "      <td>1160</td>\n",
       "      <td>1160</td>\n",
       "      <td>1160</td>\n",
       "      <td>1160</td>\n",
       "      <td>1160</td>\n",
       "      <td>1160</td>\n",
       "      <td>1160</td>\n",
       "      <td>1160</td>\n",
       "      <td>1160</td>\n",
       "      <td>1160</td>\n",
       "      <td>1160</td>\n",
       "      <td>1160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-31</th>\n",
       "      <td>1678</td>\n",
       "      <td>1678</td>\n",
       "      <td>1678</td>\n",
       "      <td>1678</td>\n",
       "      <td>1678</td>\n",
       "      <td>1678</td>\n",
       "      <td>1678</td>\n",
       "      <td>1678</td>\n",
       "      <td>1678</td>\n",
       "      <td>1678</td>\n",
       "      <td>1678</td>\n",
       "      <td>1678</td>\n",
       "      <td>1678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-31</th>\n",
       "      <td>1664</td>\n",
       "      <td>1664</td>\n",
       "      <td>1664</td>\n",
       "      <td>1664</td>\n",
       "      <td>1664</td>\n",
       "      <td>1664</td>\n",
       "      <td>1664</td>\n",
       "      <td>1664</td>\n",
       "      <td>1664</td>\n",
       "      <td>1664</td>\n",
       "      <td>1664</td>\n",
       "      <td>1664</td>\n",
       "      <td>1664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-30</th>\n",
       "      <td>1671</td>\n",
       "      <td>1671</td>\n",
       "      <td>1671</td>\n",
       "      <td>1671</td>\n",
       "      <td>1671</td>\n",
       "      <td>1671</td>\n",
       "      <td>1671</td>\n",
       "      <td>1671</td>\n",
       "      <td>1671</td>\n",
       "      <td>1671</td>\n",
       "      <td>1671</td>\n",
       "      <td>1671</td>\n",
       "      <td>1671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-31</th>\n",
       "      <td>1841</td>\n",
       "      <td>1841</td>\n",
       "      <td>1841</td>\n",
       "      <td>1841</td>\n",
       "      <td>1841</td>\n",
       "      <td>1841</td>\n",
       "      <td>1841</td>\n",
       "      <td>1841</td>\n",
       "      <td>1841</td>\n",
       "      <td>1841</td>\n",
       "      <td>1841</td>\n",
       "      <td>1841</td>\n",
       "      <td>1841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-30</th>\n",
       "      <td>1787</td>\n",
       "      <td>1787</td>\n",
       "      <td>1787</td>\n",
       "      <td>1787</td>\n",
       "      <td>1787</td>\n",
       "      <td>1787</td>\n",
       "      <td>1787</td>\n",
       "      <td>1787</td>\n",
       "      <td>1787</td>\n",
       "      <td>1787</td>\n",
       "      <td>1787</td>\n",
       "      <td>1787</td>\n",
       "      <td>1787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>1603</td>\n",
       "      <td>1603</td>\n",
       "      <td>1603</td>\n",
       "      <td>1603</td>\n",
       "      <td>1603</td>\n",
       "      <td>1603</td>\n",
       "      <td>1603</td>\n",
       "      <td>1603</td>\n",
       "      <td>1603</td>\n",
       "      <td>1603</td>\n",
       "      <td>1603</td>\n",
       "      <td>1603</td>\n",
       "      <td>1603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-31</th>\n",
       "      <td>1995</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-28</th>\n",
       "      <td>2031</td>\n",
       "      <td>2031</td>\n",
       "      <td>2031</td>\n",
       "      <td>2031</td>\n",
       "      <td>2031</td>\n",
       "      <td>2031</td>\n",
       "      <td>2031</td>\n",
       "      <td>2031</td>\n",
       "      <td>2031</td>\n",
       "      <td>2031</td>\n",
       "      <td>2031</td>\n",
       "      <td>2031</td>\n",
       "      <td>2031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-31</th>\n",
       "      <td>2099</td>\n",
       "      <td>2099</td>\n",
       "      <td>2099</td>\n",
       "      <td>2099</td>\n",
       "      <td>2099</td>\n",
       "      <td>2099</td>\n",
       "      <td>2099</td>\n",
       "      <td>2099</td>\n",
       "      <td>2099</td>\n",
       "      <td>2099</td>\n",
       "      <td>2099</td>\n",
       "      <td>2099</td>\n",
       "      <td>2099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-30</th>\n",
       "      <td>1978</td>\n",
       "      <td>1978</td>\n",
       "      <td>1978</td>\n",
       "      <td>1978</td>\n",
       "      <td>1978</td>\n",
       "      <td>1978</td>\n",
       "      <td>1978</td>\n",
       "      <td>1978</td>\n",
       "      <td>1978</td>\n",
       "      <td>1978</td>\n",
       "      <td>1978</td>\n",
       "      <td>1978</td>\n",
       "      <td>1978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-31</th>\n",
       "      <td>1874</td>\n",
       "      <td>1874</td>\n",
       "      <td>1874</td>\n",
       "      <td>1874</td>\n",
       "      <td>1874</td>\n",
       "      <td>1874</td>\n",
       "      <td>1874</td>\n",
       "      <td>1874</td>\n",
       "      <td>1874</td>\n",
       "      <td>1874</td>\n",
       "      <td>1874</td>\n",
       "      <td>1874</td>\n",
       "      <td>1874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-30</th>\n",
       "      <td>1663</td>\n",
       "      <td>1663</td>\n",
       "      <td>1663</td>\n",
       "      <td>1663</td>\n",
       "      <td>1663</td>\n",
       "      <td>1663</td>\n",
       "      <td>1663</td>\n",
       "      <td>1663</td>\n",
       "      <td>1663</td>\n",
       "      <td>1663</td>\n",
       "      <td>1663</td>\n",
       "      <td>1663</td>\n",
       "      <td>1663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-31</th>\n",
       "      <td>1392</td>\n",
       "      <td>1392</td>\n",
       "      <td>1392</td>\n",
       "      <td>1392</td>\n",
       "      <td>1392</td>\n",
       "      <td>1392</td>\n",
       "      <td>1392</td>\n",
       "      <td>1392</td>\n",
       "      <td>1392</td>\n",
       "      <td>1392</td>\n",
       "      <td>1392</td>\n",
       "      <td>1392</td>\n",
       "      <td>1392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-31</th>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-30</th>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-31</th>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-30</th>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31</th>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-31</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pk  article  headline  comments  link  symbol  publisher  \\\n",
       "date                                                                     \n",
       "2018-01-31     1        1         1         1     1       1          1   \n",
       "2018-02-28     0        0         0         0     0       0          0   \n",
       "2018-03-31     0        0         0         0     0       0          0   \n",
       "2018-04-30     0        0         0         0     0       0          0   \n",
       "2018-05-31     0        0         0         0     0       0          0   \n",
       "2018-06-30     1        1         1         1     1       1          1   \n",
       "2018-07-31     0        0         0         0     0       0          0   \n",
       "2018-08-31     1        1         1         1     1       1          1   \n",
       "2018-09-30     0        0         0         0     0       0          0   \n",
       "2018-10-31     2        2         2         2     2       2          2   \n",
       "2018-11-30     3        3         3         3     3       3          3   \n",
       "2018-12-31     0        0         0         0     0       0          0   \n",
       "2019-01-31     8        8         8         8     8       8          8   \n",
       "2019-02-28     5        5         5         5     5       5          5   \n",
       "2019-03-31     8        8         8         8     8       8          8   \n",
       "2019-04-30     4        4         4         4     4       4          4   \n",
       "2019-05-31     9        9         9         9     9       9          9   \n",
       "2019-06-30     4        4         4         4     4       4          4   \n",
       "2019-07-31     4        4         4         4     4       4          4   \n",
       "2019-08-31     6        6         6         6     6       6          6   \n",
       "2019-09-30     5        5         5         5     5       5          5   \n",
       "2019-10-31     5        5         5         5     5       5          5   \n",
       "2019-11-30     8        8         8         8     8       8          8   \n",
       "2019-12-31     3        3         3         3     3       3          3   \n",
       "2020-01-31     1        1         1         1     1       1          1   \n",
       "2020-02-29     9        9         9         9     9       9          9   \n",
       "2020-03-31    24       24        24        24    24      24         24   \n",
       "2020-04-30    49       49        49        49    49      49         49   \n",
       "2020-05-31   760      760       760       760   760     760        760   \n",
       "2020-06-30  1160     1160      1160      1160  1160    1160       1160   \n",
       "2020-07-31  1678     1678      1678      1678  1678    1678       1678   \n",
       "2020-08-31  1664     1664      1664      1664  1664    1664       1664   \n",
       "2020-09-30  1671     1671      1671      1671  1671    1671       1671   \n",
       "2020-10-31  1841     1841      1841      1841  1841    1841       1841   \n",
       "2020-11-30  1787     1787      1787      1787  1787    1787       1787   \n",
       "2020-12-31  1603     1603      1603      1603  1603    1603       1603   \n",
       "2021-01-31  1995     1995      1995      1995  1995    1995       1995   \n",
       "2021-02-28  2031     2031      2031      2031  2031    2031       2031   \n",
       "2021-03-31  2099     2099      2099      2099  2099    2099       2099   \n",
       "2021-04-30  1978     1978      1978      1978  1978    1978       1978   \n",
       "2021-05-31  1874     1874      1874      1874  1874    1874       1874   \n",
       "2021-06-30  1663     1663      1663      1663  1663    1663       1663   \n",
       "2021-07-31  1392     1392      1392      1392  1392    1392       1392   \n",
       "2021-08-31  1195     1195      1195      1195  1195    1195       1195   \n",
       "2021-09-30   102      102       102       102   102     102        102   \n",
       "2021-10-31    48       48        48        48    48      48         48   \n",
       "2021-11-30    64       64        64        64    64      64         64   \n",
       "2021-12-31    40       40        40        40    40      40         40   \n",
       "2022-01-31     5        5         5         5     5       5          5   \n",
       "\n",
       "            pos_sent  neg_sent  neu_sent  comp_sent    sa  word_obj  \n",
       "date                                                                 \n",
       "2018-01-31         1         1         1          1     1         1  \n",
       "2018-02-28         0         0         0          0     0         0  \n",
       "2018-03-31         0         0         0          0     0         0  \n",
       "2018-04-30         0         0         0          0     0         0  \n",
       "2018-05-31         0         0         0          0     0         0  \n",
       "2018-06-30         1         1         1          1     1         1  \n",
       "2018-07-31         0         0         0          0     0         0  \n",
       "2018-08-31         1         1         1          1     1         1  \n",
       "2018-09-30         0         0         0          0     0         0  \n",
       "2018-10-31         2         2         2          2     2         2  \n",
       "2018-11-30         3         3         3          3     3         3  \n",
       "2018-12-31         0         0         0          0     0         0  \n",
       "2019-01-31         8         8         8          8     8         8  \n",
       "2019-02-28         5         5         5          5     5         5  \n",
       "2019-03-31         8         8         8          8     8         8  \n",
       "2019-04-30         4         4         4          4     4         4  \n",
       "2019-05-31         9         9         9          9     9         9  \n",
       "2019-06-30         4         4         4          4     4         4  \n",
       "2019-07-31         4         4         4          4     4         4  \n",
       "2019-08-31         6         6         6          6     6         6  \n",
       "2019-09-30         5         5         5          5     5         5  \n",
       "2019-10-31         5         5         5          5     5         5  \n",
       "2019-11-30         8         8         8          8     8         8  \n",
       "2019-12-31         3         3         3          3     3         3  \n",
       "2020-01-31         1         1         1          1     1         1  \n",
       "2020-02-29         9         9         9          9     9         9  \n",
       "2020-03-31        24        24        24         24    24        24  \n",
       "2020-04-30        49        49        49         49    49        49  \n",
       "2020-05-31       760       760       760        760   760       760  \n",
       "2020-06-30      1160      1160      1160       1160  1160      1160  \n",
       "2020-07-31      1678      1678      1678       1678  1678      1678  \n",
       "2020-08-31      1664      1664      1664       1664  1664      1664  \n",
       "2020-09-30      1671      1671      1671       1671  1671      1671  \n",
       "2020-10-31      1841      1841      1841       1841  1841      1841  \n",
       "2020-11-30      1787      1787      1787       1787  1787      1787  \n",
       "2020-12-31      1603      1603      1603       1603  1603      1603  \n",
       "2021-01-31      1995      1995      1995       1995  1995      1995  \n",
       "2021-02-28      2031      2031      2031       2031  2031      2031  \n",
       "2021-03-31      2099      2099      2099       2099  2099      2099  \n",
       "2021-04-30      1978      1978      1978       1978  1978      1978  \n",
       "2021-05-31      1874      1874      1874       1874  1874      1874  \n",
       "2021-06-30      1663      1663      1663       1663  1663      1663  \n",
       "2021-07-31      1392      1392      1392       1392  1392      1392  \n",
       "2021-08-31      1195      1195      1195       1195  1195      1195  \n",
       "2021-09-30       102       102       102        102   102       102  \n",
       "2021-10-31        48        48        48         48    48        48  \n",
       "2021-11-30        64        64        64         64    64        64  \n",
       "2021-12-31        40        40        40         40    40        40  \n",
       "2022-01-31         5         5         5          5     5         5  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordy_df_news.groupby(pd.Grouper(key='date', freq=\"1M\")).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>channel</th>\n",
       "      <th>symbols</th>\n",
       "      <th>pos_sent</th>\n",
       "      <th>neu_sent</th>\n",
       "      <th>neg_sent</th>\n",
       "      <th>comp_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-08</td>\n",
       "      <td>wetlqd-ideas</td>\n",
       "      <td>['AMD']</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.4404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-13</td>\n",
       "      <td>wetlqd-ideas</td>\n",
       "      <td>['MSFT']</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.4404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-13</td>\n",
       "      <td>wetlqd-ideas</td>\n",
       "      <td>['MSFT']</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.3612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-14</td>\n",
       "      <td>wetlqd-ideas</td>\n",
       "      <td>['ON', 'MA', 'ING']</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.403</td>\n",
       "      <td>-0.4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-14</td>\n",
       "      <td>wetlqd-ideas</td>\n",
       "      <td>['CRM']</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3389</th>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>option-trading</td>\n",
       "      <td>['OOOO']</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3390</th>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>option-trading</td>\n",
       "      <td>['ING']</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.8402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3391</th>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>trading</td>\n",
       "      <td>['FSLY']</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3392</th>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>trading</td>\n",
       "      <td>['IT']</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3393</th>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>options</td>\n",
       "      <td>['CRM']</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3394 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date         channel              symbols  pos_sent  neu_sent  \\\n",
       "0    2019-08-08    wetlqd-ideas              ['AMD']     0.293     0.707   \n",
       "1    2019-08-13    wetlqd-ideas             ['MSFT']     0.182     0.818   \n",
       "2    2019-08-13    wetlqd-ideas             ['MSFT']     0.294     0.706   \n",
       "3    2019-08-14    wetlqd-ideas  ['ON', 'MA', 'ING']     0.000     0.597   \n",
       "4    2019-08-14    wetlqd-ideas              ['CRM']     0.000     1.000   \n",
       "...         ...             ...                  ...       ...       ...   \n",
       "3389 2020-12-08  option-trading             ['OOOO']     0.000     1.000   \n",
       "3390 2020-12-08  option-trading              ['ING']     0.900     0.100   \n",
       "3391 2020-12-08         trading             ['FSLY']     0.000     1.000   \n",
       "3392 2020-12-08         trading               ['IT']     0.000     1.000   \n",
       "3393 2020-12-08         options              ['CRM']     0.000     1.000   \n",
       "\n",
       "      neg_sent  comp_sent  \n",
       "0        0.000     0.4404  \n",
       "1        0.000     0.4404  \n",
       "2        0.000     0.3612  \n",
       "3        0.403    -0.4019  \n",
       "4        0.000     0.0000  \n",
       "...        ...        ...  \n",
       "3389     0.000     0.0000  \n",
       "3390     0.000     0.8402  \n",
       "3391     0.000     0.0000  \n",
       "3392     0.000     0.0000  \n",
       "3393     0.000     0.0000  \n",
       "\n",
       "[3394 rows x 7 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments#.groupby(pd.Grouper(key='date', freq='1M')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sql.connect('../data/interim/discord/discord.db') as con:\n",
    "    full_comments =pd.read_sql(f\"SELECT DATE(timestamp) date, channel, server, pk, content, isBot, mentions, emojis, links, chat_emotes from comments ORDER BY timestamp\", parse_dates={'date': '%Y-%m-%d'}, con=con)\n",
    "with sql.connect('../data/interim/companies.db') as con:\n",
    "    wanted_companies = pd.read_sql(\"SELECT DISTINCT symbol FROM daily WHERE symbol NOT IN ('PT', 'IT', 'ON', 'ING')\", con=con).symbol.values\n",
    "    wanted_companies = tuple(wanted_companies)\n",
    "    mentions = pd.read_sql(f\"SELECT * from mentions WHERE symbol IN {wanted_companies}\", con=con, index_col='pk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>channel</th>\n",
       "      <th>server</th>\n",
       "      <th>pk</th>\n",
       "      <th>content</th>\n",
       "      <th>isBot</th>\n",
       "      <th>mentions</th>\n",
       "      <th>emojis</th>\n",
       "      <th>links</th>\n",
       "      <th>chat_emotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>wetlqd-ideas</td>\n",
       "      <td>Misc</td>\n",
       "      <td>0</td>\n",
       "      <td>Play account today</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>wetlqd-ideas</td>\n",
       "      <td>Misc</td>\n",
       "      <td>1</td>\n",
       "      <td>@everyone today’s total. This doesn’t calculat...</td>\n",
       "      <td>0</td>\n",
       "      <td>everyone</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>wetlqd-ideas</td>\n",
       "      <td>Misc</td>\n",
       "      <td>2</td>\n",
       "      <td>Crack</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>wetlqd-ideas</td>\n",
       "      <td>Misc</td>\n",
       "      <td>3</td>\n",
       "      <td>Big crack</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>wetlqd-ideas</td>\n",
       "      <td>Misc</td>\n",
       "      <td>4</td>\n",
       "      <td>Heroin</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31929</th>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>trading</td>\n",
       "      <td>LSV</td>\n",
       "      <td>31929</td>\n",
       "      <td>&lt;@!644997307976122388&gt; all of my shorter video...</td>\n",
       "      <td>0</td>\n",
       "      <td>644997307976122388</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31930</th>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>trading</td>\n",
       "      <td>LSV</td>\n",
       "      <td>31930</td>\n",
       "      <td>&lt;@428921853403463713&gt; have you done a video in...</td>\n",
       "      <td>0</td>\n",
       "      <td>428921853403463713</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31931</th>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>trading</td>\n",
       "      <td>LSV</td>\n",
       "      <td>31931</td>\n",
       "      <td>&lt;@!184420431242067977&gt; nope, not yet</td>\n",
       "      <td>0</td>\n",
       "      <td>184420431242067977</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31932</th>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>trading</td>\n",
       "      <td>LSV</td>\n",
       "      <td>31932</td>\n",
       "      <td>they're the airline wifi company right?</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31933</th>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>options</td>\n",
       "      <td>LSV</td>\n",
       "      <td>31933</td>\n",
       "      <td>CRM ??</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31934 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date       channel server     pk  \\\n",
       "0     2019-08-02  wetlqd-ideas   Misc      0   \n",
       "1     2019-08-02  wetlqd-ideas   Misc      1   \n",
       "2     2019-08-02  wetlqd-ideas   Misc      2   \n",
       "3     2019-08-02  wetlqd-ideas   Misc      3   \n",
       "4     2019-08-02  wetlqd-ideas   Misc      4   \n",
       "...          ...           ...    ...    ...   \n",
       "31929 2020-12-08       trading    LSV  31929   \n",
       "31930 2020-12-08       trading    LSV  31930   \n",
       "31931 2020-12-08       trading    LSV  31931   \n",
       "31932 2020-12-08       trading    LSV  31932   \n",
       "31933 2020-12-08       options    LSV  31933   \n",
       "\n",
       "                                                 content  isBot  \\\n",
       "0                                     Play account today      0   \n",
       "1      @everyone today’s total. This doesn’t calculat...      0   \n",
       "2                                                  Crack      0   \n",
       "3                                              Big crack      0   \n",
       "4                                                 Heroin      0   \n",
       "...                                                  ...    ...   \n",
       "31929  <@!644997307976122388> all of my shorter video...      0   \n",
       "31930  <@428921853403463713> have you done a video in...      0   \n",
       "31931               <@!184420431242067977> nope, not yet      0   \n",
       "31932            they're the airline wifi company right?      0   \n",
       "31933                                             CRM ??      0   \n",
       "\n",
       "                 mentions emojis links chat_emotes  \n",
       "0                                                   \n",
       "1                everyone                           \n",
       "2                                                   \n",
       "3                                                   \n",
       "4                                                   \n",
       "...                   ...    ...   ...         ...  \n",
       "31929  644997307976122388                           \n",
       "31930  428921853403463713                           \n",
       "31931  184420431242067977                           \n",
       "31932                                               \n",
       "31933                                               \n",
       "\n",
       "[31934 rows x 10 columns]"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "userIdCatcher = r\"(<@(!)?\\d+>|@everyone)\"\n",
    "discord_emote_regex = r\"<:.+:\\d+>\"\n",
    "url_regex = r\"https*\\:.+|www\\..+\"\n",
    "punc_regex = r\"[\\’\\'\\'\\\"\\\"\\“\\”!\\?@#$%&\\(\\)\\*,-.\\\\\\{\\}+~\\/:;<>\\[\\]^`|=_’]\"\n",
    "contract_regex = r\"[\\'\\’\\’]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_comment(comment):\n",
    "    comment = re.sub(\"|\".join([x for x in [userIdCatcher, discord_emote_regex, url_regex]]), \"\", comment)\n",
    "    comment = re.sub(contract_regex, \"\", comment)\n",
    "    comment = re.sub(punc_regex, \" \", comment)\n",
    "    comment = comment.replace(\"\\n\", \" \").replace(\"'s\", \"\")\n",
    "    return \" \" + comment + \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_comments = full_comments.assign(cc_comment = lambda x: x.content.apply(clean_comment).apply(sentiment_art))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_comments = full_comments.assign(pos_sent = lambda x: x.cc_comment.apply(lambda y: y['pos']))\\\n",
    "    .assign(neg_sent = lambda x: x.cc_comment.apply(lambda y: y['neg']))\\\n",
    "        .assign(neu_sent = lambda x: x.cc_comment.apply(lambda y: y['neu']))\\\n",
    "            .assign(comp_sent = lambda x: x.cc_comment.apply(lambda y: y['compound']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_comments.drop('cc_comment', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_set = set(x.lower() for x in mentions.symbol.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_symbols(list_obj):\n",
    "    symbols = []\n",
    "    for l in list_obj:\n",
    "        if l in company_set:\n",
    "            symbols.append(l)\n",
    "    return symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_comments = full_comments.assign(cc_comment = lambda x: x.content.apply(str.lower))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_comments = full_comments.assign(symbols = lambda x: x.cc_comment.apply(clean_comment).apply(nltk.tokenize.word_tokenize).apply(lambda z: list_to_symbols(z)).apply(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "emote_agg = {}\n",
    "def agg_(comma_companies, agg_dict):\n",
    "    comma_companies = re.sub(r'[\\[\\]\\'\\']', \"\", comma_companies)\n",
    "    for e in comma_companies.split(\",\"):\n",
    "        e = e.strip()\n",
    "        if e in agg_dict.keys():\n",
    "            emote_agg[e] += 1\n",
    "        else:\n",
    "            emote_agg[e] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        None\n",
       "1        None\n",
       "2        None\n",
       "3        None\n",
       "4        None\n",
       "         ... \n",
       "31929    None\n",
       "31930    None\n",
       "31931    None\n",
       "31932    None\n",
       "31933    None\n",
       "Name: symbols, Length: 31934, dtype: object"
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_comments.symbols.apply(lambda x: agg_(x, emote_agg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mentions = pd.Series(emote_agg).reset_index().iloc[1:, :].sort_values(0, ascending=False).reset_index(drop=True).rename(columns={'index': 'symbol', 0:'counts'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>counts_x</th>\n",
       "      <th>counts_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>WWR</td>\n",
       "      <td>30</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>HYLN</td>\n",
       "      <td>29</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SNDL</td>\n",
       "      <td>29</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>JD</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SNAP</td>\n",
       "      <td>29</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>RKT</td>\n",
       "      <td>28</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ES</td>\n",
       "      <td>27</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>JKS</td>\n",
       "      <td>25</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NNDM</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>GME</td>\n",
       "      <td>24</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>SE</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>MA</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>SQQQ</td>\n",
       "      <td>22</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>KO</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>MARA</td>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>HEAR</td>\n",
       "      <td>21</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>CRM</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>CGC</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>IZEA</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>CBAT</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>VXX</td>\n",
       "      <td>19</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>INTC</td>\n",
       "      <td>19</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>SPCE</td>\n",
       "      <td>19</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>AAL</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>SPI</td>\n",
       "      <td>18</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>AREC</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>QQQ</td>\n",
       "      <td>18</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>UONE</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>BLNK</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>HD</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>DIS</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>MO</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>TLRY</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>ADTX</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>LMNL</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>JMIA</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>EXAS</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>SOLO</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>XERS</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>DPW</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>GILD</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>VLDR</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   symbol  counts_x  counts_y\n",
       "29    WWR        30        34\n",
       "30   HYLN        29        40\n",
       "31   SNDL        29        39\n",
       "32     JD        29        31\n",
       "33   SNAP        29        52\n",
       "34    RKT        28        42\n",
       "35     ES        27        36\n",
       "36    JKS        25        46\n",
       "37   NNDM        25        30\n",
       "38    GME        24        37\n",
       "39     SE        23        24\n",
       "40     MA        23        31\n",
       "41   SQQQ        22        36\n",
       "42     KO        22        23\n",
       "43   MARA        21        34\n",
       "44   HEAR        21        51\n",
       "45    CRM        21        27\n",
       "46    CGC        20        23\n",
       "47   IZEA        20        23\n",
       "48   CBAT        20        24\n",
       "49    VXX        19        36\n",
       "50   INTC        19        29\n",
       "51   SPCE        19        31\n",
       "52    AAL        18        23\n",
       "53    SPI        18        27\n",
       "54   AREC        18        18\n",
       "55   NFLX        18        29\n",
       "56    QQQ        18        28\n",
       "57   UONE        18        15\n",
       "58   BLNK        18        26\n",
       "59     HD        18        19\n",
       "60    DIS        17        27\n",
       "61     MO        17        18\n",
       "62   TLRY        16        22\n",
       "63   ADTX        16        20\n",
       "64   LMNL        15        19\n",
       "65   JMIA        15        17\n",
       "66   EXAS        15        32\n",
       "67   SOLO        15        28\n",
       "68   XERS        15        17\n",
       "69    DPW        14        16\n",
       "70   GILD        14        17\n",
       "71   VLDR         6         7"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mentions.merge(new_mentions.assign(symbol=lambda x: x.symbol.apply(str.upper)), 'left', on='symbol').iloc[29:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_token_dict = {}\n",
    "# full_comments = full_comments.assign(cc_comment = lambda x: x.content.apply(clean_comment).apply(str.lower))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenSeries = wordCounts(full_comments.cc_comment.values).reset_index().rename(columns={'index': 'word', 0:'counts'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "commentsPositiveSeries = wordCounts(full_comments[lambda x: x.comp_sent >= 0.0].cc_comment.values).reset_index().rename(columns={'index': 'word', 0:'counts'})\n",
    "commentsNegativeSeries = wordCounts(full_comments[lambda x: x.comp_sent <= 0.0].cc_comment.values).reset_index().rename(columns={'index': 'word', 0:'counts'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>nflx</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word  counts\n",
       "791  nflx      17"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commentsNegativeSeries[lambda x: x.word == 'nflx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>nflx</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word  counts\n",
       "823  nflx      26"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commentsPositiveSeries[lambda x: x.word == 'nflx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "533f42cc1718b4e514b78a4bcd7158294e27b7c18264f40c4fe062bcb1773c09"
  },
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
